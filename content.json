{"meta":{"title":"清弦小站","subtitle":"","description":"BLOG","author":"庞宇轩","url":"https://pyxblog.cn","root":"/"},"pages":[{"title":"","date":"2022-08-06T02:27:41.716Z","updated":"2022-08-06T02:27:41.716Z","comments":false,"path":"404.html","permalink":"https://pyxblog.cn/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2022-09-03T12:46:41.359Z","updated":"2022-08-17T11:57:36.675Z","comments":false,"path":"about/index.html","permalink":"https://pyxblog.cn/about/index.html","excerpt":"","text":"庞宇轩 中国传媒大学 信息与通信工程学院 2019级广播电视工程专业 教育背景 中国传媒大学-信息与通信工程学院-广播电视工程专业 专业评级：A+中国传媒大学国家特色专业、王牌工科专业，属于电子信息类专业，主修计算机&amp;通信两个方向的课程。 学业成绩 必修GPA 必修&amp;限选GPA 专业排名 专业总人数 3.85 3.86 1 82 证明材料 主修课程 高等数学 概率论与数理统计 C/C++程序设计 数据结构与算法 计算机网络 99 95 100 100 94 数字信号处理 数字视音频处理 信息论与编码原理 电子系统仿真与设计 计算机网络程序设计 97 96 96 99 98 证明材料 英语水平 CET-4 CET-6 IELTS IELTS-Reading IELTS-Listening IELTS-Writing IELTS-Speaking 593 472 6.5 8.0 6.5 6.5 5.5 证明材料 项目经历 首届MCL大学生学术训练季 时间：2020.08-2021.03 大一学年暑期，作为唯一一位2019级成员入选首届MCL大学生学术训练季。 首届MCL大学生学术训练季https://www.cuc.edu.cn/news/2020/0809/c1902a172348/pagem.htm 开启一周一组会的科研道路，初期通过吴恩达机器学习系列课程学习基础知识，后期阅读推荐系统领域经典文献SVD++、FM、BPR、NCF等，并理解学习其源码。 媒体融合与传播国家重点实验室 时间：2020.10-至今 大二上学期，入选我校创新人才“菁英班” 关于创新人才“菁英班”： 同届学生中共30人入选，每人选择一位博导/硕导开展科研训练，两年后毕业，毕业要求包括论文发表、竞赛获奖、大创经历等。相关内容参考： 创新人才“菁英班”http://www.cuc.edu.cn/news/2019/1126/c1902a159436/page.htm 开始跟随广播电视工程专业系主任杨盈昀教授从事智能图像与视音频领域的研究工作，从属于我校「媒体融合与传播国家重点实验室」下的智能视音频与超高清视频技术团队。"},{"title":"所有专栏","date":"2022-10-08T12:55:56.493Z","updated":"2022-08-06T02:27:41.719Z","comments":false,"path":"categories/index.html","permalink":"https://pyxblog.cn/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2022-08-06T02:27:41.720Z","updated":"2022-08-06T02:27:41.720Z","comments":false,"path":"tags/index.html","permalink":"https://pyxblog.cn/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2022-10-16T11:30:56.940Z","updated":"2022-08-06T02:27:41.720Z","comments":true,"path":"friends/index.html","permalink":"https://pyxblog.cn/friends/index.html","excerpt":"提供一些日常学习生活中常用的网站&我的宝藏网站","text":"提供一些日常学习生活中常用的网站&我的宝藏网站 链接失效请直接在评论区反馈哦～"},{"title":"第三章第二次作业","date":"2022-10-15T12:13:35.746Z","updated":"2022-10-08T12:59:53.058Z","comments":true,"path":"python-homework/chapter3_2/index.html","permalink":"https://pyxblog.cn/python-homework/chapter3_2/index.html","excerpt":"","text":"学生姓名：庞宇轩 学号：2019302110354 产生随机的样本，实现一个2层全连接网络，激活函数为sigmoid函数，损失函数为均方误差，采用梯度下降法优化，并画出损失值曲线。 导入所需的库函数 123import numpy as npimport torchfrom matplotlib import pyplot as plt 产生样本，初始化权重&amp;参数 1234567891011121314151617181920m, d, q, l = 32, 20, 10, 2# - m 样本数# - d 输入维度# - q 隐藏层神经元维数# - l 输出层神经元维数# 输入数据和输出数据x = torch.randn(m, d) # 输入数据y = torch.randn(m, l) # 输出数据# 两层权重，以及初始化v = torch.randn(d, q) # 第一层gama = torch.randn(q)w = torch.randn(q, l) # 第二层theta = torch.randn(l)# 步长eta = 0.05# 每次迭代后计算损失函数值，以备画图使用loss = np.zeros(500) 训练 梯度初始化 1234grad_v = torch.zeros(d, q)grad_gama = torch.zeros(q)grad_w = torch.zeros(q, l)grad_theta = torch.zeros(l) 遍历数据集 1234567891011121314151617181920212223242526272829303132for i in range(m): ############################ # 前向传播 # 第一层 b = torch.matmul(x[i, :], v) - gama b = torch.sigmoid(b) # 第二层 a = torch.matmul(b, w) - theta y_out = torch.sigmoid(a) ############################ # 反向传播 # 计算梯度 g = -(y_out - y[i, :]) * y_out * (1 - y_out) g = g.unsqueeze(dim=0) # (1, l) b = b.unsqueeze(dim=1) # (q, 1) grad_w_tmp = eta * torch.matmul(b, g) grad_theta_tmp = -eta * g grad_theta_tmp = grad_theta_tmp.squeeze(dim=0) g = g.squeeze(dim=0) # (,l) b = b.squeeze(dim=1) # (q,) e = b * (1 - b) * torch.matmul(w, g) grad_v_tmp = eta * torch.matmul(x[i, :].unsqueeze(dim=1), e.unsqueeze(dim=0)) grad_gama_tmp = -eta * e # 将各个样本的梯度加在一起 grad_v += grad_v_tmp grad_gama += grad_gama_tmp grad_w += grad_w_tmp grad_theta += grad_theta_tmp 更新权重&amp;计算loss 12345678910w += grad_w / mtheta += grad_theta / mv += grad_v / mgama += grad_gama / mb = torch.matmul(x, v) - gamab = torch.sigmoid(b)a = torch.matmul(b, w) - thetay_out = torch.sigmoid(a)loss[t] = 0.5 * torch.sum(torch.pow(y_out - y, 2)) / m 完整的训练代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455for t in range(500): # print(&#x27;当前训练批次:&#123;&#125;&#x27;.format(t)) # 权重梯度初始化 grad_v = torch.zeros(d, q) grad_gama = torch.zeros(q) grad_w = torch.zeros(q, l) grad_theta = torch.zeros(l) # 遍历数据集 for i in range(m): ############################ # 前向传播 # 第一层 b = torch.matmul(x[i, :], v) - gama b = torch.sigmoid(b) # 第二层 a = torch.matmul(b, w) - theta y_out = torch.sigmoid(a) ############################ # 反向传播 # 计算梯度 g = -(y_out - y[i, :]) * y_out * (1 - y_out) g = g.unsqueeze(dim=0) # (1, l) b = b.unsqueeze(dim=1) # (q, 1) grad_w_tmp = eta * torch.matmul(b, g) grad_theta_tmp = -eta * g grad_theta_tmp = grad_theta_tmp.squeeze(dim=0) g = g.squeeze(dim=0) # (,l) b = b.squeeze(dim=1) # (q,) e = b * (1 - b) * torch.matmul(w, g) grad_v_tmp = eta * torch.matmul(x[i, :].unsqueeze(dim=1), e.unsqueeze(dim=0)) grad_gama_tmp = -eta * e # 将各个样本的梯度加在一起 grad_v += grad_v_tmp grad_gama += grad_gama_tmp grad_w += grad_w_tmp grad_theta += grad_theta_tmp # 更新权重 w += grad_w / m theta += grad_theta / m v += grad_v / m gama += grad_gama / m # 计算loss值 b = torch.matmul(x, v) - gama b = torch.sigmoid(b) a = torch.matmul(b, w) - theta y_out = torch.sigmoid(a) loss[t] = 0.5 * torch.sum(torch.pow(y_out - y, 2)) / m 绘制loss曲线 12345plt.figure( )plt.plot(loss)plt.xlabel(&#x27;Number of iterations&#x27;)plt.ylabel(&#x27;Mean square error loss&#x27;)plt.show( ) 完整代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import numpy as npimport torchfrom matplotlib import pyplot as pltm, d, q, l = 32, 20, 10, 2# - m 样本数# - d 输入维度# - q 隐藏层神经元维数# - l 输出层神经元维数# 输入数据和输出数据x = torch.randn(m, d) # 输入数据y = torch.randn(m, l) # 输出数据# 两层权重，以及初始化v = torch.randn(d, q) # 第一层gama = torch.randn(q)w = torch.randn(q, l) # 第二层theta = torch.randn(l)# 步长eta = 0.05# 每次迭代后计算损失函数值，以备画图使用loss = np.zeros(500)# 进行500轮训练for t in range(500): # print(&#x27;当前训练批次:&#123;&#125;&#x27;.format(t)) # 权重梯度初始化 grad_v = torch.zeros(d, q) grad_gama = torch.zeros(q) grad_w = torch.zeros(q, l) grad_theta = torch.zeros(l) # 遍历数据集 for i in range(m): ############################ # 前向传播 # 第一层 b = torch.matmul(x[i, :], v) - gama b = torch.sigmoid(b) # 第二层 a = torch.matmul(b, w) - theta y_out = torch.sigmoid(a) ############################ # 反向传播 # 计算梯度 g = -(y_out - y[i, :]) * y_out * (1 - y_out) g = g.unsqueeze(dim=0) # (1, l) b = b.unsqueeze(dim=1) # (q, 1) grad_w_tmp = eta * torch.matmul(b, g) grad_theta_tmp = -eta * g grad_theta_tmp = grad_theta_tmp.squeeze(dim=0) g = g.squeeze(dim=0) # (,l) b = b.squeeze(dim=1) # (q,) e = b * (1 - b) * torch.matmul(w, g) grad_v_tmp = eta * torch.matmul(x[i, :].unsqueeze(dim=1), e.unsqueeze(dim=0)) grad_gama_tmp = -eta * e # 将各个样本的梯度加在一起 grad_v += grad_v_tmp grad_gama += grad_gama_tmp grad_w += grad_w_tmp grad_theta += grad_theta_tmp # 更新权重 w += grad_w / m theta += grad_theta / m v += grad_v / m gama += grad_gama / m # 计算loss值 b = torch.matmul(x, v) - gama b = torch.sigmoid(b) a = torch.matmul(b, w) - theta y_out = torch.sigmoid(a) loss[t] = 0.5 * torch.sum(torch.pow(y_out - y, 2)) / m# 绘制loss曲线图plt.figure( )plt.plot(loss)plt.xlabel(&#x27;Number of iterations&#x27;)plt.ylabel(&#x27;Mean square error loss&#x27;)plt.show( )"},{"title":"第三章第三次作业","date":"2022-10-15T12:16:55.807Z","updated":"2022-10-15T12:16:55.803Z","comments":true,"path":"python-homework/chapter3_3/index.html","permalink":"https://pyxblog.cn/python-homework/chapter3_3/index.html","excerpt":"","text":"学生姓名：庞宇轩 学号：2019302110354 使用pytorch，编写全连接神经网络，实现对MNIST手写体数据集的识别，要求：每一轮训练后给出测试集识别的准确率；训练结束后，给出测试集准确率，并随机展示16个样本，输出他们的识别结果； 导入所需的库函数 12345678910import timeimport torchimport torch.nn as nnimport torch.optim as optimfrom PIL import Imagefrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision import transforms as Tfrom torchvision.utils import make_grid, save_image 编写网络 12345678910class Net(nn.Module): def __init__(self): super(Net, self).__init__( ) self.fc = nn.Linear(28 * 28, 10) def forward(self, x): x = x.view(-1, 28 * 28) x = self.fc(x) return x 初始化 1234567891011121314151617181920212223# 归一化tranform = T.Compose([T.ToTensor( ), T.Normalize((0.1307,), (0.3081,))])# 加载数据集dataset_mnist = datasets.MNIST(&#x27;data/&#x27;, download=True, train=False, transform=tranform)# 划分训练集(0.8)和测试集(0.2)size_train = int(0.8 * len(dataset_mnist))size_test = len(dataset_mnist) - size_traindataset_train, dataset_test = torch.utils.data.random_split(dataset_mnist, [size_train, size_test], generator=torch.Generator( ).manual_seed(0))# 创建dataloaderdataloader_train = DataLoader(dataset_train, shuffle=True, batch_size=16)dataloader_test = DataLoader(dataset_test, shuffle=True, batch_size=16)net = Net( ) # 网络结构criterion = nn.CrossEntropyLoss( ) # 损失函数optimizer = optim.SGD(net.parameters( ), lr=0.001, momentum=0.9) # SGD优化epochs = 5 # 训练次数 下载数据集时，由于网络原因一直下载失败，解决方案为直接进入网址http://yann.lecun.com/exdb/mnist/单独下载四个.gz文件： 存放在data/MNIST/raw路径下即可正常运行。 训练 1234567891011121314151617181920212223242526time_start = time.time( ) # 记录训练开始的时间# 训练for epoch in range(epochs): training_loss = 0 for i, data in enumerate(dataloader_train, 0): inputs, labels = data optimizer.zero_grad( ) outputs = net(inputs) loss = criterion(outputs, labels) loss.backward( ) optimizer.step( ) training_loss += loss.item( ) # 测试 correct = 0 total = 0 with torch.no_grad( ): for data in dataloader_train: inputs, labels = data outputs = net(inputs) _, predicted = torch.max(outputs, 1) total += labels.size(0) correct += (predicted == labels).sum( ).item( ) print(&#x27;epoch:&#x27;, epoch, &#x27; | loss:&#x27;, training_loss, &#x27; | train_accuracy:&#x27;, correct / total)time_end = time.time( )print(&#x27;training_time_cost: &#123;&#125; s&#x27;.format(time_end - time_start)) 测试 1234567891011121314151617181920212223# 测试correct = 0total = 0with torch.no_grad( ): for data in dataloader_test: inputs, labels = data outputs = net(inputs) _, predicted = torch.max(outputs, 1) total += labels.size(0) correct += (predicted == labels).sum( ).item( )print(&#x27;test_accuracy: &#x27;, correct / total)# 抽取展示测试样本dataiter_test = iter(dataloader_test)images_data, labels = next(dataiter_test)image = make_grid(images_data, 4)save_image(image, &#x27;image.png&#x27;)with torch.no_grad( ): _, predicts = torch.max(net(images_data), 1)print(&#x27;labels: &#x27;, labels)print(&#x27;predicts: &#x27;, predicts)Image.open(&#x27;image.png&#x27;).show( ) 输出 123456789epoch: 0 | loss: 279.85742995142937 | train_accuracy: 0.9065epoch: 1 | loss: 166.11202605813742 | train_accuracy: 0.919125epoch: 2 | loss: 148.41587802395225 | train_accuracy: 0.923125epoch: 3 | loss: 136.94742159731686 | train_accuracy: 0.9245epoch: 4 | loss: 130.63263080082834 | train_accuracy: 0.929625training_time_cost: 9.481114864349365 stest_accuracy: 0.9085labels: tensor([1, 4, 8, 4, 1, 6, 0, 8, 3, 8, 1, 7, 0, 9, 6, 6])predicts: tensor([1, 4, 8, 4, 1, 6, 0, 8, 3, 8, 1, 7, 0, 0, 6, 6]) 完整代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import timeimport torchimport torch.nn as nnimport torch.optim as optimfrom PIL import Imagefrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision import transforms as Tfrom torchvision.utils import make_grid, save_imageclass Net(nn.Module): def __init__(self): super(Net, self).__init__( ) self.fc = nn.Linear(28 * 28, 10) def forward(self, x): x = x.view(-1, 28 * 28) x = self.fc(x) return x# 归一化tranform = T.Compose([T.ToTensor( ), T.Normalize((0.1307,), (0.3081,))])# 加载数据集dataset_mnist = datasets.MNIST(&#x27;data/&#x27;, download=True, train=False, transform=tranform)# 划分训练集(0.8)和测试集(0.2)size_train = int(0.8 * len(dataset_mnist))size_test = len(dataset_mnist) - size_traindataset_train, dataset_test = torch.utils.data.random_split(dataset_mnist, [size_train, size_test], generator=torch.Generator( ).manual_seed(0))# 创建dataloaderdataloader_train = DataLoader(dataset_train, shuffle=True, batch_size=16)dataloader_test = DataLoader(dataset_test, shuffle=True, batch_size=16)net = Net( ) # 网络结构criterion = nn.CrossEntropyLoss( ) # 损失函数optimizer = optim.SGD(net.parameters( ), lr=0.001, momentum=0.9) # SGD优化epochs = 5 # 训练次数time_start = time.time( ) # 记录训练开始的时间# 训练for epoch in range(epochs): training_loss = 0 for i, data in enumerate(dataloader_train, 0): inputs, labels = data optimizer.zero_grad( ) outputs = net(inputs) loss = criterion(outputs, labels) loss.backward( ) optimizer.step( ) training_loss += loss.item( ) # 测试 correct = 0 total = 0 with torch.no_grad( ): for data in dataloader_train: inputs, labels = data outputs = net(inputs) _, predicted = torch.max(outputs, 1) total += labels.size(0) correct += (predicted == labels).sum( ).item( ) print(&#x27;epoch: &#x27;, epoch, &#x27; | loss: &#x27;, training_loss, &#x27; | train_accuracy: &#x27;, correct / total)time_end = time.time( )print(&#x27;training_time_cost: &#123;&#125; s&#x27;.format(time_end - time_start))# 测试correct = 0total = 0with torch.no_grad( ): for data in dataloader_test: inputs, labels = data outputs = net(inputs) _, predicted = torch.max(outputs, 1) total += labels.size(0) correct += (predicted == labels).sum( ).item( )print(&#x27;test_accuracy: &#x27;, correct / total)# 抽取展示测试样本dataiter_test = iter(dataloader_test)images_data, labels = next(dataiter_test)image = make_grid(images_data, 4)save_image(image, &#x27;image.png&#x27;)with torch.no_grad( ): _, predicts = torch.max(net(images_data), 1)print(&#x27;labels: &#x27;, labels)print(&#x27;predicts: &#x27;, predicts)Image.open(&#x27;image.png&#x27;).show( )"},{"title":"第四章第一次作业","date":"2022-10-23T12:23:05.904Z","updated":"2022-10-23T12:23:05.897Z","comments":true,"path":"python-homework/chapter4_1/index.html","permalink":"https://pyxblog.cn/python-homework/chapter4_1/index.html","excerpt":"","text":"学生姓名：庞宇轩 学号：2019302110354 使用pytorch，继承nn.Module，编写二维立体卷积层，要求将：输入通道数 channels_in输出通道，即滤波器个数 channels_out卷积核尺寸 kernel_size补零个数 padding滑动步长 stride作为参数，并验证所编写卷积层的效果：输入任意3通道图片，并初始化卷积层参数为输出单通道的特征图并以图片形式展示，例如下图: 导入所需的库函数 123import numpy as npimport torch.nn as nnfrom PIL import Image # 储存图片 编写网络 传参 12345678def __init__(self, channels_in, channels_out, kernel_size, stride, padding): super(conv_2d, self).__init__( ) self.channels_in = channels_in self.channels_out = channels_out self.kernel_size = kernel_size self.stride = stride self.padding = padding self.kernel = np.ones(shape=(kernel_size, kernel_size)) 设置卷积层参数 1234def set_kernel(self): self.kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]) 函数中，直接将卷积层参数设置为作业要求，如需变更，可将函数改为 12def set_kernel(self, kernel): self.kernel = kernel 然后在主函数中设置即可。 卷积计算 12345678910111213141516171819202122232425262728293031def forward(self, x): # 创建图像容器 img_data = np.zeros(shape=(len(x[:, 0, 0]) + self.padding * 2, len(x[0, :, 0]) + self.padding * 2, self.channels_in)) # 在padding内填充图像数据 img_data[ self.padding:len(x[:, 0, 0]) + self.padding, self.padding:len(x[0, :, 0]) + self.padding, :] = x output_width = int((len(x[:, 0, 0]) - self.kernel_size + self.padding * 2) / self.stride + 1) output_height = int((len(x[0, :, 0]) - self.kernel_size + self.padding * 2) / self.stride + 1) img_output = np.zeros(shape=(output_width, output_height, self.channels_out)) for channel_out in range(self.channels_out): for w in range(output_width): for h in range(output_height): for channel_in in range(self.channels_in): tmp = img_data[ w * self.stride: w * self.stride + self.kernel_size, h * self.stride: h * self.stride + self.kernel_size, channel_in ] img_output[w, h, channel_out] += np.sum(tmp * self.kernel) / self.channels_in img_output = np.maximum(img_output, 0) # 处理负数 return img_output 二维卷积完整代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class conv_2d(nn.Module): def __init__(self, channels_in, channels_out, kernel_size, stride, padding): super(conv_2d, self).__init__( ) self.channels_in = channels_in self.channels_out = channels_out self.kernel_size = kernel_size self.stride = stride self.padding = padding self.kernel = np.ones(shape=(kernel_size, kernel_size)) def set_kernel(self): self.kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]) def forward(self, x): # 创建图像容器 img_data = np.zeros(shape=(len(x[:, 0, 0]) + self.padding * 2, len(x[0, :, 0]) + self.padding * 2, self.channels_in)) # 在padding内填充图像数据 img_data[ self.padding:len(x[:, 0, 0]) + self.padding, self.padding:len(x[0, :, 0]) + self.padding, :] = x output_width = int((len(x[:, 0, 0]) - self.kernel_size + self.padding * 2) / self.stride + 1) output_height = int((len(x[0, :, 0]) - self.kernel_size + self.padding * 2) / self.stride + 1) img_output = np.zeros(shape=(output_width, output_height, self.channels_out)) for channel_out in range(self.channels_out): for w in range(output_width): for h in range(output_height): for channel_in in range(self.channels_in): tmp = img_data[ w * self.stride: w * self.stride + self.kernel_size, h * self.stride: h * self.stride + self.kernel_size, channel_in ] img_output[w, h, channel_out] += np.sum(tmp * self.kernel) / self.channels_in img_output = np.maximum(img_output, 0) # 处理负数 return img_output 实验 12345678910conv = conv_2d(channels_in=3, channels_out=1, kernel_size=3, stride=1, padding=1)conv.set_kernel( )input_img = Image.open('ANIA.png')output_img = conv(np.array(input_img))output_img = np.squeeze(output_img)output_img = Image.fromarray(np.uint8(output_img))output_img.save('ANIA_output.png') 输出 输入图像 ANIA.png 输出图像 ANIA_output.png 完整代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import numpy as npimport torch.nn as nnfrom PIL import Imageclass conv_2d(nn.Module): def __init__(self, channels_in, channels_out, kernel_size, stride, padding): super(conv_2d, self).__init__( ) self.channels_in = channels_in self.channels_out = channels_out self.kernel_size = kernel_size self.stride = stride self.padding = padding self.kernel = np.ones(shape=(kernel_size, kernel_size)) def set_kernel(self): self.kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]) def forward(self, x): # 创建图像容器 img_data = np.zeros(shape=(len(x[:, 0, 0]) + self.padding * 2, len(x[0, :, 0]) + self.padding * 2, self.channels_in)) # 在padding内填充图像数据 img_data[ self.padding:len(x[:, 0, 0]) + self.padding, self.padding:len(x[0, :, 0]) + self.padding, :] = x output_width = int((len(x[:, 0, 0]) - self.kernel_size + self.padding * 2) / self.stride + 1) output_height = int((len(x[0, :, 0]) - self.kernel_size + self.padding * 2) / self.stride + 1) img_output = np.zeros(shape=(output_width, output_height, self.channels_out)) for channel_out in range(self.channels_out): for w in range(output_width): for h in range(output_height): for channel_in in range(self.channels_in): tmp = img_data[ w * self.stride: w * self.stride + self.kernel_size, h * self.stride: h * self.stride + self.kernel_size, channel_in ] img_output[w, h, channel_out] += np.sum(tmp * self.kernel) / self.channels_in img_output = np.maximum(img_output, 0) # 处理负数 return img_outputconv = conv_2d(channels_in=3, channels_out=1, kernel_size=3, stride=1, padding=1)conv.set_kernel( )input_img = Image.open('ANIA.png')output_img = conv(np.array(input_img))output_img = np.squeeze(output_img)output_img = Image.fromarray(np.uint8(output_img))output_img.save('ANIA_output.png')"}],"posts":[{"title":"信通小白杨生涯规划","slug":"career-planning","date":"2022-10-16T11:32:08.000Z","updated":"2022-10-17T04:16:02.217Z","comments":true,"path":"2022/10/16/career-planning/","link":"","permalink":"https://pyxblog.cn/2022/10/16/career-planning/","excerpt":"职业生涯规划的重点在于规划，我认为本科期间的生涯规划需要包含这样几个步骤： 明确自己的目标，比如： 读研，本专业或跨专业，保研或考研，留本校或向梦想学校努力； 就业，本专业或跨专业，走仕途或成为某个行业的打工人 出国，备选的国家或地区 回家啃老 探索对于自己的目标来说，性价比高的事有哪些： 课内学习，需要达到什么水平，需要重点学习哪个或哪些方面的课程，是否需要选修某些方面的课程或双学位 科研，是否要从事科研工作，科研的“大领域”和“小领域”，期望中的科研成果 竞赛，参加什么竞赛，对奖项的预期 实习，去什么样的企业/岗位，花多长时间，以积累经验还是转正为目标 实践，包括学生工作、社团、志愿服务等 影响“性价比”的因素，可能包括：对达成目标的帮助大小，完成的难度，本身的兴趣，需要付出的时间、精力和经济成本等。 按照性价比从高到低，合理安排你的生活 我认为所谓的“规划”，并不是要求你完全看清前方的道路，计划好未来的每一步，而是要培养自己的规划意识和做事的目的性。具体来说，是要你有目标地走好大学生活的每一步，在机遇到来前做好自己能做到的最充分的准备。大学生活丰富多彩且无拘无束，如果生活缺乏目的性，快活四年很可能会导致遗憾终生。除非你可以随心所欲玩四年，然后回家继承巨额家产。","text":"职业生涯规划的重点在于规划，我认为本科期间的生涯规划需要包含这样几个步骤： 明确自己的目标，比如： 读研，本专业或跨专业，保研或考研，留本校或向梦想学校努力； 就业，本专业或跨专业，走仕途或成为某个行业的打工人 出国，备选的国家或地区 回家啃老 探索对于自己的目标来说，性价比高的事有哪些： 课内学习，需要达到什么水平，需要重点学习哪个或哪些方面的课程，是否需要选修某些方面的课程或双学位 科研，是否要从事科研工作，科研的“大领域”和“小领域”，期望中的科研成果 竞赛，参加什么竞赛，对奖项的预期 实习，去什么样的企业/岗位，花多长时间，以积累经验还是转正为目标 实践，包括学生工作、社团、志愿服务等 影响“性价比”的因素，可能包括：对达成目标的帮助大小，完成的难度，本身的兴趣，需要付出的时间、精力和经济成本等。 按照性价比从高到低，合理安排你的生活 我认为所谓的“规划”，并不是要求你完全看清前方的道路，计划好未来的每一步，而是要培养自己的规划意识和做事的目的性。具体来说，是要你有目标地走好大学生活的每一步，在机遇到来前做好自己能做到的最充分的准备。大学生活丰富多彩且无拘无束，如果生活缺乏目的性，快活四年很可能会导致遗憾终生。除非你可以随心所欲玩四年，然后回家继承巨额家产。 自我介绍 2019级广播电视工程2班班长 中传青年五四奖章「科创新秀」得主 保送至中国科学院计算机网络信息中心 我的个人经历比较偏向在课内学习、科研、竞赛和实践中均取得一定的成果，然后保研，因此我给出的有关生涯规划的分享也会大体围绕着这个话题去展开。当然，我也会尽我所能去解释一些未来大家可能会遇到的事件和活动，给出更加普适性的建议。 我的生活 大一学年--上学期 线下教学 课内学习认真学习C/C++程序设计课程科研与老师沟通，了解科研的培养模式和可以做的课题方向竞赛参与学校ACM培训及每周的训练赛（一种基于C/C++的算法竞赛）参加第11届蓝桥杯C/C++程序设计竞赛，获得北京市二等奖实践担任班长加入职业生涯规划工作室，即现在的信通团委实践部，参与2019届毕业生就业质量报告编写工作主动协助辅导员处理日常工作提交入党申请 大一学年--下学期 线上教学 课内学习认真学习C/C++程序设计课程，在CSDN平台为同学撰写课程同步教程与几位同班同学结伴学习，线上打卡，保持学习状态选修课程“算法入门与应用实践”，巩固算法竞赛基础科研无竞赛继续参与学校ACM培训及每周的训练赛实践担任班长成为入党积极份子，上党课 大一学年--总结 打好成绩上的基础通过课内学习、课后整理、做多习题和参与ACM培训，提高编程能力计划以算法竞赛为未来的主要竞赛初步接触科研积极入党 大二学年--上学期 线下教学 课内学习认真学习数据结构与算法，继续在CSDN平台撰写课程同步教程科研入选首届MCL大学生学术训练季，从事科研基础方面的学习，包括机器学习与深度学习基础、英文文献阅读、组会汇报等，从事推荐系统领域的学习入选第二届创新人才“菁英班”，师从广播电视工程系主任杨盈昀教授，开始从事智能图像与视音频处理领域的研究工作竞赛学习Matlab与数学建模，与两位师姐组队在第十届APMCM亚太地区大学生数学竞赛中获得二等奖实践担任班长随着职业生涯规划工作室的改组，加入信通团委实践部，担任委员，参与2020届毕业生就业质量报告编写工作 大二学年--下学期 线下教学 课内学习保持绩点与专业排名科研作为负责人申报大创项目《基于三重态域翻译网络和超分重建的老照片修复》，获国家级立项为筹备“互联网+”大赛，开始整理申请知识产权竞赛作为负责人参与第七届中国国际“互联网+”大学生创新创业大赛，获得北京市一等奖、全国铜奖参加第12届蓝桥杯C/C++程序设计竞赛，获得北京市三等奖实践担任班长参与信通团委实践部日常工作 大二学年--总结 维持成绩上的优势排名维持代码上的优势能力，继续参与算法竞赛，但不作为主要精力点开始参与科研工作，将科研项目与创新创业结合，将创新创业作为科研和竞赛合一的精力投入点，获得代表性成果积极入党 大三学年--上学期 线下教学 课内学习摆烂科研完成大创项目的研究工作筹备自己的论文投稿与发表竞赛带领创新创业项目参与其他双创类竞赛陆续参与若干算法、数学、外语、艺术设计等领域的小比赛，培养综合能力实践担任班长开始参与线上志愿服务 大三学年--下学期 线上教学 课内学习摆烂科研大创项目《基于三重态域翻译网络和超分重建的老照片修复》优秀结项，入选第十五届全国大学生创新创业年会改革成果项目作为负责人申报大创项目《拾忆——老旧影像修复及内容互动社区》再次获得国家级评级竞赛作为负责人参与第八届中国国际“互联网+”大学生创新创业大赛，获得北京市一等奖，再次入围全国总决赛作为负责人参与第九届“创青春”中国青年创新创业大赛，获得全国铜奖参加第13届蓝桥杯C/C++程序设计竞赛，获得北京市二等奖实践担任班长参与线上志愿服务，累计参加项目148个，志愿时长622.5小时其他参与外校夏令营选拔 大三学年--总结 课内学习摆烂，大家不要学我创新创业竞赛拿大二做的项目吃老本，再次取得了不错的成果继续参与算法竞赛，维持代码熟练度参与夏令营，推免至外校积极参与线上志愿服务，为本校推免资格做准备 名词扫盲 综测 综测即“综合测评”，每年测算一次，由以下几个部分组成： 德育测评，包括遵守校规校纪情况、班主任打分和宿舍卫生检查得分等影响因素，分数一般在1100左右 智育测评，由本专业所有学生都学的必修限选课成绩决定，分数一般在4000～5000之间，在整个综测中起定档的作用 体育测评，一般是体测成绩直接加上 实践与创新能力测评，包括科研、竞赛、学生工作等影响因素，也就是我们常说的综测加分，上限200分，帮你实现档内提升甚至跨档 详细的计算规则可以参考今年的文件： 信通学院综测计算规则 点击进入下载页面 综测主要影响： 各类奖学金的评定 创新人才“菁英班”的选拔 保研时的门槛 门槛很低约等于没有 日常化的排名，比如想参与老师的科研工作，综测就代表了你的综合能力 绩点 绩点即GPA，如果综测反应的是学生的综合能力，那么绩点主要反映的就是学生的课内学习水平。 我校的绩点计算规则采用北京大学的算法，满绩点为4.00： 单门课程， 总单门课程课程学分课程学分 绩点分为“必修课GPA”和“必修限选课GPA”，前者只计算必修课，后者计算所有必修课和限选课，任选课不计入绩点。一般情况下，必修限选课GPA具有更高的出场率。 你可以在教务系统的「我的培养方案（本科）」中查看现在和未来将要修读的课程及每门课程的性质，在可信电子凭证中查看自己的绩点和绩点计算规则。 前期与成绩相关的衡量指标以综测为主，绩点一般情况下不会用到 ，用到绩点的主要场景为： 保研 时，一般类赛道直接将计入总成绩 保研外校 时，非常看重专业绩点排名 出国 时，对绩点的要求较高 科研与竞赛 可以参考我给你们的师哥师姐写的分享文章，其中提到了科研竞赛对我们的实际作用和大概的参与模式： 本科期间的科研&amp;竞赛 点击查看详情 我想把这篇文章的开头拿出来单独说一下： 科研竞赛在很多人眼中都有一定的“神圣性”：只有课内学习完全没问题的人，才有余力去参与科研和竞赛。但我认为，它其实与选修、辅修类似，只是你在安排时间精力时的一个选项。科研竞赛可以为我们带来很多实质性的好处，无论是对于综测、保研、考研，还是实习、就业、出国，成绩都只是门槛性的参考，而科研竞赛则会为你的简历增添很多光彩。所以希望看完这篇分享后，不仅是排名比较靠前的同学，而是能有更多的同学去尝试接触某一领域的学术研究，或与朋友组队参加一些竞赛，为自己的大学生活取得一些实打实的成果。 四六级 对于毕业来说，要求是至少要通过四级； 对于保研来说，最好可以通过六级，因为： 本校推免资格计算过程中，通过六级可以为你带来一定的加分 外校夏令营和预推免考核，一般都会对六级有一定的要求，如果六级能考到500以上，就可以达到绝大多数的院校门槛 大部分研究生院校都有类似的规定：本科期间六级分数达到xxx，研究生期间免修英语课程，清华大学的分数要求是550，也就是说如果六级能考到550以上，这辈子都没人逼你学英语了。 可以在教务系统的「学业完成查询」模块中，查看培养方案对英语的要求，2019级的要求如下：大学英语-基础，需修8学分，其中大一上学期英语课程4分，大一下学期英语课程4分大学英语-拓展，需修4学分，其中：可以通过大学英语拓展课修学分，一门课2分可以通过四六级修学分，通过四级2分，通过六级2分 四六级考试一般在每年的6月、12月组织，在我校，第一次参与四六级考试的机会是大一下学期，前提是没有因为疫情而未返校。 需要注意的是，我校每次四六级考核的名额都非常有限，需要大家在开放报名的时候抢名额，我有一个专业第一的朋友，因为没抢到六级考试名额，没有通过六级考试，保研受到了很大的影响。此外，如今的疫情反反复复，谁也不知道下个学期是否还有机会线下教学，所以四六级如果计划考，一定要尽早，不要拖。 志愿服务 志愿服务的作用主要有三点： 某些评奖评优的门槛，如优秀团干部，需要志愿时长不低于20小时 入党的门槛，从入党积极分子到发展对象，需要志愿时长不低于8小时 本校推免资格评定的时候，志愿时长可以直接计入加分，最多可以加200小时 疫情期间，线下志愿服务的机会非常少，且一般都挺累，可以多参加一些线上的志愿服务工作。 学生工作 整体看来，相比于课内学习和科研竞赛，学生工作是一件性价比稍低的事，可以作为学习生活的一部分，但不建议作为主要的精力投入点，也不建议太过深入。 担任班委，可以为你带来更高的同学支持度和一定的综测加分 加入学院学生会，可以为你带来一定的综测加分（一般少于班委）和额外的评优名额（一般是给部长） 加入学校学生会或相关学生组织累且几乎没用 加入部分职能部门，会产生附加价值，比如学会公众号推文排版、Photoshop基本使用等技能，或掌握相关的信息，比如在信通团委实践部了解学院历年本硕博毕业生的就业情况和掌握第一手的招聘信息 我高中期间有着较为丰富的学生工作经验，因而会更多地去考虑学生工作带来的实质性好处，对没有接触过的同学来说，积极参与学生工作，无疑会提升你的办公能力和人际交往能力，这在未来的就业中也是颇为重要的。对参与学生工作的同学来说，有两点需要注意：在其位就要谋其政，即使怀着功利的动机去参与学生工作，也要对自己的工作给予充分的主动和负责，可以不去参与，但参与了就不要摆烂；不因被需要而沉迷，不因被误解而恼怒，保持充分的清醒，只做自己该做的事，做好自己该做的事； 保研 保研，也就是推免（推荐免试攻读研究生），是很多学生的“最高理想”。保研分为两部分： 通过夏令营、预推免或九推，获得目标院校的offer 获得本校的推免资格 我校的推免分为五个赛道，其中一个赛道又分为八个子项目，每个人只能选择一个赛道（项目）参与竞争，考察课内学习、科研、竞赛、实践等各个领域的综合能力。不同赛道的考察侧重点不同，也就是说即使你的成绩并不突出，但在某些方面骨骼惊奇，也有很大的希望可以保研。 详细的推免规则可以查看这篇文章： 2022推免分享——本校篇 点击查看 2022年我院实际推免62人，其中多数同学的绩点在3.8左右，但3.6左右甚至3.4左右的同学也有不少，也就是说只要做好合理的规划，发挥出自己在某一方面的优势，同时没有特别明显的短板，就有很大的机会能够保研成功。大一上学期的时间点开始准备保研可能有点早，但可以通过对保研要求的分析，辅助制定对于未来学习生活的规划，寻找兴趣和含金量之间的交集。 奖学金 本科期间可以获得的奖学金，主要分为国奖、校奖、院奖和社会捐助奖学金四种，其中： 国奖分为国家奖学金和国家励志奖学金，需要体测达到80分以上，以综测为评选标准： 国家奖学金金额为8000，在信通学院，只有大三上学期可以评选一次，大专业有两个名额，小专业只有一个名额； 国家励志奖学金金额为5000，每年都可以评选，但只有贫困生可以参与评选； 国家奖学金和国家励志奖学金不可兼得，国奖和其他类型的奖学金基本都不可以兼得； 校奖分为校级一、二、三等奖，单项奖学金和校励志奖学金，需要体测达到80分以上： 校级一、二、三等奖金额依次为3000、2000和1500，以综测为评选标准； 校级单项奖学金金额为500，包括道德风尚单项、科研竞赛单项、体育竞赛单项等，个人申请； 校励志奖学金金额为1500，不可和国家励志奖学金兼得，以综测为评选标准； 院奖分为院一、院二和单项奖学金，体测仅需60分以上即可，不与国奖和校奖兼得（除校单项奖之外）： 院级一、二等奖金额依次为1500和1000，以综测为评选标准； 院级单项金额不定，分为： 学习进步单项奖，考察各专业同学年两个学期/两个学年之间的排名上升幅度； 科研竞赛单项奖，获得科研竞赛奖项的同学可以申请； 学生工作单项奖，一般是每个班给一个班长； 指定企业的实习单项奖，一般拿不到； 社会捐助奖学金一般会在学生工作处官网的通知公告栏发布通知和获奖公示，大部分社会捐助奖学金对体测没有要求，评审过程一般是学校将名额分配给各学院，由各学院自行评审，少部分可以自行申请，获奖难度较高，一般一个学院能有个位数个名额，或者全校只有个位数个名额，我有所了解的社会捐助奖学金包括： 索尼卓越奖学金，金额6000，信通学院大一有1个名额，大二有2个名额，大三不知道（可以看一下往年的获奖情况），理论上来说获奖同学有去索尼实习的机会（虽然我到现在都没听说什么实习的事），评选主要看综测，不与国奖和校奖兼得； 得到读书奖学金，金额2500，面向全校本科生，共评选40人，通过个人报名的形式评选，需要提交一篇读书笔记作为评选依据，参考2021年的得到读书奖学金通知； 中国电信奖学金，金额5000，面向全校本硕博，共评选2人，通过个人报名的形式评选，貌似是团中央颁发的奖学金，相关通知会在“传媒团英”公众号发布，可以去搜索查看往年的通知公示； 创新创业奖学金，特等奖金额10000，优秀奖金额5000，分为创新奖学金和创业奖学金，貌似没有体测的要求，但对信通学院来说好像只面向大四的学生选拔，主要评选在创新或创业方面有突出成果的同学，学院推荐后学校选拔审核，相关通知和公示参考学生工作处官网； 广电总台奖学金，金额2500，要求获得校级三好学生或优秀学生干部，且获得校级一、二、三等奖学金（隐性要求体测80以上），每专业1个名额，按综测评选，基本上就是直接给校一第一位； 总体来看，奖学金和综测有着密不可分的关系，好好搞综测=好好搞钱，同时，体测80分也是一个非常大的门槛。 大创 大创是一项参与度比较高的活动，也是一项非常容易引发焦虑的活动。大创全称“大学生创新创业训练计划”，由3～5位学生组成一个小团队（1位学生担任项目负责人），在一位指导老师的带领下对某一问题进行为期一年的研究，形成一定的成果。 大创的整体流程分为立项、中期审核和结项三个步骤，一般是每年的4月份开始申报，第二年的4月份结项。 大创的立项分为三个等级：国家级、北京市级和校级，其中仅国家级有经费（10000元），北京市级和校级没有经费。 大创的结项分为四个等级：优秀、良好、合格和不合格。 大创立项与结项要求 点击进入下载页面 大创参与周期长，投入精力高，但在信通学院，大创本身是个弟弟作用非常有限： 综测 totally 不认可； 保研时拿到加分的难度很大，且拿到的加分约等于没有； 因此，大创的核心价值在于它的附加价值： 利用大创项目参与“互联网+”、“挑战杯”等创新创业大赛，认真做好一个项目，可以重复参加很多创新创业大赛，堪称性价比之王； 利用大创产出知识产权，包括计算机软件著作权、国家发明专利和相关的论文； 利用大创混进导师的课题组，参与科研，一个大创小组最多可以包含5位成员，而大创的起点一般都是一个导师带一个学生，再由这个学生去找四个学生，这就为成绩不够理想的同学提供了参与科研工作的机会，也为低年级的师弟师妹创造了很多提前接触科研的机遇； 利用国家级大创的经费买点网课和硬件设备，或者报销申请知识产权产生的费用； 参考规划 对自己有较高要求，希望拿到保研资格的师弟师妹，可以参考这样的目标： 认真对待课内学习，保持绩点在3.7-3.9之间，每门课的成绩尽量保持在80分之上； 参与一个感兴趣课题的研究工作，积累一定的科研经验，掌握一些科研过程中的技能，并产出属于自己的科研成果； 认真准备一类竞赛，推荐数学建模或创新创业（加分高，综测和保研都用得到），取得自己的代表性成果； 尽早通过大学英语四六级测试； 积极参与线上志愿服务工作，积累志愿时长； 有任何问题可以直接在评论区中提出！","categories":[{"name":"分享","slug":"分享","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/"},{"name":"日常","slug":"分享/日常","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/%E6%97%A5%E5%B8%B8/"}],"tags":[]},{"title":"竞赛列表（待施工）","slug":"competitions","date":"2022-10-05T08:17:35.000Z","updated":"2022-10-17T04:17:09.988Z","comments":true,"path":"2022/10/05/competitions/","link":"","permalink":"https://pyxblog.cn/2022/10/05/competitions/","excerpt":"分享一些我参与过或了解过的竞赛，供大家参考。","text":"分享一些我参与过或了解过的竞赛，供大家参考。 前情提要有关竞赛的作用，可以参考之前的分享：本科期间的科研&amp;竞赛https://pyxblog.cn/2022/10/03/scientific-research-and-competition/回顾一下我们选择竞赛的标准：对于综测，要选择非赢利机构主办的比赛，类似xxx网、xxx公司都不行，xxx学会、xxx协会一般可以；对于推免，要按照文件给出的列表进行选择，列表之外的竞赛，即使有着很高的行业认可，也不会加分；总体上，还是要以自己的兴趣为导向，在考虑含金量的时候，也要保证自己不厌烦这个领域，只有这样才有学的下去的可能； 创新创业 中国国际“互联网+”大学生创新创业大赛 主办方：教育部 全国大学生创业服务网https://cy.ncss.cn/ “创青春”中国青年创新创业大赛 主办方：共青团中央 创青春官网http://cqc.casicloud.com/ “挑战杯”全国大学生课外学术科技作品竞赛（大挑） 主办方：共青团中央 挑战杯系列竞赛http://bj.tiaozhanbei.net/ “挑战杯”中国大学生创业计划竞赛（小挑） 主办方：共青团中央 挑战杯系列竞赛http://bj.tiaozhanbei.net/ 全国大学生电子商务创新、创意及创业挑战赛 主办方：教育部 三创赛http://www.3chuang.net/ 全国大学生创新创业年会","categories":[{"name":"分享","slug":"分享","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/"},{"name":"日常","slug":"分享/日常","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/%E6%97%A5%E5%B8%B8/"}],"tags":[]},{"title":"本科期间的科研&竞赛","slug":"scientific-research-and-competition","date":"2022-10-03T00:23:59.000Z","updated":"2022-10-17T00:35:07.957Z","comments":true,"path":"2022/10/03/scientific-research-and-competition/","link":"","permalink":"https://pyxblog.cn/2022/10/03/scientific-research-and-competition/","excerpt":"分享一些我在本科期间参与科研、竞赛的经历，包括科研的主要内容、适应人群、如何开始科研、科研成果的形式，竞赛的种类、认可度以及二者对我们的作用等，供师弟师妹们参考。 说在最前面科研竞赛在很多人眼中都有一定的“神圣性”：只有课内学习完全没问题的人，才有余力去参与科研和竞赛。我认为它其实与选修、辅修类似，只是你在安排时间精力时的一个选项。科研竞赛可以为我们带来很多实质性的好处，无论是对于综测、保研、考研，还是实习、就业、出国，成绩都只是门槛性的参考，而科研竞赛则会为你的简历增添很多光彩。所以希望看完这篇分享后，不仅是排名比较靠前的同学，而是能有更多的同学去尝试接触某一领域的学术研究，或与朋友组队参加一些竞赛，为自己的大学生活取得一些实打实的成果。","text":"分享一些我在本科期间参与科研、竞赛的经历，包括科研的主要内容、适应人群、如何开始科研、科研成果的形式，竞赛的种类、认可度以及二者对我们的作用等，供师弟师妹们参考。 说在最前面科研竞赛在很多人眼中都有一定的“神圣性”：只有课内学习完全没问题的人，才有余力去参与科研和竞赛。我认为它其实与选修、辅修类似，只是你在安排时间精力时的一个选项。科研竞赛可以为我们带来很多实质性的好处，无论是对于综测、保研、考研，还是实习、就业、出国，成绩都只是门槛性的参考，而科研竞赛则会为你的简历增添很多光彩。所以希望看完这篇分享后，不仅是排名比较靠前的同学，而是能有更多的同学去尝试接触某一领域的学术研究，或与朋友组队参加一些竞赛，为自己的大学生活取得一些实打实的成果。 科研 科研的基本形式为：在指导老师的带领下，广泛阅读某一研究课题的相关文献，理解文献提出方法的原理、复现其中的实验，与同组的同学交流学习，在一定积累的基础上进行创新性工作，产出成果的过程。 科研其实可以概括为： 课外的、持续性的、任务驱动的、强自主性的学习实践活动。 课外的 科研的内容与大家熟悉的基础课程有着较大程度的割裂，无论是在内容上还是学习习惯上——没有大量的习题给你做，没有明确的知识体系，甚至在很多时候没有合适的参考资料，但科研也与一些专业课关系密切——可能课内学习了一个经典方法，而科研就是在学习它的优化和前沿发展； 持续性的 科研是一项长期的工作，不存在突击的可能，时间的积累并不一定能带来成果，但好的成果必然离不开时间的积累； 任务驱动的 科研没有固定的时间、固定的课程、固定的作业，而是告诉你在一段时间内需要做到什么事，然后你自己安排时间去做，对本科生来说，理解、学习和复现前人的工作是占主流的任务类型，你需要利用一段时间（比如一周）阅读文献、跑代码或完成文献中提到的其他形式的实验； 强自主性的 科研的“任务驱动”决定了强自主性——你需要自己搜集相关文献，学习需要的知识，看论文的过程中遇到不懂的名词，自己去学，配程序环境时遇到问题，自己去查，没有人会给你像课内学习那样的重点整理、学习路线、习题答案或网课讲解，你需要在一个任务目标的指引下自己探索； 科研的作用 大家都是成年人了，时间也挺宝贵，咱们就少画点饼，不整虚的。 本科期间参与科研工作，能为你带来什么？ 产出科研成果 科研成果有两种类型：论文和知识产权。 论文 对于工科生来说，论文也主要分为两种类型：综述性论文和研究性论文 综述性论文：总结某个领域的发展历程和方法，比较各方法的优劣和应用场景，提出现阶段的不足和前景展望 研究性论文：按照摘要、介绍、方法、实验、结论的结构，描述一种与前人不完全一致的方法 知识产权 对于工科生来说，知识产权主要分为三种类型：国家发明专利、实用新型专利、计算机软件著作权 国家发明专利：对产品、方法或其改进所提出的原创性新技术方案，申请周期长（一年半起步），含金量高 实用新型专利：对产品形状、构造或其结合所提出的适用于实用的新技术方案，申请周期较短（6～8个月左右），有点小学生课外学术科技作品的感觉 计算机软件著作权：对计算机软件作品享有的权利，申请周期最短（2月左右），难度最低 科研成果是你参与科研工作的“有效性证明”，无论是未来走学术道路，还是找工作、找实习，以及就在我们眼前的综测、保研、考研复试，都能起到至关重要的作用。 综测 涉及科研成果的综测加分规定如下： 发表学术论文 刊物 加分 一般公开发行刊物或一般学术会议发表论文 20 国家级核心刊物文或国家一级学会主办的会议发表论文 40-60 国际学术刊物或国际学术会议发表论文 60-80 成果形式一般为论文录用通知+导师证明，论文要求学生为第一作者，或指导老师为第一作者、学生为第二作者； 科研与科技发明 参与导师的国家级、省部级等科研项目，由导师开具加分证明，加分10到50不等； 获得国家发明专利加分150； 发表国际普刊的难度不大，且一般情况下会被认定为“国际学术刊物或国际学术会议发表论文”，性价比还是蛮高的。 推免 科研在推免（也就是保研）中扮演着重要的角色，无论是帮助你拿到本校的推免资格，还是获得外校导师的青睐，有能起到至关重要的作用。 学院推免 有关信通学院的推免加分相关规则，可以参考我的其他文章： 信通学院推免科研计分规则 点击查看 保外 想保送到外校读研，需要在获得本校推免资格的基础上，参加目标院校组织的夏令营、预推免或九推的面试，在其中得到认可。 由于研究生期间的主要工作就是科研，所以相比于本校导师，外校导师在对你没有充分了解的前提下，会优先考察你在科研方面的能力。科研经历丰富、成果丰硕的同学更受外校老师的欢迎，有时甚至可以忽略你在其他方面的劣势（比如排名和竞赛不足）。 几乎所有学校在填写报名系统的时候，都需要填写科研经历及成果 部分学校需要提交参营论文 最能吸引导师的点 简历核心、个人陈述核心、面试核心 部分院校的考核内容为阅读指定领域文献/解决指定领域问题并汇报 培养知识&amp;技能 学科基础 科研在很多时候都是专业课的延伸和拓展，甚至部分专业课的深度已经达到了本科阶段的科研水平。在看论文、读代码的过程中，偶然间碰到自己课内学习的内容，回去加深一下印象，一般经过这样一个过程后你对该知识点的掌握都会有质的变化。 应该很多人有过某种念头：我真的需要这份文凭吗 我学这门课到底有啥用？科研的过程其实在一定程度上帮你筛选出了更加有用的知识，当你真的亲身参与到前沿工作中，哪怕只是略作了解，你也会深刻体会到自己所学课程中哪些知识点在现阶段的领域内使用频率很高，趁着还没忘干净，赶紧捡一捡。 举个例子，你还记得矩阵的秩怎么求吗？ 在夏令营、预推免的面试中，由于参与面试的大多数都是科研导师，因此，即使问你专业课，基本上也是问与科研强相关的知识点，因为搞科研的导师并不一定熟悉教学的内容，所以如果你有着较为丰富的科研经验，会给你的夏令营和预推免面试带来较大的把握。 代码能力 对于工科生来说，代码能力是一个符号性的技能： 本专业保研的时候，导师会偏爱代码能力强的学生，会问你会哪些语言、实现过什么； 跨专业保研的时候，一些与计算机交叉的人文社科或经管类专业，也会很喜欢代码能力强的学生； 如果你做计算机、人工智能相关的科研工作，代码是必不可少的，有时候一篇论文写的天花乱坠，旁征博引，荡气回肠，硬看一个礼拜都不一定看得懂，结果一看代码，只不过是在经典方法的基础上改了一个激活函数。 如果你从事通信相关的研究，或金融科技、数字法治等跨学科工作，代码也是一项重要的工具和解决问题的手段。 甚至即使你从事的是纯人文社科类工作，爬虫、数据可视化、数据分析、数据清洗这些工作也离不开代码。 不要怕写代码，因为在科研工作中，你很难有自己写一大堆代码的机会，更多的时候是在读别人的代码，以及安装各种依赖包、配置各种代码环境，来让人家的开源代码能在你的电脑上运行。 英语能力 科研对英语能力的锻炼主要体现在某一领域的“专业英语”：当你看了很多同一领域的文献，最开始你可能看得很慢，单词都要一个一个查，但看的多了以后，你就会发现很多时候甚至不需要理解它的中文意思，看到这个单词，就知道它干了什么。当你找到这种状态，表明你对这一领域及其相关领域有了较高的熟练度。 并且，英文最重要的其实是语感，长时间不用的话，高中学的再好也忘差不多了，老朋友之间，还是得找个机会，经常碰碰面才好，不然白交这个朋友了。 寻找兴趣与定位 千万不要把科研当成“变强的负担”，有时候相比于课内的学习，跟老师做一些课题反而可能是你真正感兴趣的事。 我有一位好友，成绩并不靠前，前几学期一直有点混的感觉，后来一次偶然的机会，对音频技术产生了浓厚的兴趣，主动去蹭一个老师的课，跟他做起了项目。后续我们学习的课程中，跟音频、语音处理有关的内容，他都显得非常专业，科研做的也比较深入，超过我们这一届很多为了科研而科研的“好学生”。 所以，大家不要把科研当成什么白月光，觉得自己课内都没学好，搞什么科研。实际上科研只是一种不同的进步方式，甚至可以理解为一种爱好，毕竟本科阶段的科研并不会真的有老师逼你做出什么成果，一切都源于你主动的驱动力。学有余力的同学，可以把科研当作你进一步提升自我的更高要求；在课内学习中成绩不够理想的同学，也完全可以把科研当作你的第二出路，说不定正是这第二出路，在保研或未来就业的时候能给你一个大惊喜。 获得一个工位 当下，压在每一位西柚西er身上的四座大山：图书馆不开门、呆宿舍想睡觉、教学楼在上课、咖啡厅贵又吵 参与科研工作，有一定几率可以让你在主楼、国重大楼或其他地方有一个独立的工位，轻奢尊享，交通便利，环境优美，冬暖夏凉，氛围浓郁，安静舒适，有自己的台式电脑，可以买你喜欢的鼠标垫和马克杯，布置你的长期固定自习桌，有时候甚至不需要把厚实的电脑背回宿舍。 你甚至可以买个小加湿器放在那，提高生活中的仪式感，喝一杯瑞幸，悠闲而舒适，与满西柚西奔波找自习场所的同学形成鲜明的对比。 本科科研内容 本科阶段到底还是打基础的阶段，受到学习能力和精力的限制，很难在短短四年时间内做到又打基础又做前沿。 因此，本科期间的科研以读经典文献、跑开源代码、总结整理和做汇报为主，前期基本不会涉及创新性工作。 基本的培养模式是： 每个老师的要求不同，组会的频率大多在一到两周一次，这段时间内组里的同学被分配不同的学习或研究任务，然后在组会上进行交流总结。 组会存在的意义一方面是进度上的鞭策，另一方面也是起到共同学习的作用。 比如有六篇大家都需要看的论文，自己一个人看六篇会很累，但一个小组三个人，一人看两篇，再互相给对方讲，是不是就容易很多？ 如何开始科研 学院为大家提供了一些接触科研的机会，你也可以自己行动起来去探索感兴趣的领域，联系相关的导师。 创新人才“菁英班” “菁英班”是信通学院为选拔优秀的本科生提前参与科研训练而组织的教学形式，在完成原专业培养计划的基础上参加“菁英班”安排的学习和科研训练。 2021菁英班选拔管理办法 点击进入下载页面 选拔 2019级选拔了30人，2020级选拔了60人。 每年10月左右启动选拔工作，流程大概是报名-筛选-面试-录取。 入选门槛为大一学年综合测评R2项在专业排名的前20%，对于科研与创新能力突出者，可以适当放宽条件，可能包括： 已经有老师愿意要你，或者你已经有一定的科研基础和不错的技能基础； 竞赛获奖； 如果成绩合格，能提前看一些科研上的基础，可能会对你的面试有一定的帮助，比如： 自学一下python 自学一下Matlab 做一份在线简历 python快速入门 Matlab二维绘图 在线简历制作教程 培养 学习：主要是面向菁英班学生开设科研相关技能培养的课程，包括Matlab、python、科技英语写作等； 科研训练：为每位学生配备个人学业导师，导师全程指导学生进行系统的科研训练，包括参与科研项目、发表高水平学术成果、参与学科竞赛等； 学院还会组织一些前沿讲座，围绕我们比较强的一些领域展开，会邀请很多行业大佬； 寒暑期会有一些与海外高校合作学习的项目； “菁英班”具有流动性： 入选后，如违反校规校纪，或本专业课程出现不及格，或转专业至其他学院，则自动退出“菁英班”； 第二年选拔时，上一学年综合测评R2项在专业排名的前15%，可以申请加入“菁英班” 结业 结业时间是大四期初，需要达到以下条件之一： 以第一作者发表一篇高水平学术论文（或指导老师为第一作者，学生为第二作者）； 授权一项国家发明专利或软件著作权； 承担一项大学生创新项目； 参与一次学科竞赛并获奖； 奖励 菁英班的学生除可以得到科研训练外，还有一系列的奖励政策： 发表高水平科研成果者，给予科研奖励； 优先参与学院组织的优秀大学生夏令营、各类培训、竞赛、课外学术科研活动； 优先资助参加学院组织的国内外交流和访问活动； 通过考核后，在免试推荐研究生、考研、直博时，同等条件下优先考虑； “菁英班”学生如获得保研资格且推免至本校，可在大四进一步接受本硕贯通培养； 由此看来，“菁英班”确实是同学们参与科研的最佳选择，最近应该就快开始选拔了，把握机会啊！ 大创 “大创”全称“大学生创新创业训练计划”，3～5人组成一个小团队，在一位指导老师的带领下对某一问题进行研究，形成一定的成果。 大创立项与结项要求 点击进入下载页面 关于大创的细节，之前受学校创新创业教育中心邀请分享过一次，由于不是本篇的重点，就直接引用当时的内容： 那么大创跟“如何开始科研”又有什么关系呢？ 我们知道，大创一般都是五个人一组，那么团队是怎么组建的？ 一个导师+一个学生，再找四个学生。 也就是说，如果你一开始找不到导师，可以直接去找感兴趣的项目组，成为组员。大创虽然只有一年的时间，但进了组以后，你开始承担一份重要的科研工作了，大创结束，但你在组里扮演的角色还在，也就顺理成章留在了组里。 导师招募 学院的部分导师自己也在带学术训练性质的小组，或者自己的课题组也在招本科生进去工作。加入这样的组，一般也需要经过提交材料+面试的过程。 我知道的两个组： MCL大学生学术训练季https://e.eqxiu.com/s/fgtFjdBp?bt=yxy&amp;share_level=2&amp;from_user=20221004a4461125&amp;from_id=59e22c6c-9&amp;share_time=1664887281161 CUC-MPIG智能媒体处理小组https://mp.weixin.qq.com/s/tHFyrgTOG3gf7u9kotvSVA 如果你有感兴趣的老师，比如你的班主任或任课老师，也可以主动找他询问，一般老师除教学任务外，也同时在带研究生或博士生，如果跟老师聊得来，说不定就可以直接混入其中。 寻求班主任的帮助 如果你有参与科研的想法，又不知道该如何切入，可以主动找你的班主任寻求帮助，班主任大概会根据你的兴趣，为你推荐学院或其他学院中研究领域相关的老师，或者自己带你先进行一些基础性的科研训练。 竞赛 竞赛的种类、形式多种多样，大多不拘泥于考试，而是以解决某些问题为导向开展个人或团队形式的能力比拼。相比于科研，竞赛对我们来说往往有着更高的吸引力和接受度： 有着更明确的目标和体系化的知识； 采用大家熟悉的课内学习模式，可以应对大多数的竞赛； 有着奖励的刺激； 出成果的难度相比于科研要低一些； 竞赛的作用 参与竞赛，能为你带来什么？ 产出竞赛成果 既然是竞赛，肯定是有奖项设置的。 科研成果的取得是严谨的且自主性强的，你需要有一定的创新性工作，并且经过严谨的论证，整理成为一定形式的成果； 而竞赛成果的取得，则纯粹是看能力和准备，发布通知，你去参加，按他的要求准备，能力足够强就拿奖，整个过程简单且粗暴。 竞赛的成果一般分为国家级、省部级和校级，作为北京的学校，省部级一般就是指北京市级。 同等级别中，国家相关部委组织的竞赛往往具有更正规的参赛流程、更大的难度和更高的认可度，一些相关学会举办的比赛也已经得到了行业的认可，含金量不下于国家相关部委举办的比赛。 获得竞赛成果，尤其是在对应行业内认可度较高的竞赛成果，将会为你的简历填上浓墨重彩的一笔。 综测 综测加分规则中，将竞赛分为了理工类学科竞赛、外语及思政类学科竞赛、文体竞赛三类，作为信通学院，自然是对理工类学科竞赛的认可度最高，当然对未来的深造或就业来说，也是与理工科相关的竞赛具有更高的行业认可度。 具体的加分规则如下： 理工类竞赛 学科竞赛必须为理工学科相关领域，其他学科竞赛成绩不计入本项加分； 学科竞赛按照学生获得的相应名次进行分等级加分，凡未获得名次，仅取得相关的荣誉称号者，均不加分； 学科竞赛的主办单位必须为国家机关、政府部门及相关行业机构，任何商业盈利机构主办或承办的学科竞赛均不计入本项加分; 同一项目一稿多投，以获得最高级别奖项的名次加分，不累计加分； 团体参赛加分均等，不折半计算 ； 竞赛等级 一等奖 二等奖 三等奖 其他 国家级政府奖 150 120 100 80 国家级一般奖 80 60 40 20 国内省级单位主办竞赛 80 60 40 20 本学校及学院主办竞赛 30 20 10 5 国际学科竞赛 80 60 40 20 可以看出，国家级一般奖和省部级奖项的加分规则一致，且国家级政府奖基本没有加上的可能——比如“互联网+”是教育部主办的比赛，其国赛获奖公示甚至是教高函（2022）1号文件，但学院依旧认定其为国家级一般奖。跟教学关系最密切的教育部都不算“国家部委”，其他部门更不放在眼里了。 外语及思政类竞赛 外语、思政类学科竞赛按照学生获得的相应名次进行分等级加分，凡未获得名次，仅取得相关的荣誉称号者均不加分； 学科竞赛的主办单位必须为国家机关、政府部门及相关行业机构，任何商业盈利机构主办或承办的学科竞赛均不计入本项加分； 同一项目，一稿多投，以获得最高级别奖项的名次加分，不累计加分； 团体参赛加分均等，不折半计算； 综测认可外语及思政类竞赛，但保研不认可，如果需要同等的备赛经历，希望大家慎重考虑选择哪个参赛。 竞赛等级 一等奖 二等奖 三等奖 其他 国家级政府奖 80 60 40 20 国家级一般奖 40 30 20 10 国内省级单位主办竞赛 40 30 20 10 本学校及学院主办竞赛 15 10 5 2 文体竞赛 文体竞赛按照学生获得的相应名次进行分等级加分，凡未获得名次，仅取得相关的荣誉称号者，均不加分； 文体竞赛主办单位必须为国家机关、政府部门及相关行业机构，任何商业盈利机构主办或承办的文体竞赛均不计入本项加分； 原则上，不承认外校及本校其他学院主办的任何文体竞赛； 集体类、团体类竞赛项目，对照相应级别和名次，参赛者加分减半； 我院的文体竞赛，写作文体竞赛，读作体育及合唱竞赛，除了你在运动会获奖，或学校相关运动比赛获奖，或加入合唱团参赛获奖之外，就只有去人民大会堂表演，才有加这一项分的希望。 推免 竞赛也是推免过程中的重要角色，无论是对于获取本校推免资格时的加分助力，还是去外校面试时的提问关注，竞赛都扮演着重要的角色。 且相比于科研，竞赛成果的获取确实更加容易，也是我和我的同学的主要成果支撑。 学院推免 有关信通学院的推免加分相关规则，可以参考我的其他文章： 信通学院推免竞赛计分规则 点击查看 值得一提的是，在今年的推免分核算中，竞赛和科研的加分权重都是10%，但竞赛比科研平均多加了30多分。 保外 由于相比于科研成果，竞赛成果的取得更加容易，因此更多的学生在权衡自己的能力、兴趣和时间安排后，会选择一项或几项含金量较高的竞赛，全心投入其中，取得一定的成果。 竞赛成果，尤其是专业相关的竞赛成果，在外校导师的眼中也有着很高的认可度，比如： 数学建模的成果代表了解决问题的能力，包括对Matlab、python的掌握和团队协作能力等； 算法竞赛的成果代表了极致的代码能力、灵活的思维和良好的代码习惯； 创新创业竞赛的成果往往与科研一致； 当然，与科研经历类似，竞赛也不是唯结果论，只要能在参赛过程中有所收获，能讲出自己在其中扮演了什么角色、锻炼了什么技能、培养了什么兴趣，也会对导师产生一定的吸引力。 培养知识&amp;技能 竞赛具有很强的目的性，其需要的能力往往也非常明确，准备竞赛的过程，往往也是很好的理解学习过程。 奖项我们当然需要，但参赛过程中的“以赛代学”同样也非常重要，这帮助你获得了成果以外的知识，顺便还能帮你获得其他类似竞赛的奖项。 学科竞赛对应了学科基础，比如数学竞赛帮你巩固数学知识，物理竞赛帮你巩固物理知识； 同时，既然是理工类竞赛，对理工基础的培养和锻炼也有着非常不错的效果，比如参与算法竞赛，会让你形成良好的代码亲和力，包括优秀的代码理解能力、良好的耐心、调试错误的能力、对程序时空复杂度的敏锐观感等。 此外，在某一领域的竞赛中获奖，也会帮你树立在这个领域内的信心，算法竞赛爷都拿过奖，数据结构又是哪里的弟弟，爷根本不放在眼里。 不同竞赛的性价比 性价比 这个词相对来说就比较功利了，但大学期间能做的事情实在太多，为了让大家有更多的选择、更强的目的性，能把时间安排的更加合理，我也不得不给出一些这方面的建议。 当然还是希望大家能以兴趣为基础去参加竞赛，强行参加自己不喜欢的竞赛，是一件非常痛苦且很难有结果的事。 整体来看，性价比最高的两类竞赛是数学建模和创新创业，因为二者都具有一个特点：一次学习，“终生”受益。 数学建模承担一次的备赛成本，把需要的知识学明白了以后，一年之内就有五六场比赛可以参加，其中美赛和国赛的含金量也处于top位置，在理工科的认可度非常高，美赛对申请国外的名校也非常有帮助。 创新创业的性价比则来源于与科研的强相关和可重复利用性，认真做一个科研项目，用它参加大创和各大创新创业竞赛，一个项目经过简单的修改甚至不修改，就可以去投很多不同的创新创业竞赛，认认真真做好一个项目，你就可以蝉联各大创新创业竞赛的奖项，同时你说不定还能搞的到科研成果。 对于综测 我院的综测中，对竞赛主办方的限制是非盈利机构，也就是说如果单纯为了综测加分，应该选择难度较低、主办方非营利机构的理工类竞赛。 久负盛名的几项重要竞赛中，“互联网+”的加分相对来说拿得比较容易，因为理工类竞赛团队加分均等，而互联网+一个参赛团队最多可以有15个人，虽然北京市一等奖很难拿，但二等奖还是有不小的希望，三等奖更是用心点就能拿得到，一旦拿到北京市三等奖，负责人和所有成员各加40分，确实是非常的香。 对于本校推免 我院的推免中，数学竞赛无疑是今年最靓的仔，碾压一众武林高手，制霸信通。详细的规则可以查看上面的链接，这里简单说一下它的逻辑： 数学竞赛分为国家级和省级两个层次，学生先参加北京市的数学竞赛，获奖后，一等奖排名前几的人有机会进入国赛的角逐； 妙就妙在，你在北京市大学生数学竞赛中获奖后，会给你发两个奖状：北京市x等奖和全国x等奖，离谱的是今年学院竟然认可了这个国奖，还把它和北京市的奖归在了不同的类别里。 这就导致，一场平时好好学，考前做做题就有很大概率拿奖的比赛，直接被送上了神坛。 2021年，第十三届全国大学生数学竞赛，我校共获得3个北京市一等奖、22个北京市二等奖、33个北京市三等奖，没有学生进入全国总决赛。 假设你获得了北京市二等奖，属于E档2类，按规定原本可以加30分，其实也不少了： 但你还有一个被认可的全国二等奖，可以加60分： 按照规定，你最多可以选择两项类别不同的竞赛进行加分，其中一项加分要除以4，相当于你参加了一次比赛，获得 的加分。 大家可能对这67.5分缺乏概念，我们用大家熟知的“度量衡”来解释一下： 发表一篇SCI期刊论文，且在大四开始前录用，加70分； 申请一项国家发明专利，专利权人写中国传媒大学，加40分； 大创获得优秀结项，负责人加10分，成员加3分（2021年国创计划，信通12个国家级项目、18个北京市级项目、10个校级项目，仅有一个优秀结项）； 在互联网+创新创业大赛中，作为负责人获得全国铜奖，加50分（全国铜奖是我校八届以来的最高奖）； 相当于0.3375的绩点，在2019级能把专业第37送到专业第一； 保研加分的初衷，应该是为有志学生的规划起到指导作用，我不明白指定这样失衡的规则，是出于什么样的考虑。但它其实引申出了另一个问题：学院会不会已经意识到了它的不合理，只因今年已经推出文件，只能将错就错，明年又“朝令夕改”？下一届的学生参考这一规则，过度看重数学竞赛，以为拿奖就能“落袋为安”，而把精力投入到更多感兴趣但不加分的事中，会不会导致又一批优秀的学生含恨秋招？ 正常规则下的性价比 为防止学院更改数学竞赛的规则，我认为还是有必要按常规思路给出一些有关推免竞赛性价比的建议。 综合考虑获奖难度，如果你不打算在某个领域全力拿个大奖，比较理想的选择是： 在美国大学生数学建模竞赛中获得H奖，+30 在互联网+中作为负责人获得省二等奖，+30 在数学竞赛、物理竞赛中获得省二等奖，+30 如果你打算在某个领域全力冲锋，考虑到难度、我校的获奖先例，我比较推荐的是： 全国大学生数学建模竞赛 电子设计大赛 对于外校推免 在信通学院大放异彩的数学竞赛，在夏令营和预推免中惨遭滑铁卢：我和身边的朋友面了这么多场试，国内喊得出名字的名校，几乎没有老师知道数学竞赛是干什么的，甚至咱们学院的老师都会在面试时提出“你用什么算法解决了什么问题”这样的疑问（把数学竞赛当成了数学建模），足以见其认可度之高实属罕见。 对本专业推免来说（计算机or通信），认可度最高的两类竞赛是算法竞赛和数学建模，通信领域对电子设计竞赛也有非常不错的认可度。 如果你想跨专业，就要去了解对应专业or行业内的比赛认可情况，由于我并不了解，这里就不妄加评论了。 此外，对于国家部委举办的比赛，比如创新创业类竞赛中的互联网+（教育部）、挑战杯（共青团中央）、创青春（共青团中央），在各个学科都有着非常高的认可度可以理解为一种政治正确。 大家有什么问题可以在评论区中提出哦！","categories":[{"name":"分享","slug":"分享","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/"},{"name":"日常","slug":"分享/日常","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/%E6%97%A5%E5%B8%B8/"}],"tags":[]},{"title":"2022推免分享——本校篇","slug":"share-recommendation-cuc","date":"2022-09-30T11:01:43.000Z","updated":"2022-10-02T09:03:51.204Z","comments":true,"path":"2022/09/30/share-recommendation-cuc/","link":"","permalink":"https://pyxblog.cn/2022/09/30/share-recommendation-cuc/","excerpt":"分享一些2022年的推免经历及经验总结，供师弟师妹们参考。推免分为两个环节： 获得本校推免资格 有学校向你发出offer（包括本校） 本文主要面向校内保研，包括本校推免资格的获取及各保研赛道的规则解读。文末提供了一些文件，包括各赛道的推免规则及结果公示，可按需下载。","text":"分享一些2022年的推免经历及经验总结，供师弟师妹们参考。推免分为两个环节： 获得本校推免资格 有学校向你发出offer（包括本校） 本文主要面向校内保研，包括本校推免资格的获取及各保研赛道的规则解读。文末提供了一些文件，包括各赛道的推免规则及结果公示，可按需下载。 概况 简介 西柚西的本科毕业生免试攻读硕士学位研究生（简称推免）共分为5个项目： 一般类别项目：即通常意义上的保研，由各学院在学校划定的“底线”上自行制定评价规则，按成绩、科研、竞赛、综合素质等因素评定保研资格，各专业的一般类别上岸几率大概在10%左右； 特殊专长项目：选拔具有特殊学术专长或具有突出培养潜质的学生，由学院推荐、学校选拔； 研究生支教团项目：选拔学生参与研究生支教服务队，由学院推荐、学校选拔； 服务国家战略人才项目：由学院推荐、学校选拔，分为众多赛道，包括 国际传播硕士班（白杨班）：对外语要求较高，且满足传媒相关的条件之一，如国际组织实习、重大活动获奖等； 国家战略科技力量培养计划：即国重保研，有GPA门槛，根据学业成绩和科研能力评价选拔； 新闻与传播专硕 翻译人才培养计划 国家网络传播与社会治理人才培养计划 退役大学生士兵计划 乡村振兴教育帮扶计划 高水平艺术团计划 奖励人才项目：选拔在国家和学校的重大活动、国内外重要艺术创作评奖、实践创新活动中表选突出的学生，由学院推荐、学校选拔； 上述共5个项目，其中「服务国家战略人才项目」包括8个子项，需要注意的是，不同项目、不同子项之间不可兼报，只能选择一个赛道报名。 推免核算时间线 今年各赛道的推免提交材料时间线为： 2022.09.13 19:14 学校发布推免通知 2022.09.14 16:22 学院发布推免加分细则 2022.09.15 11:00 特殊专长项目、奖励人才项目、研究生支教团项目材料截止 2022.09.16 11:00 服务国家战略人才项目（白杨班、国重保研等）材料截止 2022.09.16 16:00 一般类项目材料截止 可能是因为推免核算的那段时间，正好碰上疫情爆发，所以整体流程显得非常仓促。但尽管时间紧张，基本上还是会给你自己先算一遍一般类赛道得分的时间，如果抢得到一般类保研名额，就可以直接准备一般类的材料，如果得分不够，老师就会鼓励你去其他赛道尝试，当然如果你头铁，也可以强行留在一般类。 推免数据 由于一般类保研靠量化的成绩说话，分数一算出来，谁能保、谁保不了就不会有任何悬念；但即使你综合实力再强，去学校里抢其他赛道的名额也存在着一定的风险，这就会导致各专业综合能力靠前的同学都会选择稳稳占一般类保研名额，在一定程度上降低了其他赛道竞争的难度。所以，成绩不够理想的同学，只要能在某个赛道有一定的针对性准备，抢到名额的可能性还是很高的。 下面是今年各赛道的保研情况： 由于西柚西最开始公示的各赛道、各学院名额分配和实际发放的名额不符（。。。），一般类、国重、奖励和特长人才名额都有一定的变化。上图中的数据来源于最开始的公示和我了解到的增补，可能并不准确，比如存在某些学院的最终结果比图中多一两个的情况，仅供参考。 可以参考一下各赛道的名额比例，结合自己在各个方面的材料和能力，选择一个合适的赛道进行准备，或者选择几个赛道进行两手准备。 2022年信通学院成功推免的学生中，各个赛道的分布如下： 学院推免成功的学生共62位，其中一般类别项目占比最高，国重保研次之，各赛道情况如上图所示，未列出的赛道表明没有学生通过该赛道成功保研。 成功保研的学生中，所有必修限选课绩点及在专业中的排名情况如下所示： 上图包含了各个赛道的数据。尽管最终的结果不只看成绩，还要看你在科研、竞赛和综合素质方面的能力，但可以通过该表得出结论： 成绩好的同学，看一下本专业绩点排名靠前的同学是不是都保研了，深入体会一下科研、竞赛和综合素质可能拉开的差距，告诉自己只有成绩好是没用的，得各方面都差不多才行； 成绩一般但想保研的同学，看一下在冲科研竞赛的同时，应该保证自己的成绩至少处在什么水平，才有争取保研的希望，毕竟成绩永远是占比最高的评分项，甚至是很多赛道的门槛； 信通一般类赛道规则 一般类赛道是名额最多的赛道，是最能衡量综合实力的赛道，同样也是目标最明确的赛道。充分理解加分文件中的规定，体会政策展现出的倾向，做好规划，一步一个脚印地实现推免的目标，是现阶段对保研er来说最稳妥的途径。 门槛 参加一般类赛道的选拔，要求学生前三年综合测评总排名在专业前50%。 除了这个门槛，综测在保研的过程中完全没起到其他作用，所以对推免来说，综测的要求真的很宽。 计分规则 信通学院的一般类推免计算规则较为清晰，综合成绩由四个部分组成： 总分科研分竞赛分素质拓展分 其中： GPA指的是前三学年所有必修限选GPA，由教务老师从系统中直接导出，可以在这里查看自己的GPA： 可信电子凭证 进入后点击“成绩单” - “预览” 科研分、竞赛分按下述规则核算； 素质拓展分由两个部分组成： 素质拓展分材料评定得分文体竞赛得分社会服务分 GPA 在信通学院，GPA占推免计分总评的八成，具体计算规则为： 所有必修限选 乍一看，占总评的80%，好像很重要？实则不然。 从2022信通推免生绩点排名情况图表中可以看出，大多数保研的学生，绩点集中在之间。 换句话说，在保研这个竞争圈里，你的GPA起点不是0，而是3.65。 相当于每个人都有的基础分，在这个基础上，只有分的竞争空间。 话说到这份儿上，诸位“卷王”应该都有体会——对于分分必争的“好学生”来说，差0.2的GPA其实已经是鸿沟一样的差距了，但反映在推免加分规则上，竟然只差出来4分。 本来，这4分其实也不好加，你需要达成以下条件之一： 为学校申请一项国家发明专利你出钱出力，但专利权人要写中国传媒大学 发表一篇EI期刊论文（注意不是EI会议） 蓝桥杯获得全国三等奖（13届了，咱们学校进蓝桥杯国赛的好像没超过5个？） 在CCPC省赛/ICPC全国邀请赛中获得金牌 在“互联网+”创新创业大赛中获得北京市一等奖（直到2021年之前，全校都没人拿过主赛道一等奖） 在全国大学生数学建模竞赛中获得北京市一等奖 而按照2022年信通学院新增的规定，在数学竞赛中获得省三等奖，你就可以拿到4分的加分。 科研 科研加分的比重是10%，也就是说，以下列出的加分，都要乘0.1再计入总分。 科研分为三类： 论文 知识产权 大创 可以选择多类进行加分，每一类仅取最高，比如你发表了多篇论文，只能选一篇加分。细则如下： 论文 论文总体分为四档： 刊物等级 对应加分 SCI期刊 70 EI期刊、A类会议 40 B类会议、中国传媒大学学报 20 其他类别论文 10 一般来看，我们常说的EI会议、CPCI（ISTP）、国际普刊，以及知网检索、万方检索之类的刊物，没有特殊情况的话，都算作“其他类别论文”。 只有当论文的第一作者是你，或者第一作者是你的导师、第二作者是你时，才可以加分。 需要特别注意，与往年不同的是，今年突然要求论文必须发表才可以加分，只录用、未发表，则一分不加。并且，论文的发表时间必须在2022.08.31之前，尽管推免提交材料的截止时间是2022.09.16，但2022.09.01-2022.09.16这段时间发表的论文一分不加，即使你在2022.08.31之前已经拿到了录用。想通过发论文获得加分的同学，一定要注意这一点！ 知识产权 知识产权只认可三种：国家发明专利、实用新型专利和计算机软件著作权： 知识产权类型 对应加分 国家发明专利 40 实用新型专利、计算机软件著作权 10 知识产权以证书为准，按文件的要求来看，授权通知书无效； 知识产权的正式下证时间必须在2022.08.31之前，之后无效； 按文件规定，知识产权的所有人，比如专利的专利权人、软著的著作权人，必须是中国传媒大学，才可以给你加分。当然，在满足所有人是中国传媒大学的同时，还需要满足第一作者是你，或者第一作者是你的导师、第二作者是你，才可以加分。 大创 大创不在乎立项的等级，只在乎结项的等级，以及你是不是负责人： 负责人 负责人 其他成员 其他成员 优秀结项 其他结项 优秀结项 其他结项 10 3 3 0 没错，加分就是10、3、3和0，而且还要乘10%才能计入总成绩，可以看出加分文件对大创并不重视，辛苦干一年，约等于没有。 给大家参考一下它的难度：2021年的全国大学生创新创业训练计划，2022年4月结项，信通学院12个国家级项目、18个北京市级项目、10个校级项目，一共40个项目中，仅有一项国家级大创的结项评级是优秀，其他全是良好或合格。 竞赛 与科研相同，竞赛的加分的比重也是10%，即以下列出的加分，都要乘0.1才能计入总分。 在学院的一般类推免中，将竞赛分为国家级和省部级两大类，其中： 国家级竞赛分为A、B、C三个档次，每个档次对应的加分依次递减； 省部级竞赛分为D、E、F三个档次，每个档次对应的加分依次递减； 校级竞赛按各系的推免工作领导小组的认定结果加分，上限为10分； 同时，将所有竞赛分为10个类别，学生加分时，可以选择一个竞赛或两个不同类别的竞赛进行加分，不可以选择同一个类别的两个竞赛进行加分； 如果选择两个不同类别的竞赛，其中一个竞赛的加分要乘0.25； 国家级竞赛 信通学院认可的A档国家级竞赛有且仅有一个，加分标准如下： 竞赛名称 类别 国一 国二 国三 全国大学生电子设计大赛 1 100 80 60 B档竞赛有10个，所属类别及加分情况为： 竞赛名称 类别 国一 国二 国三 全国大学生数学竞赛 2 90 70 50 全国大学生数学建模竞赛 3 90 70 50 美国大学生数学建模竞赛 3 90（O） 70（F） 50（M） “互联网+”大学生创新创业大赛 4 90 70 50 “挑战杯”课外学术科技作品竞赛 4 90 70 50 ICPC总决赛 5 90 70 50 CCPC总决赛 5 90 70 50 CCPC亚洲区域赛决赛 5 90 70 50 ICPC分站赛 5 90 70 50 CCPC分站赛 5 90 70 50 ps. 美赛H奖加30，S奖不加分 C档竞赛有5个，所属类别及加分情况为： 竞赛名称 类别 国一 国二 国三 北京市大学生数学竞赛 8 80（省一） 60（省二） 40（省三） 蓝桥杯国赛 6 80 60 40 “大唐杯”全国大学生移动通信5G技术大赛 6 80 60 40 全国大学生机械创新设计大赛 7 80 60 40 全国大学生智能汽车竞赛航天智慧物流总决赛 8 80 60 40 省部级竞赛 省部级竞赛的分档与国家级竞赛基本一致，D档还是有且仅有一个： 竞赛名称 类别 省一 省二 省三 北京大学生电子设计大赛 1 50 40 30 E档竞赛有11个，所属类别及加分情况为： 竞赛名称 类别 省一 省二 省三 北京大学生数学竞赛 2 40 30 20 北京大学生物理竞赛 9 40 30 20 北京大学生数学建模竞赛 3 40 30 CCPC省赛 5 40 30 20 ICPC全国邀请赛 5 40 30 20 CCPC女生专场 5 40 30 20 华北五省大学生机器人大赛 8 40 30 20 全国大学生计算机应用能力与信息素养大赛 10 40 30 20 “互联网+”北京赛区 4 40 30 20 “挑战杯”课外学术科技大赛北京赛区 4 40 30 20 大学生智能汽车竞赛航天智慧物流竞赛北京赛区 8 40 30 20 F档竞赛有4个，所属类别及加分情况为： 竞赛名称 类别 省一 省二 省三 蓝桥杯北京赛区 6 30 20 10 北京大学生机械创新设计大赛 7 30 20 10 全国青年科普创新实验既作品大赛（北京赛区） 7 30 20 10 “大唐杯”省级预选赛 6 30 20 10 团体竞赛 对于多人完成的团体竞赛，如数学建模、互联网+等，需要根据学生在团队内的排序分配加分，细则如下： 档次 个人参赛 序列1 序列2 序列3 其他 A 1 1 0.9 0.8 0.2 B 1 1 0.8 0.6 0.2 C 1 1 0.8 0.6 0.2 D 1 1 0.9 0.8 0.2 E 1 1 0.8 0.6 0.2 F 1 1 0.8 0.6 0.2 比如数学建模，是三个人组队参赛，尽管国赛是三个人各一张证书，每个人的证书上，自己的名字排在第一位，但实际上还是要队内给出一个加分顺序。一个队伍拿了数学建模全国一等奖，则成员1加90分，成员2加分，成员3加分。 说数学竞赛崩坏了整个加分体系，原因就在这里：北京市数学竞赛获奖后，同时颁发两张奖状，一张省级奖项，一张国家级奖项。从上面的表格中可以看出，省奖属于E档2类，国奖属于C档8类，一次比赛，两张奖状，还不是一类的，可以同时加分。如果你拿到省一，直接加，相当于你的GPA涨了，直接从一个系的中后水平，拉到满绩。但它的含金量真有这么高吗？未必。且不说只要平时认真听讲，考前做做往年的题，拿个省三轻轻松松这种大实话，单论今年夏令营面试，国内叫得上名的985高校，几乎找不到一个老师知道数学竞赛到底是干什么的，甚至连本校的老师都会问你在这个比赛中用了什么算法，解决了什么问题，而不知道它只是一场难度较大的考试。 素质拓展 素质拓展的加分比重为10%，包括两个部分：材料评定和社会服务，每个部分相当于占总分的5%。 材料评定 材料评定分为两项：有无挂科和四六级通过情况，其中： 课程有挂科 课程无挂科 0 +25 四六级都没过 四级通过 四六级都通过 0 +12.5 +25 大家在这一项的分数基本都是50，也就是拿到了分。当然，也有一些倒霉蛋抢不到六级的名额，比别人少12.5分。 文体竞赛 文件上的文体竞赛，写作【文体竞赛】，读作【合唱和校运动会竞赛】，它虽然正儿八经的给你了国家级、省部级和校级获奖的加分标准，但没有给出认可的竞赛范围，这就导致除了本学院组织/带队参与的竞赛之外，其他全都不认，除非你在人民大会堂里参加文艺比赛获奖。 文体竞赛的加分规则如下： 国家级 省部级 校级 第一名 50 第一名 35 第一名 20 第二名 45 第二名 30 第二名 15 第三名 40 第三名 25 第三名 10 此外，文件规定，参加省部级及以上文化艺术活动或演出，表现突出，为学校和学院赢得良好声誉者，经学院推免小组评定，最高加30分； 需要注意的是： 文体竞赛主办单位必须为国家机关、政府部门，原则上不承认外校及本校其他学院主办的任何文体竞赛； 文体竞赛最多选择两个项目进行加分； 团体类竞赛加分减半； 文件中虽然说“国家机关、政府部门”的比赛认可，但计算综测的时候，互联网+的主办方明明是教育部，还是不算“国家机关、政府部门”举办的比赛。所以朋友们，天赋异禀的同学可以积极参加一下运动会，合唱团的同学可以努努力，其他人就别想加这一项的分了。 社会服务 社会服务是除科研竞赛外，大部分同学可以争取的另一项重要加分。 社会服务的加分上限为100，以下这些情况可以计入社会服务加分： 参军入伍服兵役，加40分 参加国际组织实习，加40分，需提供实习证明，冬奥BTP不算 参加志愿服务，上限加40分 志愿服务分基础分奖励加分，其中基础分志愿北京志愿时长，奖励加分包括： 参加国家重大志愿项目，加10分 在国家重大志愿项目中获得优秀志愿者称号，加10分 参与社（xue）会（sheng）服（gong）务（zuo），上限加30分 社会服务分基础分奖励加分，其中基础分按如下规则加分： 职务 加分 校学生会主席、院学生会主席、团委副书记、党支部书记 30 校团委部长、院学生会副主席、班长、团支书 20 校级社团社长、院学生会部长、学习委员 10 院学生会副部长、其他班委、班主任助理 5 奖励分包括： 班委任期满一年，任期内班级获评市级优秀班集体，加5分 担任校级社团社长，任期内社团获评校级十佳社团，加5分 获奖励情况，即三好之类的荣誉称号，仅可选择一项，上限加30分 奖励类型 加分 市级及以上三好学生、优秀学生干部、优秀党员、优秀团干部、优秀团员 30 校级及以上三好学生、优秀学生干部、优秀党员、优秀团干部、优秀团员 15 上面的规则中，其实有效的条目并不多，因为：参军入伍服兵役的同学貌似没有，即使有，也有专门的推免赛道，很难有机会来一般类项目；国际组织实习的界定标准非常模糊，时间成本又很高，这就导致学生不敢自己去找，但像BTP这种官方给机会的又特别标注不加分；大四之前的班级很难拿到北京市级优秀班集体；大四之前的学生很难拿到市级荣誉；因此，对大多数同学来说，能争取的加分项主要有：干一年班委；志愿时长干满200小时；获得一项三好学生、优秀团员等校级荣誉； 总结 本届一般类保研中，最高分93.35，最低分80.32，平均分86.73； 广播电视工程系科研单项平均加分14.2，竞赛平均加分51.9，社会服务平均加分61.7； 可见，大家的平均水平一般就是： 一篇国际会议论文+一项数学竞赛+志愿服务拉满+一项校级荣誉 因此，对大家来说，比较理想的状态是： 绩点3.75以上 75 points 发表一篇国际会议论文，为学校申请一项计算机软件著作权 2 points 参加美国大学生数学建模竞赛获得H奖，或获得其他比赛的省级二、三等奖 3~4 points 数学竞赛获奖，走上人生巅峰 志愿时长达到200小时，获得一项校级奖项，担任一年班委 3.5 points 材料分拉满 2.5 points 总分 87 points，勉强达到平均水平。加油！ 其他赛道 特殊专长项目 门槛 要求在校三年综合测评总排名在专业前50%，且符合以下条件之一： 在核心期刊上以独立作者或第一作者发表与学业相关、并标明作者单位为中国传媒大学的科研论文； 作为主力成员参加与学业相关的国内权威科研、学科、专业、文学艺术竞赛(全国赛)并获得三等奖以上奖励。国际赛事参照执行，但不得低于国内赛事相关要求； 作为国家级、北京市级已结项的大学生创业创新训练计划项目负责人，且结项成绩为优秀； 作为主要成员获得国家发明专利； 符合基本的报名条件后，还需要经本校两名及以上本学科/专业教授或副教授推荐，并参与学校组织的公开答辩，作为遴选的流程。 特点 可以保外校； 看重科研及竞赛成果，有点像是一般类保研的翻版； 对互联网+的认可度较高，获得国奖后基本可以确定一个名额； 唯一需要答辩的赛道； 奖励人才项目 门槛 在校前三年综测总排名在班级或专业前 50%，前三学年必修限选课 GPA 不低于3.0，且符合以下条件之一： 积极参加国家或学校的重大活动，且有优异表现； 获得国内外重要艺术创作评奖； 参与实践创新活动，且有优异表现； 特点 可以保外校； 看重重大活动参与经历，当然如果你有很强的代表作也可以抢到名额； 研究生支教团项目 门槛 量化门槛：前三年综合测评总排名在班级/专业前50% 非量化门槛：志愿服务工作经历突出，具有一定的表达能力与行政、组织能力，丰富的团学工作经历，形象素质好等 优势因素 满足以下条件之一者，同等条件下可优先考虑： 中共党员、中共预备党员 已获得中小学教师资格证或已报名2022年下半年中小学教师资格考试者 积极参加志愿服务，有参加国家重大志愿服务经历者 青年马克思主义学院学员 “先锋杯”优秀团干、团员 挑战杯、创青春、互联网+获得省部级及以上奖项的项目成员 满足以下条件之一者，直接进入面试环节，不占用各学院推荐名额： 青年马克思主义学院优秀学员 中传青年五四奖章个人奖项获得者 挑战杯、创青春、互联网+全国赛获一、二、三等奖的成员 挑战杯、创青春、互联网+北京市赛获一等奖的负责人 特点 只能保本校 通过后需要先支教一年，再回来读研，混入师弟师妹 需要写一个申请书，材料准备较为麻烦 跟校团委有点关系，会比较有优势 服务国家战略人才项目 分为八个子项，只能选择一个子项参与评选。 只能保本校。 国际传播硕士班 关键词：在传播领域有代表作，对英语要求高 申请者在校前三年综测总排名在班级或专业前50%，且GPA在班级或专业前20% 外语符合下列条件之一： 大学英语六级考试合格 雅思（学术类）成绩在6.5分及以上 托福（IBT）成绩在95分及以上 大学本科专业为外语专业 满足下列条件之一： 曾在国际组织或国际传播机构实习 曾参与重大国际活动 在国际传播平台运营具有正面影响的自媒体账号 曾在国内外有较高影响力的创作类活动或学科竞赛中入围 论文在下列任一学会年会中入围： 国内一级学会年会 国际传播学会年会 国际媒介与传播研究学会年会 新闻与大众传播教育学会年会 在国际传播领域有特殊专长 满足下列条件之一，不受第1条限制： 曾在国际组织或国际传播机构实习3个月及以上 在重大国际活动中获得证书或奖励 在国际传播平台运营具有正面影响的自媒体账号获得较高关注度 曾在国内外有较高影响力的创作类活动或学科竞赛中获奖； 论文在下列任一学会年会中获奖： 国内一级学会年会 国际传播学会年会 国际媒介与传播研究学会年会 新闻与大众传播教育学会年会 国家战略科技力量培养计划 关键词：理工科保本校，除一般类外的最佳选择 申请者在校前三年综合测评在专业或班级前50%，且在校前三年必修限选课GPA排名在专业或班级前20%。参加学科和学术竞赛并取得优异成绩者可适当放宽条件 申请者应对媒体融合与传播国家重点实验室科研团队的研究方向具有浓厚的兴趣，相关学科的基础课程及专业课程成绩优异，科研设想具有创新性，具有相关研究基础和研究经历者优先 综合评价成绩由学业成绩、科研能力评价分数组成，成绩占比之和为100%。其中，学业成绩占比为40%，科研能力评价分数占比为60% 新闻与传播（国际传播）专硕计划 关键词：同白杨班，但简单一点 申请者在校前三年综测总排名在班级或专业前50%，且GPA在班级或专业前20% 外语符合下列条件之一： 大学英语六级考试合格 雅思（学术类）成绩在6.5分及以上 托福（IBT）成绩在95分及以上 大学本科专业为外语专业 满足下列条件之一： 在国际传播实践领域有特殊专长 曾在国际传播机构实习（如媒体、企业、国际组织） 曾参与重大国际活动（如外交活动、体育活动、文化活动） 曾运营有广泛、重要且正向影响力的自媒体账号 曾撰写或拍摄有广泛、重要且正向影响力的国际传播作品 曾入围国内外有较高影响力的创作类活动或学科竞赛 论文在重要国际和国内学术组织主办的会议上宣读或被会议收录，包括但不限于： 国际传播学会（ICA） 国际媒介与传播研究学会（IAMCR） 新闻与大众传播教育学会（AEJMC） 欧洲传播研究与教育学会（ECREA） 以及国内一级学会 满足下列条件之一，可不受第1条限制： 在重大国际活动中获得证书或奖励 在国内外有较高影响力的创作类活动或学科竞赛中获奖 论文在下列任一学会年会中获奖： 国际传播学会 国际媒介与传播研究学会 新闻与大众传播教育学会 欧洲传播研究与教育学会 以及国内一级学会 取得其他重要国际传播实践与理论成果，需提供证明 国家网络传播与社会治理人才培养计划 关键词：偏学术，看科研成果 申请者在校前三年综合测评在专业或班级前50%，且在校前三年必修限选课GPA排名在专业或班级前20% 申请者应对媒体大数据、社会治理、社会计算等研究方向具有浓厚的兴趣，相关学科的基础课程及专业课程成绩优异，科研设想具有创新性，具有相关研究基础和研究经历者优先 综合评价成绩由学业成绩、科研能力评价分数组成，成绩占比之和为100%。其中，学业成绩占比为40%，科研能力评价分数占比为60% 满足下列条件之一，不受第1条限制： 参加国家级学科和学术竞赛并取得优异成绩 在重大影响力的科研机构或国家重点实验室实习3个月以上并取得科研成果 在大数据、社会治理、社会计算等领域有特殊专长，并提供相关支撑材料 翻译人才培养计划 关键词：工科直接下一位 大学本科为外语专业、翻译专业或跨文化传播类等相关专业 申请者在校前三年综测总排名在班级或专业前50%，且GPA在班级或专业前20% 外国语符合下列条件之一： 大学英语六级在530分及以上 雅思成绩在7分及以上 CATTI笔译三级及以上 英语专业四级良好及以上 其他语种相应等级 学科实践类满足下列条件之一： 曾在国际活动、会议、赛事等项目中承担翻译任务 曾在媒体与跨文化传播领域有较长时间的实习经历 曾在学科竞赛或创作类活动中获得奖励 对于在某方面有特殊才能的学生，满足下列条件之一，不受第2条限制： 有译著、影视翻译作品或新闻翻译作品出版或公开发布 曾在重大国际传播活动中担任翻译 有公开发表具有较高水平的学术论文、著作、专利等 曾参加国内国际的高水平学术会议并发言 曾在国内外有影响力的重大竞赛中获奖 其他 退役大学生士兵计划、乡村振兴教育帮扶计划和高水平艺术团计划，请直接参考文件。 相关通知及公示下载 Download files 推免通知及公示下载 有任何问题可以直接在评论区提问！","categories":[{"name":"分享","slug":"分享","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/"},{"name":"推免","slug":"分享/推免","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/%E6%8E%A8%E5%85%8D/"}],"tags":[]},{"title":"RGB文件三通道分量熵计算","slug":"rgb-hist","date":"2022-09-22T02:36:41.000Z","updated":"2022-09-22T02:51:21.048Z","comments":true,"path":"2022/09/22/rgb-hist/","link":"","permalink":"https://pyxblog.cn/2022/09/22/rgb-hist/","excerpt":"","text":"基于python的RGB三通道分量熵计算参考代码。 素材 测试图像下载地址： Download test.rgb 256px256px 代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import matplotlib.pyplot as pltimport cv2 as cvimport numpy as npeps = np.spacing(1) # 浮点精度，用于防止log(0)# 读取图像，转化为256*256*3f = open(\"test.rgb\", \"rb\")data = f.read( )f.close( )data = [int(x) for x in data]data = np.array(data).reshape((256, 256, 3)).astype(np.uint8)# 绘制原图和三通道图像预览fig_img = plt.subplots(1, 4)plt.subplot(1, 4, 1)plt.imshow(data)plt.title(\"original\")plt.axis('off')plt.subplot(1, 4, 2)plt.imshow(data[:, :, 0], cmap=\"gray\")plt.title(\"r\")plt.axis('off')plt.subplot(1, 4, 3)plt.imshow(data[:, :, 1], cmap=\"gray\")plt.title(\"g\")plt.axis('off')plt.subplot(1, 4, 4)plt.imshow(data[:, :, 2], cmap=\"gray\")plt.title(\"b\")plt.axis('off')plt.suptitle('image show')plt.show( )# 绘制三通道直方图fig_hist = plt.subplots(3, 1)plt.subplot(3, 1, 1)plt.hist(data[:, :, 0])plt.title('r')plt.subplot(3, 1, 2)plt.hist(data[:, :, 1])plt.title('g')plt.subplot(3, 1, 3)plt.hist(data[:, :, 2])plt.title('b')plt.suptitle('hist')plt.show( )# 计算概率分布p = np.zeros([3, 256])for i in range(3): for j in range(256): for k in range(256): index = data[k][j][i] p[i][index] = p[i][index] + 1# 计算熵H = [0, 0, 0]for i in range(3): tot = p[i].sum( ) p[i] = p[i] / tot for j in range(256): H[i] = H[i] - p[i][j] * np.log2(p[i][j] + eps)print(H) 结果 实验图像： 计算结果： 1[6.856861210882921, 7.178462484835032, 7.229552890551773]","categories":[{"name":"数据压缩","slug":"数据压缩","permalink":"https://pyxblog.cn/categories/%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"numpy","slug":"numpy","permalink":"https://pyxblog.cn/tags/numpy/"},{"name":"matplotlib","slug":"matplotlib","permalink":"https://pyxblog.cn/tags/matplotlib/"}]},{"title":"秋招&实习季，教你制作在线简历","slug":"resume","date":"2022-09-06T13:51:56.000Z","updated":"2022-09-26T01:15:00.000Z","comments":true,"path":"2022/09/06/resume/","link":"","permalink":"https://pyxblog.cn/2022/09/06/resume/","excerpt":"","text":"这篇教程教你制作的简历本质上是部署在Gitee上，依赖Gitee Pages服务的静态页面，制作它需要的知识仅包括前端三件套，即HTML、CSS和Javascript。当然，即使你没有任何基础，也可以按照这篇教程的步骤制作出自己的在线简历。 提前看看我们的简历效果： 个人简历 点击查看 本文参考了镜花水月大佬的开源项目：传送门，感谢开源！ 准备工作 在开始之前，你需要进行一定的准备，包括： 注册一个Gitee账号，并完成实名认证 准备你的简历素材： 一张证件照 一张背景图片 相关文案 注册Gitee并实名 Gitee是一款基于Git的代码托管和研发协作平台，地址是： Gitee 点击访问 注册你的gitee账号，注册成功后自动登录，进入工作台，点击右上角的「头像-账号设置-实名认证」： 仔细阅读实名认证的相关要求，需要注意的是： “身份证照片”必须是照片，而不能是扫描件 手持身份证照片须严格按要求拍摄 单幅图像大小不超过2MB 实名认证通常在1个工作日内审核完毕，周末不算工作日。 网站工具箱 这里给出几个本教程中可以用到的工具性网站： 菜鸟教程 前端三件套现学现用 阿里巴巴矢量素材库 去码头搞点icon 项目的拉取与部署 进入我的仓库： 在线简历项目 ol-resume.gitee.io 点击右上角的「Fork」： 如果能顺便点一下右侧的Star就好了。 代码拉取完成后，点击页面右侧的「管理」，进入项目的基本信息页面： 在基本信息页面，你可以根据自己的需要调整项目的名称和访问路径，并点击下方的保存： 最终的访问路径就是https://xxx.gitee.io/resume/ 修改完成后，点击右侧的「服务」，选择其中的「Gitee Pages」： 勾选「强制使用HTTPS」，点击「启动」，即可完成部署： 至此，你已经完成了部署，如一切操作无误，可以直接点击上方的网站地址，访问我们在教程开始时访问过的页面： 调整内容 在调整内容之前，有些必要的HTML知识和基本工具可以提前了解一下，使你后续的简历编辑工作更加顺利。 Google Chrome开发者工具 如果你使用的是谷歌浏览器（火狐和Microsoft Edge类似），在简历的页面中单击右键，选择「检查」： 点击左侧小方块中的按钮，再点击网页中的某个元素，即可查看该元素在源代码中的位置： 尝试在这里修改文案，发现网页上的内容确实会随之改变： 但是，在开发者工具里进行的修改并不会被保存，因而它起到的作用只是帮我们找到某个想修改的元素在源代码中的位置。真正的源代码文件是项目中的index.html，后续会对其进行详细介绍。 HTML知识储备 一定的html基础可以让你更加灵活地编辑你的简历，如果看不懂也不要紧，可以跳过本部分。 与大家比较熟悉的python和C++不同，HTML不是逻辑语言，而是一种标记语言，即不涉及逻辑关系的语言，仅使用某些约定好的标记，区分不同的网页结构。我们平时阅览的网页内容，可以理解为存放在一个个不同的标签里。 既然是标记语言，就应该有一种规定的标记规则——标签使用尖括号&lt;&gt;包裹，分为单标签和双标签： 双标签较为常见，一般用于储存文本内容或规定网页结构，比如&lt;p&gt;&lt;/p&gt;标签中包裹了段落内容，&lt;ul&gt;&lt;/ul&gt;标签中包裹了无序列表等，可以参考下面的案例； 单标签一般用于储存多媒体元素，如图片、视频等，比如&lt;img src=\"link.jpg\"&gt;是一个图片标签，可以显示图片link.jpg，可以参考下面的案例； 文本标签 源码效果1234567891011&lt;span&gt;纯文本标签span&lt;/span&gt;&lt;p&gt;段落标签p&lt;/p&gt;&lt;b&gt;加粗文本标签b&lt;/b&gt;&lt;ul&gt; 无序列表ul &lt;li&gt;列表的行li&lt;/li&gt; &lt;li&gt;列表的行li&lt;/li&gt;&lt;/ul&gt;分割线&lt;hr/&gt;换行符&lt;br/&gt;&lt;mark&gt;标记&lt;/mark&gt;纯文本标签span 段落标签p 加粗文本标签b 无序列表ul 列表的行li 列表的行li 分割线 换行符 标记 媒体标签 本项目中应用到的媒体标签主要有两种：图像标签&lt;img&gt;和矢量图标签&lt;svg&gt;，其中： 图像标签&lt;img&gt;的属性包括 src即图像的地址，本项目中采用相对路径的形式引用图片 alt即图像的描述，本项目中可有可无 给出一个完整的图像标签案例以供参考： 源码效果1&lt;img src=&quot;https://img-1306037672.cos.ap-beijing.myqcloud.com/avatar.jpeg&quot; alt=&quot;avatar&quot;&gt; 矢量图标签&lt;svg&gt;在本项目中主要通过之前提到的iconfonts获取，我们可能需要调整的只有它的宽和高，即width和height属性。 在iconfonts中选择想要的素材后，点击「下载」图标： 预设合适的矢量图大小，点击「复制SVG代码」，后续插入到index.html中即可。 编辑index.html 编辑文件index.html有两种方式——下载编辑和在线编辑，由于本文的定位是“零基础”，因而采用在线编辑的方式给出参考教程，如有合适的代码编辑器，可以选择下载后编辑，下载方式： 下载到本地编辑的好处是，可以在本地使用浏览器打开index.html，实时地查看你的修改给它带来了什么变化，而如果采用在线修改的方式，每次都要重新部署后才可以通过链接访问，因此我建议对html语言没有太多了解的朋友，优先选择下载编辑，一边改一边看着。 我们点击「Web IDE」，进入在线编辑页面： 选择右侧的index.html文件，开始编辑： 别紧张，不是要你写代码，是要你改文案。 到这一步，我们可以结合之前提到过的Google Chrome开发者工具，定点修改自己想调整的内容，如之前查看的标题： 代码源文件中，我写了很多注释，可以参考注释修改内容。 修改时，点击编辑器左上方的小加号，可以实现代码的暂存，点击下方的提交，可以将所有修改保存到项目，需要注意，每次提交的时候，都需要在“提交信息”栏中记录本次的更新内容，且每次提交前都需要先暂存，再提交： 每次修改，要想生效，都需要重新部署Gitee Pages服务，具体方法是点击「服务」-「更新」。 由于Gitee Pages服务的违规内容检测非常敏感，建议你在调整内容的时候进行频繁的更新，以防改了一堆内容，结果违规了，还要一点点去找违规在哪里。 插入图片 由于本文的定位是“零成本”，因此没有租对象存储，而是采用将图片放置在项目路径assets/images/中，再采用相对路径的方式调用，如简历中的头像，在源代码中是这样的： 我们可以看到，&lt;img&gt;标签的属性src值为assets/images/avatar.jpeg，对应我们项目中的： 因此，如果我们需要修改图片，或插入新图片，只需要将图片上传到项目中，再使用&lt;img&gt;标签引用即可。为方便管理，我们统一将图片存放在assets/images/路径下，图片名尽量不含中文。 修改图标 由于上传图片有点麻烦，且万一图床崩了，icon也无法正常显示，因此简历中采用矢量图的形式加载icon，矢量图素材主要来源于阿里巴巴矢量素材库，使用时只要将其添加到对应的文本之前，即可正常显示。 以“个人能力”旁边的图表为例，首先找到它的位置： 在编辑器中，可以使用快捷键control+f实现查找功能，以便找到对应的位置，macOS用户的快捷键是command+f 向右滚动少许，可以看出它的宽和高都是25px，为免影响整体的布局和logo大小的一致性，新的logo大小也应该是25px： 我们在iconfonts中找到合适的图标，复制SVG代码： 像这样从下往上选择一整行，直接粘贴即可： 进阶 如果你有一定的前端基础，可以自行调整assets/css路径下的CSS样式。想学习的话，也可以参考下面的教程： HTML教程 决定了网页的基本结构 CSS教程 决定了网页的样式 JavaScript教程 决定了网页的交互 上面的教程讲解非常清晰，并且具有直观、可运行的代码示例，可供参考学习。 如有问题，可直接在评论区留言，也可添加我的微信询问！","categories":[{"name":"小技巧","slug":"小技巧","permalink":"https://pyxblog.cn/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}],"tags":[{"name":"前端","slug":"前端","permalink":"https://pyxblog.cn/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"scrapy爬虫实战03-爬取其他文件格式","slug":"python-spider-scrapy3","date":"2022-08-06T16:15:29.000Z","updated":"2022-08-06T16:18:39.303Z","comments":true,"path":"2022/08/07/python-spider-scrapy3/","link":"","permalink":"https://pyxblog.cn/2022/08/07/python-spider-scrapy3/","excerpt":"","text":"本次实战中，我们以图片为例，演示使用Scrapy框架爬取非文本内容的方法。 在前面两次的Scrapy框架爬虫实战中，已经对基础操作有了较为详细的解释说明，因此本次教程中的基础操作将不再过多赘述。 目标网站：传送门 爬虫编写 我们以CrawlSpider为工具进行爬取。 创建CrawlSpider爬虫 在命令行中创建爬虫： 1234cd zcoolscrapy startproject zcoolcd zcoolscrapy genspider -t crawl zcoolSpider https://www.zcool.com.cn/ 基础设置 进行一些常规化的基础设置，后续使用Scrapy框架时可以按照这样的思路直接往下进行。 创建start.py 创建start.py以实现在pycharm内运行Scrapy爬虫 12from scrapy import cmdlinecmdline.execute(&quot;scrapy crawl zcoolSpider&quot;.split(&quot; &quot;)) 关闭协议、设置ua 在settings.py中关闭那个君子协议，然后设置好自己的user-agent 1234567891011121314BOT_NAME = &#x27;zcool&#x27;SPIDER_MODULES = [&#x27;zcool.spiders&#x27;]NEWSPIDER_MODULE = &#x27;zcool.spiders&#x27;# Obey robots.txt rulesROBOTSTXT_OBEY = False# Override the default request headers:DEFAULT_REQUEST_HEADERS = &#123; &#x27;Accept&#x27;: &#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;, &#x27;Accept-Language&#x27;: &#x27;en&#x27;, &#x27;User-Agent&#x27; : &#x27;我的user-agent&#x27;&#125; 设置初始页面 设置一下zcoolSpider.py（就是爬虫文件）里的start_urls，本次实战中我们爬取的是“精选部分”，页面链接在这：传送门 123name = &#x27;zcoolSpider&#x27; allowed_domains = [&#x27;zcool.com.cn&#x27;] start_urls = [&#x27;https://www.zcool.com.cn/discover/0!3!0!0!0!!!!1!1!1&#x27;] 编写灵魂——rules规则 页码对应url 不难找到不同页码对应链接的规律： 均为https://www.zcool.com.cn/discover/0!3!0!0!0!!!!1!1!+页码的形式 规则（正则表达式）应该这样写： 1Rule(LinkExtractor(allow=r&#x27;.+0!3!0!0!0!!!!1!1!\\d+&#x27;),follow=True) 详情页 详情页的规则也很明显，均为https://www.zcool.com.cn/work/+一串字母+=.html 规则（正则表达式）应该这样写： 1Rule(LinkExtractor(allow=r&#x27;.+work/.+html&#x27;),follow=False,callback=&quot;parse_detail&quot;) 数据解析与存储 上面已经写好了rules，使crawlSpider有了自己找到每一个详情页的能力，接下来我们就处理这些详情页。 编写回调函数parse_details 由于每个详情页里都有很多张图，所以我们期望把每一页里的图放在同一个文件夹里，然后以那一页的标题为文件名，这样便于我们以后查看。因此，在回调函数中，我们需要获取的内容主要有两个：标题和图片链接 获取标题 12title = response.xpath(&quot;//div[@class=&#x27;details-contitle-box&#x27;]/h2/text()&quot;).getall() # getall返回列表title = &quot;&quot;.join(title).strip() # 用于将列表拼接并删掉首尾的空格 获取图片url 利用div标签的class属性，定位图片的链接 1image_urls = response.xpath(&quot;//div[@class=&#x27;photo-information-content&#x27;]/img/@src&quot;).getall() ps. 我们可以在插件XPath Helper中验证自己找的xpath路径是否正确，如图： 的确是可以成功获取url 编写items.py 12345import scrapyclass ZcoolItem(scrapy.Item): title = scrapy.Field() # 标题 image_urls = scrapy.Field() # 图片链接 images = scrapy.Field() # 图片本身 在zcoolSpider.py中调用items.py 12345678from ..items import ZcoolItem...class ZcoolspiderSpider(CrawlSpider): ... def parse_detail(self, response): ... item = ZcoolItem(title=title,image_urls=image_urls) return item 在setting.py中打开piplines，并编写文件存储路径 12345678import osIMAGES_STORE = os.path.join(os.path.dirname(os.path.dirname(__file__)),&#x27;images&#x27;)# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = &#123; &#x27;zcool.pipelines.ZcoolPipeline&#x27;: 300,&#125; 其中os.path.dirname的作用是获取上层文件夹路径，__file__就是只这个文件本身，os.path.join则实现了将路径拼接的作用。 编写piplines.py 12345678910111213141516171819from scrapy.pipelines.images import ImagesPipelinefrom zcool import settings # 这是想调用settings.py里写的IMAGE_STOREimport osimport re # 正则表达式库class ZcoolPipeline(ImagesPipeline): def get_media_requests(self, item, info): media_requests = super(ZcoolPipeline, self).get_media_requests(item,info) for media_request in media_requests: media_request.item = item return media_requests def file_path(self, request, response=None, info=None, *, item=None): origin_path = super(ZcoolPipeline, self).file_path(request, response, info) # 先执行一遍原函数 title = request.item[&#x27;title&#x27;] title = re.sub(r&#x27;[\\\\/:\\*\\?&quot;&lt;&gt;\\|]&#x27;,&quot;&quot;,title) # 删除非法字符 save_path = os.path.join(settings.IMAGES_STORE,title) image_name = origin_path.replace(&quot;full/&quot;,&quot;&quot;) return os.path.join(save_path,image_name) 注意到上面的title = re.sub(r'[\\\\/:\\*\\?\"&lt;&gt;\\|]',\"\",title)一句中，因为我们想用详情页的标题作为文件夹名，但文件夹名中不可以出现这些字符：\\ / : * ? \" &lt; &gt; |，因此我们要用正则表达式的方法，把标题中的这些字符删除。 至此，我们编写完了本次实战的爬虫，运行可得结果如下： 最终代码参考： zcoolSpider.py 123456789101112131415161718192021import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Rulefrom ..items import ZcoolItemclass ZcoolspiderSpider(CrawlSpider): name = &#x27;zcoolSpider&#x27; allowed_domains = [&#x27;zcool.com.cn&#x27;] start_urls = [&#x27;https://www.zcool.com.cn/discover/0!3!0!0!0!!!!1!1!1&#x27;] rules = ( Rule(LinkExtractor(allow=r&#x27;.+0!3!0!0!0!!!!1!1!\\d+&#x27;),follow=True), Rule(LinkExtractor(allow=r&#x27;.+work/.+html&#x27;),follow=False,callback=&quot;parse_detail&quot;) ) def parse_detail(self, response): image_urls = response.xpath(&quot;//div[@class=&#x27;photo-information-content&#x27;]/img/@src&quot;).getall() title = response.xpath(&quot;//div[@class=&#x27;details-contitle-box&#x27;]/h2/text()&quot;).getall() title = &quot;&quot;.join(title).strip() item = ZcoolItem(title=title,image_urls=image_urls) return item items.py 12345import scrapyclass ZcoolItem(scrapy.Item): title = scrapy.Field() image_urls = scrapy.Field() images = scrapy.Field() piplines.py 123456789101112131415161718from scrapy.pipelines.images import ImagesPipelinefrom zcool import settingsimport osimport reclass ZcoolPipeline(ImagesPipeline): def get_media_requests(self, item, info): media_requests = super(ZcoolPipeline, self).get_media_requests(item,info) for media_request in media_requests: media_request.item = item return media_requests def file_path(self, request, response=None, info=None, *, item=None): origin_path = super(ZcoolPipeline, self).file_path(request, response, info) # 先执行一遍原函数 title = request.item[&#x27;title&#x27;] title = re.sub(r&#x27;[\\\\/:\\*\\?&quot;&lt;&gt;\\|]&#x27;,&quot;&quot;,title) save_path = os.path.join(settings.IMAGES_STORE,title) image_name = origin_path.replace(&quot;full/&quot;,&quot;&quot;) return os.path.join(save_path,image_name) settings.py 123456789101112131415161718192021222324252627BOT_NAME = &#x27;zcool&#x27;SPIDER_MODULES = [&#x27;zcool.spiders&#x27;]NEWSPIDER_MODULE = &#x27;zcool.spiders&#x27;# Obey robots.txt rulesROBOTSTXT_OBEY = False# Override the default request headers:DEFAULT_REQUEST_HEADERS = &#123; &#x27;Accept&#x27;: &#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;, &#x27;Accept-Language&#x27;: &#x27;en&#x27;, &#x27;User-Agent&#x27; : &#x27;我的user-agent&#x27;&#125;# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = &#123; &#x27;zcool.pipelines.ZcoolPipeline&#x27;: 300,&#125;import osIMAGES_STORE = os.path.join(os.path.dirname(os.path.dirname(__file__)),&#x27;images&#x27;)","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/"},{"name":"实战","slug":"爬虫/实战","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/tags/%E7%88%AC%E8%99%AB/"},{"name":"scrapy","slug":"scrapy","permalink":"https://pyxblog.cn/tags/scrapy/"}]},{"title":"scrapy爬虫实战02-CrawlSpider入门","slug":"python-spider-scrapy2","date":"2022-08-06T16:12:29.000Z","updated":"2022-08-06T16:16:02.052Z","comments":true,"path":"2022/08/07/python-spider-scrapy2/","link":"","permalink":"https://pyxblog.cn/2022/08/07/python-spider-scrapy2/","excerpt":"","text":"目标网站：传送门 CrawlSpider爬虫的创建 为什么要有CrawlSpider爬虫 spider是Scrapy框架中的基础爬虫，在翻页的时候，我们是这样操作的： 123456# 获取下一页next_href = response.xpath(\"//a[@id='amore']/@href\").get()if next_href: next_url = response.urljoin(next_href) request = scrapy.Request(next_url) yield request 而比spider高级一点的CrawlSpider爬虫，其主要特色是不用手动yield，可以实现遇到指定URL后自动翻页，这就比spider方便一些。 创建CrawlSpider爬虫的命令： 1scrapy genspider -t crawl [爬虫名字] [域名] 参考上面的创建流程，我们在终端中输入下面四行代码： 12345cd /Users/pangyuxuan/lyCrawlSpider # cd到文件夹lyCrawlSpiderscrapy startproject lycs # 创建Scrapy项目，项目名称为lycscd lycs # 进入项目路径scrapy genspider -t crawl lycSpider https://www.lieyunwang.com/ # 创建crawl爬虫，爬虫名称为lycSpider，目标域名为https://www.lieyunwang.com/ 得到了这样的爬虫文件： 与spider的区别——“规则”的定义 spiders文件夹中的lycSpider.py与基础案例中的gsw_spider.py相对应，其默认的代码如下： 123456789101112131415161718192021import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Ruleclass LycspiderSpider(CrawlSpider): name = 'lycSpider' # 没变 allowed_domains = ['https://www.lieyunwang.com/'] # 没变 start_urls = ['http://https://www.lieyunwang.com//'] # 没变 rules = ( # 满足rules时自动爬取，不用再手动yield Rule(LinkExtractor(allow=r'Items/'), callback='parse_item', follow=True), ) def parse_item(self, response): item = {} #item['domain_id'] = response.xpath('//input[@id=\"sid\"]/@value').get() #item['name'] = response.xpath('//div[@id=\"name\"]').get() #item['description'] = response.xpath('//div[@id=\"description\"]').get() return item 其中： LinkExtractor 使用LinkExtractor可以在页面中自动找到所有满足规则的url，实现自动的爬取。 1class scrapy.linkextractors.LinkExtractor(allow = (),deny = (),allow_domains = (),deny_domains = (),deny_extensions = None,restrict_xpaths = (),tags = ('a','area'),attrs = ('href'),canonicalize = True,unique = True,process_value = None) 常用参数： allow ：允许的url——所有满足这个正则表达式的url都会被提取。 deny ：禁止的url——所有满足这个正则表达式的url都不会被提取。 allow_domains ：允许的域名——只有在这个里面指定的域名的url才会被提取。 deny_domains ：禁止的域名——所有在这个里面指定的域名的url都不会被提取。 restrict_xpaths ：使用xpath——和allow共同过滤链接。 Rule 用来定义这个url爬取后的处理方式，比如是否需要跟进，是否需要执行回调函数等。 1class scrapy.spiders.Rule(link_extractor, callback = None, cb_kwargs = None, follow = None,process_links = None, process_request = None) 常用参数： link_extractor ：一个LinkExtractor对象，用于定义爬取规则 callback ：满足这个规则的url，应该要执行哪个回调函数。 follow ：指定根据该规则从response中提取的链接是否需要跟进，也就是需不需要找这个链接的页面里还有没有其他符合要求的链接 process_links ：从link_extractor中获取到链接后会传递给这个函数，用来过滤不需要爬取的链接 实操 先在settings.py里关闭协议、设置ua 123456789# Obey robots.txt rulesROBOTSTXT_OBEY = False# Override the default request headers:DEFAULT_REQUEST_HEADERS = { 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en', 'User-Agent' : '我的user-'} 我们打开猎云网主页https://www.lieyunwang.com/ 调整start_urls 在页码1处点击检查，点击下方的链接进入第一页，复制此时浏览器内的链接即可： 1start_urls = ['https://www.lieyunwang.com/latest/p1.html'] 编写rules 我们的思路是： 找到每一页的链接，再从每一页里找每一篇文章的链接。 规则应该是这样： 1234rules = ( Rule(LinkExtractor(allow=r'/latest/p\\d+\\.html'), follow=True), Rule(LinkExtractor(allow=r'/archives/\\d+'), callback=\"parse_detail\", follow=False), ) 其中： 第一条规则用于找到每一页，因为页面的格式都是这样： 所以使用正则表达式匹配字符，即为/latest/p\\d+\\.html，其中： 页码可能是两位数，所以用d+ .是特殊符号，需要额外加一个反斜杠\\ 此外，找到每一页并不是终点，我们还需要找这一页里的文章，也就是还需要从这一页里面找其他链接，所以follow=True 第二条规则用于找每一页里的所有文章，因为文章的格式都是这样： 所以我们的正则表达式写为/archives/\\d+ 此外，我们找到文章以后，并不需要通过该文章找其他文章，所以follow=False，另外我们需要调用函数来获取它的内容了，所以callback=\"parse_detail\"，其中parse_detail是后面要写的函数 在parse_detail函数里测试一下我们的rules写没写对： 1234567891011121314151617181920import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Ruleclass LycspiderSpider(CrawlSpider): name = 'lycSpider' allowed_domains = ['lieyunwang.com'] start_urls = ['https://www.lieyunwang.com/latest/p1.html'] rules = ( Rule(LinkExtractor(allow=r'/latest/p\\d+\\.html'), follow=True), Rule(LinkExtractor(allow=r'/archives/\\d+'), callback=\"parse_detail\", follow=False), ) def parse_detail(self, response): print(\"=\"*50) print(response.url) # 输出找到的url来验证 print(\"=\"*50) 哈哈对了！不对我会写在博客里吗 ps. 运行方法与前面的运行方法一致，都是新建一个start.py文件，可以先跳到后面去看一下start.py文件怎么写，也可以省略这一步测试（反正它一定是对的就是了，哼） 数据解析与存储 方便起见，我们只爬取文章的标题title、导语conclude和段落内容content 数据解析和存储的方式与之前的完全一样，在这里直接给出操作流程，不做过多的赘述： 1. 使用xpath获取三个部分的内容 直接右键-检查-copy xpath即可 1234567def parse_detail(self, response): title = response.xpath('//*[@id=\"fixed_container\"]/div[1]/div[2]/div[1]/h1/text()').getall() title = \"\".join(title).strip() content = response.xpath('//*[@id=\"main-text-id\"]').getall() content = \"\".join(content).strip() conclude = response.xpath('//*[@id=\"fixed_container\"]/div[1]/div[2]/div[3]').getall() conclude = \"\".join(conclude).strip() 2. 在settings.py中解除piplines的注释 12345# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = { 'lycs.pipelines.LycsPipeline': 300,} 3. 编写piplines.py 12345678910111213from itemadapter import ItemAdapterimport jsonclass LycsPipeline: def open_spider(self,spider): self.fp = open(\"简讯.txt\",'w',encoding='utf-8') def process_item(self, item, spider): self.fp.write(json.dumps(dict(item),ensure_ascii=False)+'\\n') return item def close_spider(self,spider): self.fp.close() 4. 编写items.py 12345import scrapyclass LycsItem(scrapy.Item): title = scrapy.Field() # 标题 content = scrapy.Field() # 导语 conclude = scrapy.Field() # 结论 5. 在lycSPider.py里导入items并传入要保存的参数 1234567... # 省略其他部分代码from ..items import LycsItem... # 省略其他部分代码 def parse_detail(self, response): ... # 省略其他部分代码 item = LycsItem(title=title,content=content,conclude=conclude) return item # 写yield应该也可以 运行 CrawlSpider的运行与spider完全一样，都是在终端输入命令以运行，方便起见，我们还是编写start.py文件来实现在pycharm里的运行： 12from scrapy import cmdlinecmdline.execute(\"scrapy crawl lycSpider\".split(\" \")) ps. 为了秀一把这里给出了另一种发送命令的方式，本质上与之前那一种是一样的。 直接成功！ 总结 相比于spider，CrawlSpider的核心优势就是可以自己找新的页面，不用我们手动设置翻页方法。 最终的参考代码 lycSpider.py 123456789101112131415161718192021222324import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Rulefrom ..items import LycsItemclass LycspiderSpider(CrawlSpider): name = 'lycSpider' allowed_domains = ['lieyunwang.com'] start_urls = ['https://www.lieyunwang.com/latest/p1.html'] rules = ( Rule(LinkExtractor(allow=r'/latest/p\\d+\\.html'), follow=True), Rule(LinkExtractor(allow=r'/archives/\\d+'), callback=\"parse_detail\", follow=False), ) def parse_detail(self, response): title = response.xpath('//*[@id=\"fixed_container\"]/div[1]/div[2]/div[1]/h1/text()').getall() title = \"\".join(title).strip() content = response.xpath('//*[@id=\"main-text-id\"]').getall() content = \"\".join(content).strip() conclude = response.xpath('//*[@id=\"fixed_container\"]/div[1]/div[2]/div[3]').getall() conclude = \"\".join(conclude).strip() item = LycsItem(title=title,content=content,conclude=conclude) return item items.py 12345import scrapyclass LycsItem(scrapy.Item): title = scrapy.Field() content = scrapy.Field() conclude = scrapy.Field() piplines.py 1234567891011from itemadapter import ItemAdapterimport jsonclass LycsPipeline: def open_spider(self,spider): self.fp = open(\"简讯.txt\",'w',encoding='utf-8') def process_item(self, item, spider): self.fp.write(json.dumps(dict(item),ensure_ascii=False)+'\\n') return item def close_spider(self,spider): self.fp.close() settings.py 123456789101112131415161718192021222324252627BOT_NAME = 'lycs'SPIDER_MODULES = ['lycs.spiders']NEWSPIDER_MODULE = 'lycs.spiders'# Obey robots.txt rulesROBOTSTXT_OBEY = False# Override the default request headers:DEFAULT_REQUEST_HEADERS = { 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en', 'User-Agent' : '我的user-agent'}# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = { 'lycs.pipelines.LycsPipeline': 300,}# Override the default request headers:DEFAULT_REQUEST_HEADERS = { 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en', 'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36'}","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/"},{"name":"实战","slug":"爬虫/实战","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/tags/%E7%88%AC%E8%99%AB/"},{"name":"scrapy","slug":"scrapy","permalink":"https://pyxblog.cn/tags/scrapy/"}]},{"title":"Scrapy爬虫实战01-古诗文网","slug":"python-spider-scrapy1","date":"2022-08-06T16:06:53.000Z","updated":"2022-08-06T16:12:16.581Z","comments":true,"path":"2022/08/07/python-spider-scrapy1/","link":"","permalink":"https://pyxblog.cn/2022/08/07/python-spider-scrapy1/","excerpt":"","text":"ps. 案例制作时的操作环境是MacOS，如果是windows用户，下文中提到的“终端”指的就是cmd命令行窗口。 pps. 本文省略了安装过程，尚未安装scrapy的用户可以直接在pycharm的preference内搜索安装。 目标网站：传送门 任务：使用Scrapy框架爬虫，爬取“推荐”中共10页的古诗题目、作者、朝代和内容 ps. 各类教程都拿它举例子，古诗文网好惨 项目创建 创建Scrapy爬虫项目需要在终端中进行 先打开一个文件路径，即你希望的爬虫文件存放路径，比如我放在创建好的spidertest 文件夹中： 1cd /Users/pangyuxuan/spidertest # 这是文件夹路径 使用命令创建项目： 1scrapy startproject [项目名称] 创建爬虫： 12cd [项目名称] # 先进入项目路径scrapy genspider [爬虫名称] [目标域名] # 再创建爬虫文件 至此你已经创建好了scrapy爬虫文件，它应该长这样： 其中[项目名称]为gsw_test，[爬虫名称]为gsw_spider 综上，创建一个基本的scrapy爬虫文件，一共在终端的命令行中输入了4行代码： 12345cd /Users/pangyuxuan/spidertest # 打开一个文件路径，作为爬虫的存放路径scrapy startproject gsw_test # 创建scrapy项目，名为gsw_testcd gsw_test # 打开项目路径scrapy genspider gsw_spider https://www.gushiwen.org # 创建scrapy爬虫，爬虫名为gsw_spider，目标域名为 https://www.gushiwen.org 各个文件的作用 后续的编写还是依赖pycharm，所以在pycharm中打开项目文件： 其中各个文件的作用如下： settings.py：用来配置爬虫的，比如设置User-Agent、下载延时、ip代理。 middlewares.py：用来定义中间件。 items.py：用来提前定义好需要下载的数据字段。 pipelines.py：用来保存数据。 scrapy.cfg：用来配置项目。 爬取第一页的内容并保存 以下内容请按顺序阅读并实现 设置settings.py 先在settings.py中做两项工作： 设置robots.txt协议为“不遵守” robots.txt是一个互联网爬虫许可协议，默认是True（遵守协议），如果遵守的话大部分网站都无法进行爬取，所以先把这个协议的状态设为不遵守 12# Obey robots.txt rulesROBOTSTXT_OBEY = False ps. 所以这个协议的意义是什么。。。 配置请求头（设置user-agent） 123456# Override the default request headers:DEFAULT_REQUEST_HEADERS = &#123; &#x27;Accept&#x27;: &#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;, &#x27;Accept-Language&#x27;: &#x27;en&#x27;, &#x27;user-agent&#x27; : &#x27;我自己的ua&#x27;&#125; 主要工作——编写gsw_spider.py 123456789import scrapyclass GswSpiderSpider(scrapy.Spider): # 我们的代码都写在这个类里面 name = &#x27;gsw_spider&#x27; # 爬虫的名字 allowed_domains = [&#x27;https://www.gushiwen.org&#x27;] # 目标域名 start_urls = [&#x27;http://https://www.gushiwen.org/&#x27;] # 爬虫的起始网页 def parse(self, response): 目前的爬虫起始网页start_urls是自动生成的，我们把它换成古诗文网的第一页 1start_urls = [&#x27;https://www.gushiwen.cn/default_1.aspx&#x27;] 为了使打印出来的结果更加直观，我们编写myprint函数如下： 1234def myprint(self,value): print(&quot;=&quot;*30) # 在输出内容的上、下加一些&#x27;=&#x27;，找起来方便 print(value) print(&quot;=&quot;*30) 然后我们尝试打印一下当前爬取到的内容，应该为古诗文网第一页的信息。 目前为止，gsw_spider.py被改成了这样： 12345678910111213141516import scrapyclass GswSpiderSpider(scrapy.Spider): name = &#x27;gsw_spider&#x27; # 爬虫的名字 allowed_domains = [&#x27;https://www.gushiwen.org&#x27;] # 目标域名 start_urls = [&#x27;https://www.gushiwen.cn/default_1.aspx&#x27;] # 起始页面 def myprint(self,value): print(&quot;=&quot;*30) print(value) print(&quot;=&quot;*30) def parse(self, response): self.myprint(response.text) # 打印网页源代码 运行的方法 scrapy爬虫需要在终端里输入命令来运行，输入命令如下： 1scrapy crawl gsw_spider # gsw_spider是爬虫名 方便起见，我们在项目目录里新建一个start.py，通过cmdline库里的函数来向终端发送命令，这样就不用不停地切换窗口了，而且运行结果可以在pycharm里直接展现，这样就与我们之前学的爬虫一样了。 后续我们无论修改哪个代码，都是运行start.py这个文件。 123from scrapy import cmdlinecmds = [&#x27;scrapy&#x27;,&#x27;crawl&#x27;,&#x27;gsw_spider&#x27;] # 拼接命令语句cmdline.execute(cmds) # 执行 点击运行，可以在运行窗口中看到结果： 截至目前为止，我们已经获取了网页源代码，接下来的工作就是从源代码中解析想要的数据了。 无需导入新的库，Scrapy框架为我们内置了许多函数，使我们仍可以用之前学习的数据解析知识（xpath、bs4和正则表达式）来完成数据提取。 使用xpath提取数据 使用xpath语法提取数据，返回的结果是选择器列表类型SelectorList，选择器列表里包含很多选择器Selector，即： response.xpath返回的是SelectorList对象 SelectorList存储的是Selector对象 我们获取一下所有包含古诗标题的标签，输出返回值类型，以验证上面的结论： 12345def parse(self, response): gsw_divs = response.xpath(&quot;//div[@class=&#x27;left&#x27;]/div[@class=&#x27;sons&#x27;]&quot;) self.myprint(type(gsw_divs)) # 打印获取到的div标签集的类型 for gsw_div in gsw_divs : self.myprint(type(gsw_div)) # 打印标签集中的每个元素的类型 运行结果： 使用get()或getall()函数从选择器类型的数据中提取需要的数据： get()返回选择器的第一个值（字符串类型） getall()返回选择器的所有值（列表类型） 12345for gsw_div in gsw_divs : title_get = gsw_div.xpath(&quot;.//b/text()&quot;).get() title_getall = gsw_div.xpath(&quot;.//b/text()&quot;).getall() self.myprint(title_get) # 打印get函数的结果 self.myprint(title_getall) # 打印getall函数的结果 输出： 我们共提取标题、朝代、作者、内容四部分信息，gsw_spider.py代码如下： 1234567891011121314151617181920212223242526import scrapyclass GswSpiderSpider(scrapy.Spider): name = &#x27;gsw_spider&#x27; # 爬虫的名字 allowed_domains = [&#x27;https://www.gushiwen.org&#x27;] # 目标域名 start_urls = [&#x27;https://www.gushiwen.cn/default_1.aspx&#x27;] # 起始页面 def myprint(self,value): # 用于打印的函数 print(&quot;=&quot;*30) print(value) print(&quot;=&quot;*30) def parse(self, response): gsw_divs = response.xpath(&quot;//div[@class=&#x27;left&#x27;]/div[@class=&#x27;sons&#x27;]&quot;) for gsw_div in gsw_divs : title = gsw_div.xpath(&quot;.//b/text()&quot;).get() # 题目 source = gsw_div.xpath(&quot;.//p[@class=&#x27;source&#x27;]/a/text()&quot;).getall() # 朝代+作者 # source是getall函数的返回值，是个列表，故可以直接用下标调用 dynasty = source[0] # 朝代 writer = source[1] # 作者 self.myprint(source) content = gsw_div.xpath(&quot;.//div[@class=&#x27;contson&#x27;]//text()&quot;).getall() # 诗文内容 # 用//text()获取标签下的所有文本 content = &#x27;&#x27;.join(content).strip() # 将列表拼接,并用strip()删除前后的换行/空格 你可以在任意地方插入self.myprint(内容)来进行打印，以验证数据是否被成功提取 接下来就是保存数据，我们先在items.py中配置好要保存的数据有哪些。 配置items.py 还记得这个文件是干什么用的吗？ items.py：用来提前定义好需要下载的数据字段。 一共有上述四部分内容需要保存，因此我们的items.py应该这样写： 1234567import scrapyclass GswTestItem(scrapy.Item): title = scrapy.Field() # 标题 dynasty = scrapy.Field() # 朝代 writer = scrapy.Field() # 作者 content = scrapy.Field() # 内容 其中Field()可以理解为一种普适的变量类型，不管是字符串还是列表，都用scrapy.Field()来接收。 在gsw_spider.py里导入items 定义完items.py后，我们在gsw_spiders.py里导入它。需要注意的是，gsw_spiders.py在spiders文件夹里，也就是说items.py在gsw_spiders.py的上层目录中： 因此导入时，应该这样写： 1from ..items import GswTestItem # ..表示上层目录 导入后，我们将对应参数传入，然后使用yield关键字进行返回 12item = GswTestItem(title=title,dynasty=dynasty,writer=writer,content=content)yield item 进入pipelines.py和settings.py 先在settings.py里把pipelines.py打开： 123456# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = &#123; &#x27;gsw_test.pipelines.GswTestPipeline&#x27;: 300, # 300是这个pipeline的优先级，代表了执行顺序，数值越小优先级越大&#125; 再编写pipelines.py 123456789101112131415161718from itemadapter import ItemAdapterimport json # 记得自己导入json库class GswTestPipeline: def open_spider(self,spider): self.fp = open(&quot;古诗文.txt&quot;,&#x27;w&#x27;,encoding=&#x27;utf-8&#x27;) # 制定文件名和编码格式 def process_item(self, item, spider): self.fp.write(json.dumps(dict(item),ensure_ascii=False)+&#x27;\\n&#x27;) # dict函数将item转化为字典 # json.dumps()将字典格式的item转换为json字段 # 参数ensure_ascii=False,用于存储中文 # +&#x27;\\n&#x27;用于将保存的内容自动换行 return item def close_spider(self,spider): # 关闭文件 self.fp.close() 上面的open_spider函数和close_spider函数虽然不是自带的，但它是一种模版化的函数（套路），是一种Scrapy框架提供的高效的文件存储形式。 我们自己写的时候，只要按上述样式编（默）写即可，根据自己的需求修改存储文件的文件名、格式和编码方式，但不能改变两个函数名！ 现在我们运行start.py，就会发现路径下多了一个古诗文.txt，打开以后是这样： 至此，第一页爬取成功！（不要在意为什么只爬了一点就结束了，先往下看，最后会有修正） 爬取后续内容 爬取了第一页的内容以后，我们还需要继续往后寻找，先来找一下第二页的url： 右键检查“下一页”按钮以获取下一页的url 为了测试寻找下一页的功能，我们暂时忽略之前的代码 1234def parse(self, response): next_href = response.xpath(&quot;//a[@id=&#x27;amore&#x27;]/@href&quot;).get() # 获取href属性 next_url = response.urljoin(next_href) # 给/default_2.aspx添加前缀域名使其变完整 self.myprint(next_url) # 输出以验证 找到了！ 接下来我们就用一个request来接收scrapy.Request(next_url)的返回值，并使用yield关键字来返回即可： 1234next_href = response.xpath(&quot;//a[@id=&#x27;amore&#x27;]/@href&quot;).get()next_url = response.urljoin(next_href)request = scrapy.Request(next_url)yield request 需要注意的是，我们需要给“寻找下一页”操作设立一个终止条件，当下一页不存在的时候停止访问，所以最后的代码长这个样子： 123456# 获取下一页next_href = response.xpath(&quot;//a[@id=&#x27;amore&#x27;]/@href&quot;).get()if next_href: next_url = response.urljoin(next_href) request = scrapy.Request(next_url) yield request 针对反爬虫机制的修改完善 此时我们的代码是这样的： gsw_spider.py 123456789101112131415161718192021222324252627282930313233import scrapyfrom ..items import GswTestItemclass GswSpiderSpider(scrapy.Spider): name = &#x27;gsw_spider&#x27; # 爬虫的名字 allowed_domains = [&#x27;https://www.gushiwen.org&#x27;] # 目标域名 start_urls = [&#x27;https://www.gushiwen.cn/default_1.aspx&#x27;] def myprint(self,value): print(&quot;=&quot;*30) print(value) print(&quot;=&quot;*30) def parse(self, response): gsw_divs = response.xpath(&quot;//div[@class=&#x27;left&#x27;]/div[@class=&#x27;sons&#x27;]&quot;) for gsw_div in gsw_divs : title = gsw_div.xpath(&quot;.//b/text()&quot;).get() # 古诗题目 source = gsw_div.xpath(&quot;.//p[@class=&#x27;source&#x27;]/a/text()&quot;).getall() # 朝代+作者 # source是getall函数的返回值，是个列表，直接用下标调用 dynasty = source[0] # 朝代 writer = source[1] # 作者 content = gsw_div.xpath(&quot;.//div[@class=&#x27;contson&#x27;]//text()&quot;).getall() # 诗文内容 # 用//text()获取标签下的所有文本 content = &#x27;&#x27;.join(content).strip() # 将列表拼接,并用strip()删除前后的换行/空格 item = GswTestItem(title=title,dynasty=dynasty,writer=writer,content=content) yield item # 获取下一页 next_href = response.xpath(&quot;//a[@id=&#x27;amore&#x27;]/@href&quot;).get() if next_href: next_url = response.urljoin(next_href) request = scrapy.Request(next_url) yield request 运行后，会报这样一个错误：IndexError: list index out of range，意思是“列表的下标索引超过最大区间”。 为什么会有这样的错误呢？ 我们可以在网页上看到，页面上不全是古诗文： 除了古诗文外，这种短句子也是在class=sons的标签下，按照我们的查找方式： 123gsw_divs = response.xpath(&quot;//div[@class=&#x27;left&#x27;]/div[@class=&#x27;sons&#x27;]&quot;)for gsw_div in gsw_divs : source = gsw_div.xpath(&quot;.//p[@class=&#x27;source&#x27;]/a/text()&quot;).getall() 找到图中蓝色的div标签以后，它里面是没有p标签的，也就是说此时的source是个空表，直接调用source[0]那必然是要报错的。 这算是网站的一种反爬虫机制，利用格式不完全相同的网页结构来让你的爬虫报错，太狠了！！ 为了解决这个问题，我们添加try...except结构如下： 123456789101112for gsw_div in gsw_divs : title = gsw_div.xpath(&quot;.//b/text()&quot;).get() source = gsw_div.xpath(&quot;.//p[@class=&#x27;source&#x27;]/a/text()&quot;).getall() try: dynasty = source[0] writer = source[1] content = gsw_div.xpath(&quot;.//div[@class=&#x27;contson&#x27;]//text()&quot;).getall() content = &#x27;&#x27;.join(content).strip() item = GswTestItem(title=title,dynasty=dynasty,writer=writer,content=content) yield item except: print(title) # 打印出错的标题以备检查 这样，上面的报错就被完美解决了。 然鹅，一波未平一波又起，bug永远是生生不息源源不绝的 我们发现了一个新的报错：DEBUG: Filtered offsite request to 'www.gushiwen.cn': &lt;GET https://www.gushiwen.cn/default_2.aspx&gt; 这是因为我们在最开始的allowed_domains里限制了访问的域名：\"https://www.gushiwen.org\" 而到了第二页的时候，网站偷偷把域名换成.cn了！ .cn不是.org，我们的爬虫没法继续访问，所以就停了。这又是这个网站的一个反爬虫机制，我们只需要在allowed_domains里添加一个.cn的域名，这个问题就可以得到妥善的解决： 1allowed_domains = [&#x27;gushiwen.org&#x27;,&#x27;gushiwen.cn&#x27;] 运行可得到期望结果： 最终的古诗文网Scrapy爬虫代码 gsw_spider.py 12345678910111213141516171819202122232425262728293031323334353637import scrapyfrom ..items import GswTestItemclass GswSpiderSpider(scrapy.Spider): name = &#x27;gsw_spider&#x27; # 爬虫的名字 # allowed_domains = [&#x27;https://www.gushiwen.org&#x27;] # 目标域名 allowed_domains = [&#x27;gushiwen.org&#x27;,&#x27;gushiwen.cn&#x27;] start_urls = [&#x27;https://www.gushiwen.cn/default_1.aspx&#x27;] def myprint(self,value): print(&quot;=&quot;*30) print(value) print(&quot;=&quot;*30) def parse(self, response): gsw_divs = response.xpath(&quot;//div[@class=&#x27;left&#x27;]/div[@class=&#x27;sons&#x27;]&quot;) for gsw_div in gsw_divs : title = gsw_div.xpath(&quot;.//b/text()&quot;).get() # 古诗题目 source = gsw_div.xpath(&quot;.//p[@class=&#x27;source&#x27;]/a/text()&quot;).getall() # 朝代+作者 # source是getall函数的返回值，是个列表，直接用下标调用 try: dynasty = source[0] # 朝代 writer = source[1] # 作者 content = gsw_div.xpath(&quot;.//div[@class=&#x27;contson&#x27;]//text()&quot;).getall() # 诗文内容 # 用//text()获取标签下的所有文本 content = &#x27;&#x27;.join(content).strip() # 将列表拼接,并用strip()删除前后的换行/空格 item = GswTestItem(title=title,dynasty=dynasty,writer=writer,content=content) yield item except: print(title) # 获取下一页 next_href = response.xpath(&quot;//a[@id=&#x27;amore&#x27;]/@href&quot;).get() if next_href: next_url = response.urljoin(next_href) request = scrapy.Request(next_url) yield request items.py 123456789101112131415# Define here the models for your scraped items## See documentation in:# https://docs.scrapy.org/en/latest/topics/items.htmlimport scrapyclass GswTestItem(scrapy.Item): # define the fields for your item here like: title = scrapy.Field() dynasty = scrapy.Field() writer = scrapy.Field() content = scrapy.Field() pipelines.py 12345678910111213from itemadapter import ItemAdapterimport jsonclass GswTestPipeline: def open_spider(self,spider): self.fp = open(&quot;古诗文.txt&quot;,&#x27;w&#x27;,encoding=&#x27;utf-8&#x27;) def process_item(self, item, spider): self.fp.write(json.dumps(dict(item),ensure_ascii=False)+&#x27;\\n&#x27;) # dict函数将item转化为字典,再转换为json字段进行保存 return item def close_spider(self,spider): self.fp.close() settings.py 为了看起来简洁一点，注释部分我就都删了 123456789101112131415161718192021BOT_NAME = &#x27;gsw_test&#x27;SPIDER_MODULES = [&#x27;gsw_test.spiders&#x27;]NEWSPIDER_MODULE = &#x27;gsw_test.spiders&#x27;# Obey robots.txt rulesROBOTSTXT_OBEY = False# Override the default request headers:DEFAULT_REQUEST_HEADERS = &#123; &#x27;Accept&#x27;: &#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;, &#x27;Accept-Language&#x27;: &#x27;en&#x27;, &#x27;user-agent&#x27; : &#x27;我的user-agent&#x27;&#125;# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = &#123; &#x27;gsw_test.pipelines.GswTestPipeline&#x27;: 300,&#125; 大功告成！自己试一下吧！","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/"},{"name":"实战","slug":"爬虫/实战","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/tags/%E7%88%AC%E8%99%AB/"},{"name":"scrapy","slug":"scrapy","permalink":"https://pyxblog.cn/tags/scrapy/"}]},{"title":"python爬虫实战演示","slug":"python-spider-demo1","date":"2022-08-06T15:56:53.000Z","updated":"2022-08-06T16:06:17.936Z","comments":true,"path":"2022/08/06/python-spider-demo1/","link":"","permalink":"https://pyxblog.cn/2022/08/06/python-spider-demo1/","excerpt":"","text":"猫眼专业版实时票房数据获取 网址：http://piaofang.maoyan.com/dashboard 错误方法1： 1234import requestsurl = &#x27;http://piaofang.maoyan.com/dashboard&#x27;resp = requests.get(url)print(resp.content.decode(&#x27;utf-8&#x27;)) 点开“检查网页源代码”，发现输出和源代码不一样 问题出在请求头上，连User-agent都没有，稍微走点心的网站都知道你是爬虫了 Ps.user-agent是什么：user-agent会告诉网站，访问者是通过什么工具来请求的，如果是爬虫请求，一般会拒绝；如果是用户浏览器，就会应答。我们在浏览器里获取的user-agent添加到爬虫中，网站检测这项数据时会把它当成你自己用的那个浏览器，以起到瞒天过海的作用。 错误方法2： 1234567import requestsurl = &#x27;http://piaofang.maoyan.com/dashboard&#x27;headers = &#123; # 添加一个请求头 &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36&#x27;&#125;resp = requests.get(url,headers=headers)print(resp.content.decode(&#x27;utf-8&#x27;)) 这下输出和网页源代码一样了，兴高采烈找数据，发现没有！ 原来是因为猫眼专业版的数据是实时更新的，因此它没有保存在静态的网页结构里，而是通过json文件实时发送，所以我们在网页源代码中是找不到数据的，数据在哪呢？ 点开“检查”，在Network里你会发现，网页在不停的请求文件，选中右边的Response，仔细一找，数据就在里面！ 当然，如果你觉得麻烦，这里推荐一个格式解析工具，可以自动把json文件里的代码以更美观的角度呈现。 在线的json解析工具：https://www.json.cn/ 所以，我们请求静态网页的链接，是找不到数据的，而把链接换成发送数据包的链接，就可以得到数据了。 正确方法： 12345678910import requests# 使用json文件里的urlurl = &#x27;http://piaofang.maoyan.com/dashboard-ajax?orderType=0&amp;uuid=176e6479baec8-0cc8072b9a3fd4-171d4b58-13c680-176e6479bafc8&amp;riskLevel=71&amp;optimusCode=10&amp;_token=eJxNkctqw0AMRf9l1sKRRvOyIYtAoaTQRUPaTchi8qgTSuLgmNJS%2Bu%2BVJi4tGO7x1cOS%2FGX6%2Bc40COZ935vGUIVVMGCGq2koEHmk6DlhALP98yySxTqC2fQvd6ZZEXECcdbqLMRYkXMINeIa%2FiGjPJozlxRzGIZLM5lcjrl7zee2OuXuM5%2BrbXea7PL1sOlyv5NJjBScllrAkQHF4RiBVJP0K8rgiyZIqjVDXTQBWQGHDigUiCNQDVZ7OGtHYAZbQhxGcBG4hLwF5gI1cAkFcaJCRHDlEzrDDTz4kixTeB3DI0PkAgGiVnkrB7mBBULdyTMBldG8XIvYKXnxSi8fZIGou%2Fmoh056lDc9imgedfh9f5T%2FKKnXY3sW2j98LJ%2Fb%2BWx2384WT9Op%2Bf4B3HBuKQ%3D%3D&#x27;headers = &#123; &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36&#x27;&#125;resp = requests.get(url,headers=headers)print(resp.content.decode(&#x27;utf-8&#x27;)) 一些其他的动态网页，可能并不是实时更新，但也是采用同样的数据显示方式，这就需要你仔细的找一下数据到底藏在哪个文件里，点开Response后从上往下捋就行了。 当然你也可以使用selenium方法去模拟浏览器的行为，在这里就不细说了 石头阅读模拟登陆 石头阅读是一款免费的小说阅读器，书库覆盖面广，资源丰富，可以免费看各类需要付费的小说，堪称白嫖党的利器，趁此机会安利一下 网址：https://www.stoneread.com/ 登陆在右上角，有点隐蔽： 模拟登陆大体上有两种，即添加cookie和使用post请求添加账号密码。由于后面的实战会涉及到前一种，所以这个实战就先用后一种了。 核心思路是，获取网站用以验证账号密码的url，然后把我们准备好的账号密码以post请求的形式发给它，这样就相当于登陆成功了。 怎么找目标url？ 我们先手动登陆试试，点击登录后，注视着“检查”里的Network栏，你会发现一个“一闪即逝”的文件： \"小老弟，跑的挺快啊\" 我们点击左上角的停止键，就可以获得这个文件，点开就有了url，顺便再抄一下user-agent 翻到下面，有一个“Form Data”，一看就是我们提交的账号密码： 不许盗号！！！ 这个checkbox代表的是那个“下次自动登录”选项，on自然就是表示“勾选” 代码： 1234567891011121314import requestsurl = &#x27;https://www.stoneread.com/login/logincheck?ur=&#x27;headers = &#123; &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36&#x27;&#125;data = &#123; &#x27;username&#x27; : &#x27;kaitoukiddo@yeah.net&#x27;, &#x27;password&#x27; : &#x27;12345ssdlh&#x27;, &#x27;checkbox&#x27; : &#x27;on&#x27;&#125;resp = requests.post(url,headers=headers,data=data)print(resp.content.decode(&#x27;utf-8&#x27;)) 结果中有“登陆成功”字样，和我们看到的页面一致。嘿嘿，成功啦～ 设置代理ip 这个方法它成功几率不太大，因为我用的是免费的代理ip，没氪金怎么会变强呢它就不太稳定。我先把验证方法给一下。 获取免费ip的网址： * 快代理：https://www.kuaidaili.com/free/ * 芝麻代理：http://http.zhimaruanjian.com/ * 太阳代理：http://http.taiyangruanjian.com/ * 讯代理：http://www.xdaili.cn/ * 蚂蚁代理：http://www.mayidaili.com/ * 极光代理：http://www.jiguangdaili.com/ 查看当前ip的请求url：http://www.httpbin.org/ip ps. http://www.httpbin.org/是一个功能很强大的网站，大家可以访问一下康康 我们先不用代理，看一下自己的ip地址 1234import requestsurl = &#x27;http://www.httpbin.org/ip&#x27;resp = requests.get(url)print(resp.text) 这个时候，就会打印出我自己电脑的真实ip 然后我们为它添加代理： 1234567import requestsproxy = &#123; # 免费的代理ip，这会儿估计已经没法用了 &#x27;http&#x27;:&#x27;111.77.197.127:9999&#x27;&#125;url = &#x27;http://www.httpbin.org/ip&#x27;resp = requests.get(url,proxies=proxy)print(resp.text) 这个时候如果你欧了一把，选的代理ip恰好是可以用的，那你就会看到程序打印出了你选的ip地址。 附： urllib库设置代理的方法——ProxyHandler处理器 12345678910111213from urllib import requesturl = &#x27;http://httpbin.org/ip&#x27;#1. 使用ProxyHandler,传入代理构建一个handler,代理的结构是字典handler = request.ProxyHandler(&#123;&#x27;http&#x27;:&#x27;122.193.244.243:9999&#x27;&#125;)#2. 使用上面创建的handler构建一个openeropener = request.build_opener(handler)#3. 使用opener去发送一个请求resp = opener.open(url)print(resp.read()) selenium设置代理的方法 1234options = webdriver.ChromeOptions() # 创建ChromeOptions对象options.add_argument(&quot;--proxy-server=htto://175.43.151.209:9999&quot;) # 代理driver = webdriver.Chrome(executable_path=&quot;/Users/pangyuxuan/Desktop/chromedriver&quot;,chrome_options=options) # 在driver路径后添加代理参数driver.get(&quot;http://httpbin.org/ip&quot;) 在Scrapy中设置代理 设置普通代理 12345678class IPProxyDownloadMiddleware(object): PROXIES = [ &quot;5.196.189.50:8080&quot;, ] def process_request(self,request,spider): proxy = random.choice(self.PROXIES) print(&#x27;被选中的代理：%s&#x27; % proxy) request.meta[&#x27;proxy&#x27;] = &quot;http://&quot; + proxy 设置独享代理 12345678class IPProxyDownloadMiddleware(object): def process_request(self,request,spider): proxy = &#x27;121.199.6.124:16816&#x27; user_password = &quot;970138074:rcdj35xx&quot; request.meta[&#x27;proxy&#x27;] = proxy # bytes b64_user_password = base64.b64encode(user_password.encode(&#x27;utf-8&#x27;)) request.headers[&#x27;Proxy-Authorization&#x27;] = &#x27;Basic &#x27; + b64_user_password.decode(&#x27;utf-8&#x27;) 爬取瓜子二手车交易信息 网址：https://www.guazi.com/www/buy/ 我们先什么都不加，直接请求网址，看输出是什么，再逐渐的添加请求头里的内容，来尝试网站究竟是用什么作为反爬虫的检测依据的。 什么都不加： 12345import requestsfrom lxml import etreeurl = &#x27;https://www.guazi.com/www/buy/&#x27;resp = requests.get(url)print(resp.text) 输出： 经过比较，它和网页源代码不一致，且最后还出现了乱码现象，说明text把解码方法猜错了——体现了content.decode('utf-8')的稳定性 添加User-agent： 12345678import requestsfrom lxml import etreeurl = &#x27;https://www.guazi.com/www/buy/&#x27;headers = &#123; &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36&#x27;&#125;resp = requests.get(url,headers=headers)print(resp.content.decode(&#x27;utf-8&#x27;)) 哈哈！还是不行。 添加cookie： 123456789import requestsfrom lxml import etreeurl = &#x27;https://www.guazi.com/www/buy/&#x27;headers = &#123; &#x27;Cookie&#x27; : &#x27;uuid=8375fbff-6a87-4130-8c96-7a4aa8d30728; ganji_uuid=8329982395237678242215; cainfo=%7B%22ca_a%22%3A%22-%22%2C%22ca_b%22%3A%22-%22%2C%22ca_s%22%3A%22self%22%2C%22ca_n%22%3A%22self%22%2C%22ca_medium%22%3A%22-%22%2C%22ca_term%22%3A%22-%22%2C%22ca_content%22%3A%22-%22%2C%22ca_campaign%22%3A%22-%22%2C%22ca_kw%22%3A%22-%22%2C%22ca_i%22%3A%22-%22%2C%22scode%22%3A%22-%22%2C%22keyword%22%3A%22-%22%2C%22ca_keywordid%22%3A%22-%22%2C%22display_finance_flag%22%3A%22-%22%2C%22platform%22%3A%221%22%2C%22version%22%3A1%2C%22client_ab%22%3A%22-%22%2C%22guid%22%3A%228375fbff-6a87-4130-8c96-7a4aa8d30728%22%2C%22ca_city%22%3A%22qd%22%2C%22sessionid%22%3A%22dbe4532a-24f9-45fc-8c5f-b9518a2efb46%22%7D; antipas=93901707482fmWd51E58673WzOJ; cityDomain=www; clueSourceCode=%2A%2300; user_city_id=-1; preTime=%7B%22last%22%3A1611505261%2C%22this%22%3A1610175479%2C%22pre%22%3A1610175479%7D; sessionid=30370a7d-e999-43e4-a614-4ffacc7c8e75; lg=1; Hm_lvt_bf3ee5b290ce731c7a4ce7a617256354=1610175480,1610175573,1610524515,1611505262; Hm_lpvt_bf3ee5b290ce731c7a4ce7a617256354=1611505262&#x27;, &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36&#x27;&#125;resp = requests.get(url,headers=headers)print(resp.content.decode(&#x27;utf-8&#x27;)) 哈哈！竟然行了！ 虽然我自己试的时候还额外添加了Host，但不知道为什么现在只加一个cookie就行了。 后续的思路就是我们通过“检查”，在Elements里找到详情页的链接如图： 并且不同的车存放在不同的&lt;li&gt;标签中： 所以我们遍历所有&lt;li&gt;标签，依次访问每辆车的详情页面，再获取详情页面的车辆信息，进行存储即可。感兴趣的同学可以自行完成后面的代码，也可以找我要一下之前的代码 爬取豆瓣top250 网址：https://movie.douban.com/top250 这个案例也是我学习时候，花比较多时间做的一个案例，虽然它没有什么很惊艳的实现技巧，但我在做的时候遇到了这样一个问题：我被封号了！ 考虑到我囊中羞涩，没有租60r/月的代理服务器，而免费代理它又不太稳定，于是我选择老老实实的注册登陆。没错我就是前几天才注册豆瓣 很简单，只要登录以后添加cookie信息就可以了。 代码如下，做到存储数据之前： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import requestsfrom bs4 import BeautifulSoupheaders = &#123; &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&#x27;, &#x27;Cookie&#x27; : &#x27;ll=&quot;118221&quot;; bid=Dp60PRKNGWI; __yadk_uid=t4cy7TbKsr834lpYtjbt0Vn6au2yF7oP; _vwo_uuid_v2=D181BE4292803A62776208FF476CE0C21|403fd897a559fbd412c3a7530efb5d2f; __gads=ID=546d1adef9db7e77-221ec2b1c5c5000a:T=1611226743:RT=1611226743:S=ALNI_MZmgV9oiEJeTVAfAnDiNlwsRm8WMQ; ap_v=0,6.0; __utmc=30149280; __utmz=30149280.1611299250.2.2.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; __utmc=223695111; __utmz=223695111.1611299250.2.2.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; _pk_ref.100001.4cf6=%5B%22%22%2C%22%22%2C1611302352%2C%22https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3DStwtEMgge76IHS2f9aoITF2La9KliUfVdz-ShjuHwB78oJQFmijIAnaCAMgiQfxo%26wd%3D%26eqid%3Dd8a7eb3b0003fac200000002600a79b0%22%5D; _pk_ses.100001.4cf6=*; __utma=30149280.233705150.1611225868.1611299250.1611302352.3; __utma=223695111.583107523.1611225868.1611299250.1611302352.3; __utmb=223695111.0.10.1611302352; dbcl2=&quot;231087110:rCDcDbFTf0I&quot;; ck=rEkU; push_noty_num=0; push_doumail_num=0; __utmt=1; __utmv=30149280.23108; __utmb=30149280.2.10.1611302352; _pk_id.100001.4cf6=fcbcfa39023ea437.1611225868.3.1611304162.1611299286.&#x27;&#125;# 函数：获取详情页面的url，返回一个列表def get_detail_urls(url): resp = requests.get(url, headers=headers) # 获取详情页面url html = resp.text soup = BeautifulSoup(html, &#x27;lxml&#x27;) lis = soup.find(&#x27;ol&#x27;, class_=&#x27;grid_view&#x27;).find_all(&#x27;li&#x27;) # 经搜索，grid_view属性值唯一，故用find直接找到即可 detail_urls = [] # 列表 for li in lis: detail_url = li.find(&#x27;a&#x27;)[&#x27;href&#x27;] detail_urls.append(detail_url) return detail_urlsdef parse_detail_url(url): resp = requests.get(url,headers=headers) html = resp.text soup = BeautifulSoup(html,&#x27;lxml&#x27;) lis = [] name = list(soup.find(&#x27;span&#x27;,property=&#x27;v:itemreviewed&#x27;).stripped_strings) name = &#x27;&#x27;.join(name) lis.append(name) director = list(soup.find(&#x27;div&#x27;,id=&#x27;info&#x27;).find_all(&#x27;span&#x27;)[0].stripped_strings) director = &#x27;&#x27;.join(director) lis.append(director) actor = list(soup.find(&#x27;div&#x27;,id=&#x27;info&#x27;).find(&#x27;span&#x27;,class_=&#x27;actor&#x27;).stripped_strings) actor = &#x27;&#x27;.join(actor) lis.append(actor) score = soup.find(&#x27;strong&#x27;,class_=&#x27;ll rating_num&#x27;).string lis.append(score) remark = list(soup.find(&#x27;span&#x27;,property=&#x27;v:summary&#x27;).stripped_strings) remark = &#x27;&#x27;.join(remark) lis.append(remark) print(lis)def main(): base_url = &#x27;https://movie.douban.com/top250?start=&#123;&#125;&amp;filter=&#x27; for x in range(0,251,25): url = base_url.format(x) detail_urls = get_detail_urls(url) for detail_url in detail_urls: parse_detail_url(detail_url) # resp = requests.get(detail_url,headers=headers) # html = resp.text # soup = BeautifulSoup(html,&#x27;lxml&#x27;) # name = list(soup.find(&#x27;div&#x27;,id=&#x27;content&#x27;).find(&#x27;h1&#x27;).stripped_strings) # title = list(soup.find(&#x27;span&#x27;,property=&#x27;v:itemreviewed&#x27;).stripped_strings) # name = &#x27;&#x27;.join(name) # 将列表转化为字符串 # director = list(soup.find(&#x27;a&#x27;,rel=&#x27;v:directedBy&#x27;)) # director = list(soup.find(&#x27;div&#x27;,id=&#x27;info&#x27;).find(&#x27;span&#x27;,class_=&#x27;attrs&#x27;).stripped_strings) # print(director) # writer = list(soup.find(&#x27;div&#x27;,id=&#x27;info&#x27;).find_all(&#x27;span&#x27;)[3].find(&#x27;span&#x27;,class_=&#x27;attrs&#x27;).stripped_strings) # writer = &#x27;&#x27;.join(writer) # print(writer) # actor = list(soup.find(&#x27;div&#x27;,id=&#x27;info&#x27;).find(&#x27;span&#x27;,class_=&#x27;actor&#x27;).stripped_strings) # actor = &#x27;&#x27;.join(actor) # print(actor) # remark = list(soup.find(&#x27;span&#x27;,class_=&#x27;all hidden&#x27;).stripped_strings) # print(remark) # score = list(soup.find(&#x27;strong&#x27;,class_=&#x27;ll rating_num&#x27;).stripped_strings) # print(score)if __name__ == &#x27;__main__&#x27;: main() 好家伙，我写这个文档时候，为了要上面那个“状态异常”的截图，把cookie删了以后疯狂爬取，直接导致我被封号了： 而且好像还没那么容易解锁。 哎，先看最后一个吧 selenium行为链实战 有些厉害的网站会根据鼠标行为判断你是人还是爬虫，这个时候selenium库的行为链就可以帮你的爬虫躲过检查。因为我还没遇到这么牛逼的网站，所以就随便举个例子，说一下行为链的语法了。 比如我想在百度主页搜索“元尊” 123456789101112131415161718192021from selenium import webdriverfrom selenium.webdriver.common.action_chains import ActionChainsdriver = webdriver.Chrome(executable_path=&quot;/Users/pangyuxuan/Desktop/chromedriver&quot;)driver.get(&quot;https://www.baidu.com/&quot;)inputTag = driver.find_element_by_id(&#x27;kw&#x27;) # 获取输入框submitTag = driver.find_element_by_id(&#x27;su&#x27;) # 获取按钮&quot;百度一下&quot;actions = ActionChains(driver) # 创建行为链对象actionsactions.move_to_element(inputTag) # 鼠标移动到inputTagactions.send_keys_to_element(inputTag,&#x27;元尊&#x27;) # 输入要搜索的内容actions.move_to_element(submitTag) # 鼠标移动到提交按钮actions.click(submitTag) # 点击提交actions.perform() # 上面的都是在定义，还没执行，通过perform执行 还有更多的鼠标相关的操作。 click_and_hold(element) ：点击但不松开鼠标。 context_click(element) ：右键点击。 double_click(element) ：双击。 更多方法请参考：http://selenium-python.readthedocs.io/api.html 彩蛋：关于我被封号这件事","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/"},{"name":"实战","slug":"爬虫/实战","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"常用LaTex公式及用法","slug":"latex-toolbook","date":"2022-08-06T15:46:36.000Z","updated":"2022-08-24T14:26:33.311Z","comments":true,"path":"2022/08/06/latex-toolbook/","link":"","permalink":"https://pyxblog.cn/2022/08/06/latex-toolbook/","excerpt":"整理了一些使用频率相对较高的LaTex公式，用到新的会不断往里补充，也欢迎大家在评论区补充！","text":"整理了一些使用频率相对较高的LaTex公式，用到新的会不断往里补充，也欢迎大家在评论区补充！ 运算符 常用二元运算 \\pm \\cdot \\times \\mp \\div \\frac{1}{1} 常用巨算符 \\sum \\prod \\int \\bigcup \\bigcap \\oint 关系符 常用二元关系 \\leq or \\le \\geq or \\ge \\ll \\gg \\in \\subset \\subseteq \\equiv \\approx \\propto 取反 加\\not来实现取反，如:\\not \\subset 特殊字符 常用希腊字母 \\alpha \\beta \\gamma \\delta \\epsoilon \\zeta \\theta \\lambda \\pi \\xi \\rho \\sigma \\eta \\phi \\psi \\omega 将首字母大写即可获得相应大写字母 特殊符号 特殊符号 \\{ \\} \\% \\dots \\cdots \\vdots \\to \\Rightarrow \\varnothing \\forall \\exists \\infty 公式块的相关写法 等式对齐写法 开头写\\begin{aligned}，结尾写\\end{aligned}，中间需要对其的等式用&amp;&amp;包裹，再换行\\\\ 例如 12345$$\\begin{aligned} S(n) &amp; = 1+2+ \\dots +n &amp; \\\\ &amp; = \\frac{(n+1) \\times n}{2} &amp;\\end{aligned}$$ 大括号的用法 开头写\\begin{cases}，结尾写\\end{cases}，中间如下，例如 1234567$$1+(-1)^k=\\begin{cases}2 &amp; \\text{k=2n-1}\\\\0 &amp; \\text{k=2n}\\end{cases}$$ 组合数的写法 可以强行写： 123$$C_n^m$$ 也可以使用大括号的描写方式，注意上面的是范围，下面的数是要取的个数，与的上下相反 123$$\\tbinom{n}{m}$$ 求和符号的行内写法 若直接写 1$\\sum_{i=0}^n a_n$ 会显示为 若想将和挪到的上下，可以如下写 1$\\sum\\limits_{i=0}^n a_n$ 效果： 矩阵的写法 123456\\begin{matrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{matrix} \\\\\\begin{pmatrix} 0 &amp; -i \\\\ i &amp; 0 \\end{pmatrix} \\\\\\begin{bmatrix} 0 &amp; -1 \\\\ 1 &amp; 0 \\end{bmatrix} \\\\\\begin{Bmatrix} 1 &amp; 0 \\\\ 0 &amp; -1 \\end{Bmatrix} \\\\\\begin{vmatrix} a &amp; b \\\\ c &amp; d \\end{vmatrix} \\\\\\begin{Vmatrix} i &amp; 0 \\\\ 0 &amp; -i \\end{Vmatrix} 大佬的文章备查 LaTex符号大全-基于lshort-zh-cn 转载自王美庭 2019-03-26 Latex所有常用数学符号吐血整理！（包含大括号、等式对齐） 原创繁凡さん 2020-05-27 常用LaTex表达式&amp;符号——组合数学篇 原创__hep__ 2020-05-03","categories":[{"name":"markdown系列教程","slug":"markdown系列教程","permalink":"https://pyxblog.cn/categories/markdown%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"latex","slug":"latex","permalink":"https://pyxblog.cn/tags/latex/"},{"name":"markdown","slug":"markdown","permalink":"https://pyxblog.cn/tags/markdown/"}]},{"title":"pytorch实现线性回归","slug":"pytorch-demo-2","date":"2022-08-06T15:42:03.000Z","updated":"2022-08-06T15:44:48.720Z","comments":true,"path":"2022/08/06/pytorch-demo-2/","link":"","permalink":"https://pyxblog.cn/2022/08/06/pytorch-demo-2/","excerpt":"","text":"用cpu就能很快跑出来 不需要额外的输入文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import torchimport numpy as npimport torch.nn as nnx_values = [i for i in range(11)] # [0,1,2,3,4,5,6,7,8,9,10]x_train = np.array(x_values, dtype=np.float32)x_train = x_train.reshape(-1, 1) # 将x_train调整为11*1的矩阵y_values = [2.5*i+3.5 for i in x_values] # y=2.5x+3.5y_train = np.array(y_values, dtype=np.float32)y_train = y_train.reshape(-1, 1)class LinearRegressionModel(nn.Module): # 继承自nn包的Module类 def __init__(self, input_dim, output_dim): super(LinearRegressionModel, self).__init__() # 执行父类的构造函数 self.linear = nn.Linear(input_dim, output_dim) # nn.Linear(输入数据维度, 输出数据维度) 全连接层 def forward(self, x): out = self.linear(x) return outinput_dim = 1output_dim = 1model = LinearRegressionModel(input_dim, output_dim)epochs = 1000 # 训练次数learning_rate = 0.01 # 学习率optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)# 优化器，使用基本的优化器SGD，传入需要更新的参数（model中的全部参数）和学习率criterion = nn.MSELoss() # 回归任务可选用MSE等for epoch in range(epochs): epoch += 1 # x_train和y_train均为numpy.ndarry格式，需要转换为tensor格式才可以传入框架 inputs = torch.from_numpy(x_train) labels = torch.from_numpy(y_train) # 每次迭代开始时 梯度需要清零 optimizer.zero_grad() # 前向传播 outputs = model.forward(inputs) # 计算损失 loss = criterion(outputs, labels) # 反向传播 loss.backward() # 更新权重参数 optimizer.step() # 每50个epoch输出一次，以显示训练进度 if epoch % 50 == 0: print('epoch {}, loss {}'.format(epoch, loss.item()))y_predicted = model.forward(torch.from_numpy(x_train)).data.numpy()# 前向传播 传入训练数据x 输出预测结果y 用以测试# .data.numpy() 将结果转换成numpyprint(y_predicted)","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"实战demo","slug":"深度学习/实战demo","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98demo/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://pyxblog.cn/tags/PyTorch/"},{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"pytorch实现Minist手写数字识别","slug":"pytorch-demo-1","date":"2022-08-06T15:30:43.688Z","updated":"2022-08-06T15:44:45.804Z","comments":true,"path":"2022/08/06/pytorch-demo-1/","link":"","permalink":"https://pyxblog.cn/2022/08/06/pytorch-demo-1/","excerpt":"","text":"代码中的 import xxx 和 from xxx import xxx 为依赖包，可按编译器的提示自行安装。 数据集下载地址：http://deeplearning.net/data/mnist/ 考虑到外网下载较慢，提供国内的镜像下载链接： Github仓库：https://github.com/zionfuo/keras-datasets 数据集下载后，代码中读取文件： 12345with gzip.open(&#x27;data/mnist/mnist.pkl.gz&#x27;, &#x27;rb&#x27;) as f: # 读取数据 ((x_train, y_train), (x_test, y_test), _) = pickle.load(f, encoding=&#x27;latin-1&#x27;)x_train, y_train, x_test, y_test = map( # 将数据类型转换为tensor torch.tensor, (x_train, y_train, x_test, y_test)) 注意将上面的文件路径换成自己数据集的路径。下面是完整代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091# -- 构造网络 --# mnist数据集50000个样本，每个样本28*28=784个像素点# 输入数据1*784，设计三层网络，第一层784*128，第二层128*256，第三层256*10from torch import nnimport torch.nn.functional as Fclass Mnist_NN(nn.Module): # 继承父类 def __init__(self): super().__init__() # 继承父类的构造函数 self.hidden1 = nn.Linear(784, 128) # 隐层1 784*128 self.hidden2 = nn.Linear(128, 256) # 隐层2 128*256 self.out = nn.Linear(256, 10) # 输出层 def forward(self, x): # 前向传播 x = F.relu(self.hidden1(x)) # 输入-隐层1，激活函数relu x = F.relu(self.hidden2(x)) # 隐层1-隐层2，激活函数relu x = self.out(x) # 隐层2-输出 return x # 返回前向传播计算结果# -- 构造数据集 --import gzipimport pickleimport torchfrom torch.utils.data import TensorDataset # 用于创建数据集from torch.utils.data import DataLoader # 用于加载数据集# 使用TensorDataset和DataLoader创建的数据集可以根据传入的batch自动抽样# 也可自动在每次分组时洗牌with gzip.open(&#x27;data/mnist/mnist.pkl.gz&#x27;, &#x27;rb&#x27;) as f: # 读取数据 ((x_train, y_train), (x_test, y_test), _) = pickle.load(f, encoding=&#x27;latin-1&#x27;)x_train, y_train, x_test, y_test = map( # 将数据类型转换为tensor torch.tensor, (x_train, y_train, x_test, y_test))train_dataset = TensorDataset(x_train, y_train) # 训练数据集test_dataset = TensorDataset(x_test, y_test) # 测试数据集def getData(train_dataset, test_dataset, batch_size): # 加载数据集 return ( DataLoader(train_dataset, batch_size=batch_size, shuffle=True), DataLoader(test_dataset, batch_size=batch_size * 2), )# -- 训练 --import numpy as npfrom torch import optimloss_func = F.cross_entropy # 损失函数，直接从functional中调用交叉熵函数def getModel(): # 获取实例化模型和优化器 model = Mnist_NN() return model, optim.SGD(model.parameters(), lr=0.001)def loss_batch(model, loss_func, x_bath, y_bath, opt=None): loss = loss_func(model(x_bath), y_bath) # 有优化器，即训练，需要进行更新参数等操作 # 无优化器，即测试，只求损失值即可 if opt is not None: loss.backward() # 反向传播 opt.step() # 更新参数 opt.zero_grad() # 梯度清零 return loss.item(), len(x_bath)def mnist(steps, model, loss_func, opt, train_data, test_data): # steps 迭代多少次 # model 网络的实例 # loss_func 损失函数 # opt 优化器 # train_data 训练数据 # test_data 测试数据 for step in range(steps): for x_bath, y_bath in train_data: # 训练 loss_batch(model, loss_func, x_bath, y_bath, opt) with torch.no_grad(): # 测试，不更新参数 losses, nums = zip( *[loss_batch(model, loss_func, x_bath, y_bath) for x_bath, y_bath in test_data] ) val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums) print(&#x27;当前step:&#x27; + str(step), &#x27;验证集损失：&#x27; + str(val_loss)) 训练： 123train_data, test_data = getData(train_dataset, test_dataset, 64)model, opt = getModel()mnist(25, model, loss_func, opt, train_data, test_data)","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"实战demo","slug":"深度学习/实战demo","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98demo/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://pyxblog.cn/tags/PyTorch/"},{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"python快速入门","slug":"python-basic","date":"2022-08-06T15:27:25.000Z","updated":"2022-09-14T05:41:06.222Z","comments":true,"path":"2022/08/06/python-basic/","link":"","permalink":"https://pyxblog.cn/2022/08/06/python-basic/","excerpt":"","text":"数值类型与基本操作 12345678910112**5 # 2的5次方1.3e5 1.3e-5 # 科学计数法0xFF # 16进制 0x是16进制前缀type(a) # 打印数据类型a = int(input('请输入数据')) # 类型转换# input()输入数据默认为字符串# 常见类型 int float str bool list dict-字典 set-集合abs(5.2) # abs函数——取绝对值round(5.2) # round函数——四舍五入min(2,3,4) # min函数——取最小值 可以有若干参数max(2,3,4) # max函数——取最大值 可以有若干参数 基本数据结构 字符串 str 123456789101112131415161718192021222324252627282930313233343536st = 'jupyter ' + 'python' # 字符串加法 -&gt; 有序拼接 'jupyter python'st = 'jupyter ' * 3 # 字符串数乘 -&gt; 重复 'jupyter jupyter jupyter'len(st) # 字符串长度# 拆分st = 'Gin Vodka Vermouth Bourbon'st.split() # 默认按空格拆分字符串 返回列表 ['Gin','Vodka','Vermouth','Bourbon']st.split('Vodka') # 也可指定拆分间隔 间隔不会计入结果# 合并li = ['Gin','Vodka','Vermouth','Bourbon']st = '\\\\'st.join(li) # 以st为衔接合并列表，要求列表中的元素均为字符串类型 # 'Gin\\\\Vodka\\\\Vermouth\\\\Bourbon'# 替换st = 'Gin Vodka Vermouth Bourbon'st.replace('Bourbon','Zero')# 大小写st = 'Vermouth'st.lower() # vermouthst.upper() # VERMOUTHst.strip() # 去除首尾多余空格st.lstrip() # 去除左边多余空格st.rstrip() # 去除右边多余空格# format占位'{} and {} are black'.format('Gin','Vodka')# Gin and Vodka are black'{2} and {1} are black'.format('Gin','Vodka') # 指定索引# Vodka and Gin are black'{a} and {b} are black'.format(a='Gin',b='Vodka') # 指定参数# Gin and Vodka are black 列表 list 有序，可以混合存放任意类型数据，可嵌套，通过索引访问 123456789101112131415161718192021222324li = [1,2] + [3,4] # 列表相加 -&gt; 有序拼接 [1,2,3,4]li = [1,2] * 3 # 列表数乘 -&gt; 重复 [1,2,1,2,1,2]len(li) # 求列表长度del li[3:] # 按索引删除某元素tmp in li # 判断元素tmp是否在列表li中 返回True or Falseli.count(tmp) # 计算元素tmp在列表中的个数li.index(tmp) # 返回元素tmp在列表中首次出现的索引 没找到报错ValueErrorli.append(tmp) # 将元素tmp添加进列表最后li.insert(ind,tmp) # 将元素tmp添加在列表索引ind位置li.remove(tmp) # 将列表中首个tmp从列表中移除li.pop() # 将列表尾部的元素弹出 并返回该元素li.pop(ind) # 将索引ind位置的元素弹出 并返回该元素li.sort() # 列表升序排序li.sort(reverse=1) # 列表降序排序li_sort = sorted(li) # 列表升序排序 将结果储存在新列表中 不改变原列表li.reverse() # 列表翻转# 按索引遍历for i in range(len(li)): print(li[i])# 按元素遍历for t in li: print(t) 索引 用于有序数据结构，如字符串和列表，不用于字典和集合 123456789101112# 首端正数从0开始，尾端倒数从-1开始st = '01234567'st[0] # '0'st[-1] # '7' # 切片st[0:4] # 左闭右开区间 '0123'st[4:] # 4到无穷 '4567'st[:4] # 0到4 '0123'st[-2:] # 倒数第二到无穷 '67'st[::3] # 每3个取一个值 '036' 字典 dict 基本结构：key-value 无序，使用key访问value，不可使用索引 12345678910111213141516171819202122232425di = {'Gin':'black','Bourbon':'red'}di['Gin'] # 'black'# 列表转化为字典di = dict([('amy',89), ('tom',90)])# {'amy': 89, 'tom': 90}di.get('amy') # 89 di.get('sam') # 没找到 但不会报错di.get('sam','none') # 返回nonedi.pop('amy') # 弹出指定key-value 并返回valuedi['tom'] +=10 # {'tom',100} value可以被运算del di['tom'] # 删除指定key-valuedi = {'Gin':'black','Bourbon':'red'}di.update({'Gin':'black','Vodka':'black'}) # 更新'Gin' in di # Truedi.keys() # 返回字典di的所有key 类型为dict_keys 可用于遍历di.values() # 返回字典di的所有value 类型为dict_values 可用于遍历tang.items() # 返回字典di的所有key-value对# 遍历for key in di.keys(): print(di[key]) 集合 set 集合内元素不重复，无序，可以进行一些集合间的数学运算/判断 123456789101112131415li = [1,1,2,3,5,8]se = set(li) # {1,2,3,5,8}li = list(se) # 与list可以互相转化a = {1,2,3,4}b = {2,3,4}a | b # 并集 {1,2,3,4}a &amp; b # 交集 {2,3,4}a - b # 在a里面 不在b里面的元素 {1}b &lt;= a # True 判断子集a &lt;= a # Truea.update([4,5,6]) # 更新 {1,2,3,4,5,6}a.remove(1) # 移除指定元素a.pop() # 弹出并返回首部元素 逻辑结构 判断结构 通过and/or连接多个判断条件 三个及以上判断结果用elif表示 使用: 和缩进表示逻辑从属 123456789a = 90if a &gt; 100 and a &lt;= 200: print('if')elif a == 50 or a == 90: print('elif1')elif (a &lt;10 and a &gt; 0) or a &gt; 200: print('elif2')else: print('else') 循环结构 while 循环 12345678a = 0while a &lt; 5: print(a) a += 1se = {'Gin','Vodka','Bourbon'}while se: print(se.pop()) for循环 1234567for i in range(1,5): print(i)di = {'Gin':'black','Vodka':'black','Bourbon':'red'}for key in di.keys(): print(di[key]) 函数 参数和返回值根据需要设定，通过def关键字、:和缩进表示逻辑从属 12345678910111213141516171819202122def print_value(a): print('The value of a is ',a) def add_value(a=1,b=2): # 为参数设置默认值 print('a+b is ',a+b) def add_number(a,*args): # 接受不定个数的参数 b = 0 for i in args: a += i b += a return a,b # 返回值可以有多个a,b = add_number(1,2,3)print (a,b) # 6 9 def add_2(a,**kwargs): # **kwargs可传入不定个数的key-value对 for arg,value in kwargs.items(): print(arg,value)add_2(1,x=2,y=3)# x 2# y 3 包 12345678%%writefile test.py # writefile用于在jupyter中新建文件value = 10010def test_function(): print('success') 123456789101112# 导入包import test as te # 整个导入包 调用时需用te.print(te.value) # 10010te.test_function() # successfrom test import value,test_function # 导入包中的部分变量和函数 直接使用无需.print(value) # 10010te.test_function() # successfrom test import * # 导入包中的部分变量和函数 直接使用无需.print(te.value) # 10010te.test_function() # success 类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class people: '帮助信息：这是一个帮助信息' # 类的自带属性 location = 'earth' # 所有实例都会共享number def __init__(self,name,age): # 构造函数 self.name = name self.age = age def show_name(self): print(self.name)per1 = people('Vodka',40) # 实例化per1.name = 'Gin' # 访问per1的name变量per2.show_name() # 访问per2的show_name函数del per1.name # 删除实例per1的name属性hasattr(per1,'age') # True 查看实例是否具有某一属性hasattr(per1,'name') # False 被删除的属性和不存在的属性返回Falsegetattr(per1,'age') # 获取实例per1的属性agesetattr(per1,'name','Gin') # 为实例per1设置name属性setattr(per1,'sex','male') # 可以设置类中没有的属性delattr(per1,'sex') # 删除per1的sex属性print(peolpe.__doc__) # 帮助信息print (people.__name__) # 类的名字print (people.__module__) # 类的定义所在的模块print (people.__bases__) # 父类的构成print (people.__dict__) # 类的组成# 继承class Dad: # 父类 def __init__(self): print ('父类构造函数') def dadFunction(self): print ('父类方法') def sameName(self): print ('来自dad') class son(Dad): # Dad的子类 def __init__(self): print ('子类构造函数') def sonFunction(self): print ('子类方法') def sameName(self): print ('来自子类')child = son() # 子类构造函数child.dadFunction() # 父类方法child.sonFunction() # 子类方法child.sameName() # 来自子类 基础操作 异常处理 用以防止报错导致的程序中断 12345678910111213141516171819202122232425262728293031323334353637383940414243444546li = [1,0]for tmp in li: try: print('front') # 报错语句前的语句可以被执行 print(1/tmp) # 报错 跳转至except 该语句不会被执行 print('last') # 报错语句后的语句不可以被执行 except ZeroDivisionError: print('不可以除0') # 涵盖所有报错类型import mathfor i in range(10): try: input_number = input('write a number') if input_number == 'q': break result = 1/math.log(float(input_number)) print (result) except ValueError: print ('ValueError: input must &gt; 0') except ZeroDivisionError: print ('log(value) must != 0') except Exception: # 其他的可能性 print ('unknow error') # finallytry: 1 / 0except: print('不可以除0')finally: print('finally') # 无论try中是否有异常，finally都会被执行 # 自定义错误类型class NumNotInList(ValueError): # 自定义的一种异常 passli = [1,2,3]while True: num = int(input('input a number: ')) if num not in li: raise NumNotInList('数字{}不在列表中'.format(num)) # 抛出一个错误 输入不在列表中的数字时报错终止 并显示错误类型为NumNotInList 文件处理 1234567891011121314151617181920txt = open('./test.txt') # ./ 即本代码所在的路径txt_str = txt.read() # read函数返回文本内容txt_lines = txt.readlines() # readlines返回列表 文本每一行组成一个元素 包括换行符txt.close() # 文件打开后要记得关闭txt = open('test.txt','w') # 以覆盖写入模式打开文件 一旦写入丢失原有数据txt.write('123')txt.close()txt = open('test.txt','a') # 以追加写入模式打开文件 在原有数据后面写入新的数据txt.write('\\n321')txt.close()txt = open('test.txt','r') # 以只读模式打开文件 可以读取文件内容print (txt.read())txt.close()with open('test.txt','w') as f: f.write('123\\n321') # with方法会自动close 且自带类似try-except的防止报错功能 较为常用 系统时间 所在包：time.py 123456789import timeprint(time.time()) # 从1970年1月1日到现在经过了多长时间print (time.localtime(time.time()))# time.struct_time(tm_year=2022, tm_mon=2, tm_mday=4, tm_hour=23, tm_min=18, tm_sec=46, tm_wday=4, tm_yday=35, tm_isdst=0)print (time.asctime(time.localtime(time.time())))# Fri Feb 4 23:18:38 2022print (time.strftime('%Y-%m-%d %H:%M:%S',time.localtime()))# 2022-02-04 23:19:17time.sleep(10) # 程序停止十秒","categories":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/categories/python/"},{"name":"基础教程","slug":"python/基础教程","permalink":"https://pyxblog.cn/categories/python/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"}]},{"title":"Matlab二维绘图","slug":"matlab-advance-1","date":"2022-08-06T15:11:00.000Z","updated":"2022-09-26T01:50:46.165Z","comments":true,"path":"2022/08/06/matlab-advance-1/","link":"","permalink":"https://pyxblog.cn/2022/08/06/matlab-advance-1/","excerpt":"Matlab进阶教程1-二维绘图，包含基本的绘图函数，坐标系的切换，图形窗口，图形标注及特殊图形的绘制（饼图、条形图等）。","text":"Matlab进阶教程1-二维绘图，包含基本的绘图函数，坐标系的切换，图形窗口，图形标注及特殊图形的绘制（饼图、条形图等）。 Matlab基础教程系列： Matlab基础0——命令行 Matlab基础1——基础知识 Matlab基础2——向量与多项式 Matlab基础3——元胞与结构体 Matlab基础4——矩阵 Matlab基础5——符号运算 基本绘图函数 plot 最基本的绘图函数。执行plot函数时，若当前已有图形窗口，则将图画在现有图形窗口上，覆盖原有图形；若当前没有图形窗口，则自动创建新的图形窗口。 1plot(X,Y); % 创建以X为自变量、Y为因变量的二维线图 X和Y必须是同维向量，绘制以X为横坐标、Y为纵坐标的曲线。若： X是向量，Y是矩阵，则X的维数应与Y的某一维相等，绘制多条颜色不同的曲线，曲线数等于Y的另一维数，X则仍作为横坐标。当Y是方阵时，Matlab会优先处理列，即绘制Y的每一列对X的曲线。 123x = 0:0.01:10; % 1*1001y = [sin(x);sin(x)+1;sin(x)-1]; % 3*1001plot(x,y); grid on; % 3条曲线 X是矩阵，Y是向量时，规则同上，但Y会被当作横坐标 X与Y皆为矩阵时，要求二者必须同维，以X的每一列作为横坐标、以Y对应对列元素作为纵坐标绘制曲线，曲线数等于列数。 12plot(x,y,LineSpec); % 设置线型、标记符号和颜色plot(x,y,&#x27;--or&#x27;); % 带有圆形标记的红色虚线 LineSpec是一个字符串，可以包含上述若干要素，基本线型、标记和颜色如下： 线型 说明 -(default) 实线 -- 虚线 : 点线 -. 点划线 颜色 说明 w 白 white y 黄 yellow c 青 cyan g 绿 green m 品 magenta r 红 red b 蓝 blue k 黑 black 标记 说明 o 圆圈 + 加号 * 星号 . 点 x 叉号 s 方形 square p 五角形 pentagonal d 菱形 diamond ^ 上三角 v 下三角 &gt; 右三角 &lt; 左三角 h 六角形 hexagon ps. 如果仅指定标记而忽略线型，则绘图时不会显示线条，只显示标记。 12plot(x1,y1,...,xn,yn); % 在同一个坐标区域内绘制多张图plot(x1,y1,LineSpec1,...,xn,yn,LineSpecn); 也可以使用hold on命令，将不同的图画在同一个坐标系里。 12plot(y); % 创建以y中数据为因变量、相应索引为自变量的二维线图plot(y,LineSpec) 若y是实向量，则x轴刻度范围为\\([1,length(y)]\\) 若y是实矩阵，则按列绘制曲线，相当于plot(索引矩阵,y)，自变量为索引 若y是复矩阵，则按列绘制曲线，相当于plot(real(y),imag(y))，自变量为实部，因变量为虚部 123plot(ax,_); % 指定坐标范围plot(_,Name,Value); % 使用一个或多个(Name,Value)对，单独指定某些属性的值h = plot(_); % 用变量h将图形储存，可以通过改变h的属性来实时修改图形 图形线条属性可以通过输出h来查看： 123456789 Color: [0.8500 0.3250 0.0980] % 颜色 LineStyle: &#x27;-&#x27; % 线型 LineWidth: 0.5000 % 线宽 Marker: &#x27;none&#x27; % 符号 MarkerSize: 6 % 符号大小MarkerFaceColor: &#x27;none&#x27; % 符号填充颜色 XData: [1×1001 double] % x轴数据 YData: [1×1001 double] % y轴数据 ZData: [1×0 double] % z轴数据 修改示例如下： 123x = 0:0.01:10;y = [sin(x);cos(x)];h = plot(x,y); 12&gt;&gt; h(2).YData = 0.1*x; % 修改第二条线的y轴数据&gt;&gt; h(1).LineStyle = &#x27;--&#x27;; % 修改第一条线的线型 此外，还有一些常用的属性如下 属性 说明 值 LineJoin 线条边角样式 round(default) miter chamfer MarkerEdgeColor 标记轮廓颜色 none(default) auto 颜色 fplot 专门用于绘制一元函数的命令。相比于plot()根据指定数据点绘图，fplot()会自适应地选取数据点，即在平滑处选取数据点稀疏、在陡峭处选取数据点密集，使图像更加光滑准确。 12fplot(f); % 在x的默认区间[-5,5]绘制由函数y=f(x)定义的曲线fplot(f,x_interval); % 在x的指定区间x_interval绘制由函数y=f(x)定义的曲线 f 为m文件函数名或系统自带函数名，x_interval为一个二元向量，包含区间的两个端点。示例如下： 1fplot(@exp,[-1,1]); grid on; 1234fplot(funx,funy);% 在t的默认区间[-5,5]绘制由参数方程x=funx(t),y=funy(t)定义的曲线fplot(funx,funy,t_interval);% 在t指定区间t_interval绘制由参数方程x=funx(t),y=funy(t)定义的曲线 funx和funy为参数方程函数名，t_interval为一个二元向量，包含区间的两个端点。 123xt = @(t) 2*cos(t);yt = @(t) sin(t);fplot(xt, yt); grid on; 1234fplot(_,LineSpec); % 指定线型、标记符号和颜色fplot(_,Name,Value); % 指定线条属性fplot(ax,_); % 指定坐标范围fp = fplot(_); % 返回可修改的图形对象 subplot 用于在同一个图形窗口中分割出多个视图区域。 1subplot(m,n,p); % 将当前窗口分割成m行n列的区域，用p指定当前位置 对p的编号采用从左至右、从上至下的原则。 12subplot(m,n,p,&#x27;replace&#x27;); % 将视图替换为空坐标区subplot(&#x27;Position&#x27;,pos); % 在pos指定的自定义位置创建坐标区 pos的格式为[left, bottom, width, height]，即以左下角坐标、宽度和高度定义，若新坐标区与原有坐标区重叠，则原有坐标区会被替换。 不同坐标系下的绘图 上述所有绘图命令均建立在平面直角坐标系中，下面介绍几种其他坐标系的绘图方法。 极坐标系 polarplot 与直角坐标系的plot函数几乎一致，只是将x换做theta，将y换做rho 12345678polarplot(theta,rho); % theta-极角(rad),rho-极半径polarplot(theta,rho,LineSpec);polarplot(theta1,rho1,...,thetan,rhon);polarplot(theta1,rho1,LineSpec1,...,thetan,rhon,LineSpecn);polarplot(z); % rho对应复数z的模长，theta对应幅角主值polarplot(z,LineSpec);ploarplot(_,Name,Value);p = polarplot(_); 示例： 1234theta = 0:0.01*pi:6*pi;rho1 = theta/10;rho2 = theta/12;polarplot(theta,rho1,&#x27;-b&#x27;,theta,rho2,&#x27;--r&#x27;); 坐标转化： 1234[theta, rho] = cart2pol(x, y); % 直角坐标转极坐标[x, y] = pol2cart(theta, rho); % 极坐标转直角坐标R = deg2rad(D); % 角度转弧度D = rad2deg(R); % 弧度转角度 对数坐标系 对于某些变化迅速的变量，线性坐标可能无法形象展示其变化过程。若将部分或全部坐标取对数，就可以减缓变量的变化过程。常用的对数坐标系有： semilogx() - x轴为对数坐标，y轴为线性坐标 semilogy() - y轴为对数坐标，x轴为线性坐标 loglog() - x、y轴均为对数坐标 函数调用规则与plot类似。示例如下： 1234x = 0:0.01:10;y = exp(x);subplot(2,1,1); plot(x,y); grid on; % 直接绘制subplot(2,1,2); semilogy(x,y); grid on; % 对y轴取对数 ps. 对数以10为底 双y轴坐标系 对于同一个坐标系内的两条曲线，若二者的变化范围差距过大，会导致变化范围较小的曲线无法清晰显示。此时，可以使用yyaxis left与yyaxis right命令为坐标系创建两个y轴，并分别绘制。该命令仅起到定位作用，与subplot类似。 示例如下： 1234567x = 0:0.01:10;y_large = sin(x);y_small = 0.1*cos(x);subplot(2,1,1); plot(x,y_large,x,y_small); grid on;subplot(2,1,2); grid on;yyaxis left; plot(x,y_large);yyaxis right;plot(x,y_small); 图形窗口 Matlab的图形窗口和命令行窗口是相互独立的，通过图形窗口可以修改和编辑图形界面、实现大量数据计算结果的可视化。 创建 使用figure命令创建图形窗口 12345figure % 创建一个图形窗口figure(Name,Value); % 使用(Name,Value)对来修改属性，如(&#x27;Name&#x27;,&#x27;图1&#x27;)f = figure(_); % 使用变量f储存窗口对象，可以通过它改变窗口的属性figure(f); % 指定当前绘图窗口为ffigure(num); % 创建一个编号为num的图形窗口 相关命令 命令 说明 set(f,[Name1,...],[Value1,...]) 设定图形窗口的属性值 get(f) 获取图形窗口的属性值 close close all 关闭图形窗口 clf 清空图形窗口（不会关闭） 图形标注 坐标轴范围 使用axis(limit)指定当前坐标区的范围，limit只能是长度为4、6、8的向量。 123axis([Xmin,Xmax,Ymin,Ymax]); % 2维axis([Xmin,Xmax,Ymin,Ymax,Zmin,Zmax]); % 3维axis([Xmin,Xmax,Ymin,Ymax,Zmin,Zmax,Cmin,Cmax]); % 4维 图形注释 123456fill(x,y,&#x27;color&#x27;); % 用指定颜色填充数据(x,y)构成的多边形title(&#x27;string&#x27;); % 为图形添加标题xlabel(&#x27;string&#x27;); % 为x轴添加标注ylabel(&#x27;string&#x27;);zlabel(&#x27;string&#x27;);text(x,y,&#x27;string&#x27;); % 在指定位置添加字符串 可以配合num2str(num)函数，为图像添加与数值有关的标注，字符串之间使用[]衔接。 12345x = 0:0.01:10;k = rand(1,1);y = sin(x) * k;plot(x, y);title([&#x27;k=&#x27;, num2str(k)]); % 标题显示随机数k的取值 图例 12345legend(label1,...,labeln); % 按照曲线顺序设置图例legend(_,&#x27;Location&#x27;,lcn); % 指定图例的位置% &#x27;north&#x27;|&#x27;south&#x27;|&#x27;east&#x27;|&#x27;west&#x27;|&#x27;northeast&#x27;|...legend(_,&#x27;Orientation&#x27;,ornt); % 指定图例的显示方式% &#x27;vertical&#x27;(defalut)|&#x27;horizontal&#x27; 网格线 123grid on; % 为当前坐标区添加主网格线grid; % 切换主网格线可见性grid minor; % 切换次网格线可见性 绘制特殊图形 条形图bar 12bar(y); % 创建一个条形图，y中的每个元素对应一个条形。bar([1,2,3,4,5]); 当y是\\(m\\times n\\)的矩阵时，创建\\(m\\)组，每组包含\\(n\\)个条形： 1bar(rand(2,5)); 123456bar(x,y); % 在横坐标x指定的位置绘制y，要求x为严格单调递增的向量bar(_,width); % 设置条形的相对宽度bar(_,style); % 设置条形组的样式 % &#x27;grouped&#x27;(defalut)|&#x27;stacked&#x27;|&#x27;hist&#x27;|&#x27;histc&#x27;bar(_,color); % 设置条形的颜色b = bar(_); % 保存对象，可以修改其属性值 此外，还有其他形式的条形图，调用格式类似： 函数 说明 barh() 水平条形图 bar3() 竖直三维条形图 bar3h() 水平三维条形图 区域图area 12345area(x); % 与plot(x)一致，但会将曲线下方区域填充颜色area(x,y); % 与plot(x,y)一致，但会将曲线下方区域填充颜色area(x,Y); % 矩阵Y按列对向量x绘图，图像依次累加area(_,basevalue); % 指定区域填充的基值，默认为0ar = area(_); % 保存对象，可以修改其属性值 123456x = 0:0.5:5;Y = [ones(size(x)) rand(size(x))+1 rand(size(x))+1 rand(size(x))+1];area(x,Y&#x27;,-1); % 矩阵Y的行数须与向量x一致，指定基值为-1 饼图pie 12345pie(x); % 使用x中的数据绘制饼图pie(x,explode); % 将扇区从饼图偏移一定位置% explode与向量x长度相同，其中的值分别对应偏移大小pie(x,labels); % 指定扇区的文本标签，标签数必须等于向量x的长度，采用元胞表示pie(x,explode,labels); 1234x = [1, 3, 1, 5];explode = [0, 0.1, 0.2, 0.3];labels = &#123;&#x27;无偏移&#x27;, &#x27;偏移0.1&#x27;, &#x27;偏移0.2&#x27;, &#x27;偏移0.3&#x27;&#125;;pie(x, explode, labels); 可以用pie3绘制三维饼图。 直方图histogram与polarhistogram 通过help指令查询详细信息。 12x = randn(10000, 1);histogram(x); 12theta = [0.1 1.1 5.4 3.4 2.3 4.5 3.2 3.4 5.6 2.3 2.1 3.5 0.6 6.1];polarhistogram(theta,6); 含误差的线图errorbar 123456errorbar(y,err); % 创建y中数据的线图，并在每个数据点绘制一个垂直误差条% err和y长度相同，对应了每个数据点的误差大小errorbar(x,y,err); % 横坐标xerrorbar(x,y,neg,pos); % neg确定数据点向下误差，pos确定数据点向上误差errorbar(_,ornt); % 设置误差条的方向 &#x27;vertical&#x27;(default)|&#x27;horizontal&#x27;|&#x27;both&#x27;e = errorbar(_); 1234x = 1:10;y = x;err = [0.1:0.1:0.5, 0.1:0.1:0.5];errorbar(x,y,err,&#x27;both&#x27;); 离散图（针状图）stem 用法与plot一致。 1234y = 1:6;stem(y);hold on;stem(y+1,&#x27;filled&#x27;); % 绘制实心点 可以用stem3绘制三维针状图 阶梯图stairs 用法与plot一致 1234x = 0:0.1:2*pi;stairs(x, sin(x));hold on; grid on;stairs(x, cos(x)); 罗盘图compass 用箭头显示坐标为\\((u,v)\\)的向量，\\(u\\)和\\(v\\)长度一致，箭头起点位于原点。 12compass(u,v);compass(z); % 相当于compass(real(z), imag(z)); 与其他画图函数类似，可以指定线型、标记符号和颜色，可以用对象保存图像。 123u = [1, 0, -3, 0];v = [0, 2, 0, -4];compass(u,v); 箭头图quiver 12quiver(x,y,u,v); % 在(x,y)位置绘制由(u,v)确定的向量quiver(u,v); % 相当于quiver(1:n,1:m,u,v),其中u,v为m*n的矩阵 1234567[x, y] = meshgrid(-2:.2:2); % 返回网格坐标z = x.*exp(-x.^2 - y.^2);[dx, dy] = gradient(z, .2, .2); % 返回梯度contour(x, y, z); % 绘制等高线hold on;quiver(x, y, dx, dy);","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"进阶教程","slug":"Matlab/进阶教程","permalink":"https://pyxblog.cn/categories/Matlab/%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab符号运算","slug":"matlab-basic-5","date":"2022-08-06T15:06:23.000Z","updated":"2022-08-17T03:52:55.112Z","comments":true,"path":"2022/08/06/matlab-basic-5/","link":"","permalink":"https://pyxblog.cn/2022/08/06/matlab-basic-5/","excerpt":"Matlab系列教程5-符号运算，包括符号表达式的创建，符号矩阵运算，符号运算及带入求值的基本操作。","text":"Matlab系列教程5-符号运算，包括符号表达式的创建，符号矩阵运算，符号运算及带入求值的基本操作。 符号运算是数值计算的扩展，在运算过程中以符号表达式或符号矩阵为运算对象，实现了符号计算和数值计算的相互结合，使应用更灵活。 创建符号表达式 创建符号表达式，需要先创建符号变量，再使用它们编写表达式。 使用关键字syms创建符号变量： 123456789101112131415161718192021syms a b c % 一次可以创建多个变量，变量之间只能用空格衔接syms A [3 4] % 创建符号矩阵% A =% % [ A1_1, A1_2, A1_3, A1_4]% [ A2_1, A2_2, A2_3, A2_4]% [ A3_1, A3_2, A3_3, A3_4]syms &#x27;A%d%d&#x27; [2 2] % 可以通过占位符%d来改变默认格式% A =% % [ A11, A12]% [ A21, A22]syms M 3 % 3阶方阵% M =% % [ M1_1, M1_2, M1_3]% [ M2_1, M2_2, M2_3]% [ M3_1, M3_2, M3_3] 先将变量创建好，才能将含有该变量字符串转化为符号表达式 123456syms xstr = &#x27;x^3+2*x+1&#x27;; % 不识别2x，即*不可省略S = eval(str); % 将字符串转化为符号表达式% S =% % x^3 + 2*x + 1 也可以通过多项式部分提到的函数ploy2sym(p)，将系数向量转化为符号表达式 12345P = [1 2 2 1];S = poly2sym(P);% S =% % x^3 + 2*x^2 + 2*x + 1 可以通过函数sym(A)将矩阵\\(A\\)转化为符号表达式sym格式。只有符号表达式可以与符号表达式计算，数值表达式无法直接与符号表达式进行计算。 123456A = ones(2,3);S = sym(A) % 2*3 sym% S =% % [ 1, 1, 1]% [ 1, 1, 1] 使用sym()函数处理数值表达式时，应从尽量小的单位入手，以免产生精度上的误差，如 12345678910111213141516171819202122232425&gt;&gt; sym(1/1234567) % 错误 ans = 7650239286923505/9444732965739290427392 &gt;&gt; 1/sym(1234567) % 正确 ans = 1/1234567% ------------------------------------------------&gt;&gt; sym(exp(pi)) % 错误 ans = 6513525919879993/281474976710656 &gt;&gt; exp(sym(pi)) % 正确 ans = exp(pi) 符号矩阵运算 转置 Matlab默认符号属于复数，在使用'求转置时，会自动求出共轭转置。因此若只想求转置，应该使用.' 12345678910111213syms &#x27;A%d%d&#x27; [2 3]% A =% % [ A11, A12, A13]% [ A21, A22, A23]B = A.&#x27;% B =% % [ A11, A21]% [ A12, A22]% [ A13, A23] 行列式 12345678910syms &#x27;A%d%d&#x27; 2% A =% % [ A11, A12]% [ A21, A22]d = det(A)% d =% % A11*A22 - A12*A21 求逆 1inv(A); % A必须是方阵，结果用A中元素表示 求秩 1rank(A); % 返回一个整数 其他 函数 说明 inv(A) 求矩阵的逆，结果用\\(A\\)中的元素表示 rank(A) 求矩阵的秩，返回一个整数 eig(A) 求特征值、特征向量 svd(A) 奇异值分解 jordan(A) Jordan标准形运算 符号运算 因式分解 使用函数factor(S)实现 12345S = poly2sym([1 3 2]); % S = X^2+3*x+2factor(S)% ans =% % [ x + 2, x + 1] 也可用于质因数分解 12S = sym(276);factor(S) % [2 2 3 23] 表达式展开 123syms xS = eval(&#x27;(x+1)*(x+2)&#x27;);expand(S) % x^2 + 3*x + 2 也可以用于三角函数、指数函数、对数函数的展开 123syms x yS = eval(&#x27;sin(x+y)&#x27;);expand(S) % cos(x)*sin(y) + cos(y)*sin(x) 表达式化简 123syms xS = eval(&#x27;sin(x)^2+cos(x)^2&#x27;);simplify(S) % x+1 分式通分 12345syms x yS = eval(&#x27;1/x+1/y&#x27;);[n, d] = numden(S)% n - 分子 n=x+y% d - 分母 d=x*y 代入/计算结果 通过函数subs(S,old,new)实现，返回值仍是sym类型。 12345678910111213syms F m a Ffstr = &#x27;Ff+F&#x27;;S = eval(str);S = subs(S,F,a*m) % 用a*m代换F% S =% % Ff + a*mres = subs(S,[a m Ff],[2 10 15]) % 分别给[a m Ff]赋值为[2 10 15]% res =% % 35","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab矩阵","slug":"matlab-basic-4","date":"2022-08-06T14:50:17.000Z","updated":"2022-08-17T03:52:20.793Z","comments":true,"path":"2022/08/06/matlab-basic-4/","link":"","permalink":"https://pyxblog.cn/2022/08/06/matlab-basic-4/","excerpt":"Matlab系列教程4-矩阵，包括基本的矩阵创建、编辑和运算操作。","text":"Matlab系列教程4-矩阵，包括基本的矩阵创建、编辑和运算操作。 矩阵是由个数排成的行列数表，记成 含有个维行向量，个维列向量。 矩阵创建 创建 - 直接输入 用[]定义矩阵，同一行的元素用,或空格分割，不同行的元素用;或回车分割 矩阵的大小不需要预先定义，若[]中不写元素，表示空矩阵 创建 - 从文件中读取 可以将较为常用的矩阵写入.m文件，调用时直接运行该文件，即可在工作台看到相应矩阵。除此之外，可以使用load命令调用.txt等类型的文件。 创建 - 用函数生成特殊矩阵 可以用某些函数生成具有某些特点的矩阵，常用函数如下 函数 说明 eye(n) eye(m,n) eye(size(A)) 创建指定大小的单位矩阵 ones(n) ones(m,n) ones(size(A)) 创建指定大小矩阵，其中元素均为1 zeros(n) zeros(m,n) zeros(size(A)) 创建指定大小矩阵，其中元素均为0 rand(n) rand(m,n) rand(size(A)) 创建指定大小矩阵，其中元素服从范围内的均匀分布 randn(n) randn(m,n) randn(size(A)) 创建指定大小矩阵，其中元素服从标准正态分布 compan(P) 创建系数向量为的多项式的伴随矩阵 diag(v) 创建以向量中的元素为对角线的对角阵 hilb(n) 创建一个的Hilbert矩阵 magic(n) 创建一个阶幻方 sparse(A) 将矩阵转化为稀疏矩阵形式，即由的非零元素和下标构成稀疏矩阵 矩阵编辑 矩阵拼接 123456789A = [1 2 3 4];B = zeros(2);C = ones(2);D = [A; B C]% D =% % 1 2 3 4% 0 0 1 1% 0 0 1 1 用,或空格衔接，以实现矩阵的横向拼接，如上例中的矩阵与矩阵 用;或换行衔接，以实现矩阵的纵向拼接，如上例中的矩阵与拼接矩阵 引用矩阵中的某些元素 对矩阵的每个维度均指定一个索引，即可引用相应的数据。 索引可以是标量（一个数）、向量（只能包含正整数）和:（表示全部）。 12345678910A = [1 2 3 4 5 6 7 8 9 10 11 12];A(2,2) % 第2行第2列，即元素6A(3,[2,4]) % 第3行第2和第4列，即[10 12]A(1:3,3) % 第3列第1行至第4行，即[3;7;11]A(3,:) % 第3行所有元素，即[9 10 11 12]A(:,4) % 第4列所有元素，即[4;8;12] 矩阵变形 变换维度：通过函数reshape(X,m,n)实现：将中的数据按列取出，再根据指定的维度，从左至右按列填充 123456789101112t = 1:12;A = reshape(t, 2, 6)% A =% 1 3 5 7 9 11% 2 4 6 8 10 12B = reshape(A, 4, 3)% B =% 1 5 9% 2 6 10% 3 7 11% 4 8 12 也可以仅指定一个维度，让函数自适应另一个维度的大小 12C = reshape(B, 3, []); % 重构为3*4的矩阵D = reshape(C, [], 2); % 重构为6*2的矩阵 旋转与翻转 函数 说明 rot90(X) rot90(X,k) 将矩阵逆时针方向旋转 fliplr(X) 将矩阵左右翻转 flipud(X) 将矩阵上下翻转 flipdim(X,dim) dim=1时对行翻转，dim=2时对列翻转 三角阵/对角阵的抽取 提取对角线/用对角线构造对角阵 12345678910111213141516171819202122v = 1:3;A = diag(v) % 生成以向量v为对角线的对角阵% 1 0 0% A = 0 2 0% 0 0 3v = diag(A) % 提取矩阵A的对角线，生成列向量% 1% v = 2% 3A = diag(v,2) % 生成以向量v为主对角线上第2条对角线的对角阵% 0 0 1 0 0% 0 0 0 2 0% A = 0 0 0 0 3% 0 0 0 0 0% 0 0 0 0 0v = diag(A,2) % 提取主对角线上第2条对角线，生成列向% 1% v = 2% 3 提取上/下三角阵 123456789101112131415161718192021A = ones(3);tril(A) % 提取下三角阵% 1 0 0% 1 1 0% 1 1 1tril(A,1) % 从主对角线上第一条对角线开始提取下三角阵% 1 1 0% 1 1 1% 1 1 1triu(A) % 提取上三角阵% 1 1 1% 0 1 1% 0 0 1triu(A,-1) % 从主对角线下第一条对角线开始提取上三角阵% 1 1 1% 1 1 1% 0 1 1 几个函数虽然功能不同，但第二个参数中对角线的定位规则一致，正数代表主对角线上的对角线，负数代表下面的对角线，提取时取闭区间。 矩阵运算 加减运算 要求进行运算的矩阵形状一致（即各维度长度一致），计算时对应位置相加减即可，有交换律和结合律。 乘运算 若有三个矩阵，则对矩阵中的任意一个元素，有 即 其中矩阵的列数（第二维度）需要等于矩阵的行数（第一维度）。 矩阵乘运算不满足交换律。 点乘运算 两个形状一致的矩阵，对应位相乘，得到一个形状不变的矩阵。 除法运算 - 左除 线性方程组，若非奇异，即它的逆矩阵存在，则可解出X=inv(D)*B=D\\B 条件：的阶数等于的行数。（非奇异表明是方阵） 除法运算 - 右除 线性方程组，若非奇异，即它的逆矩阵存在，则可解出X=B*inv(D)=B/D 条件：的列数等于的阶数。 除号偏向哪边，哪边要求非奇异 使用除法运算解线性方程组比使用inv求逆的方法更迅速，且拥有更小的残差 常用矩阵运算函数 函数 说明 cond(A) 返回2-范数逆运算的条件数，即最大奇异值与最小奇异值之比 condest(A) 返回 1-范数条件数的下限 det(A) 返回矩阵的行列式（一个值） eig(A) 返回矩阵的特征值/特征向量 inv(A) 返回矩阵的逆 norm(A,p) 返回矩阵的范数，p可以为1 2 Inf 'fro'，不填默认为2 normest(A) 返回矩阵的2-范数，相当于norm(A,2) rank(A) 返回矩阵的秩 orth(A) 矩阵的正交化运算，返回适用于矩阵范围的标准正交基，列数等于秩 rcond(A) 返回1-范数的逆条件数 trace(A) 返回矩阵对角线之和，即矩阵的迹 expm(A) 矩阵指数运算，每个元素变为 logm(A) 矩阵对数运算，每个元素变为 sqrtm(A) 矩阵开方运算，返回使 cdf2rdf 将复数对角矩阵转换成实数块对角矩阵 rsf2csf 将实数块对角矩阵转换成复数对角矩阵 rref 将矩阵转换成逐行递减的阶梯矩阵 funm 一般的矩阵函数 关于矩阵的条件数与“病态”： 矩阵的条件数用于刻画矩阵的“病态”程度，定义为： 它是一个不小于1的实数，当时，说矩阵是“病态”的，反之则是“良态”的。 奇异值分解 SVD SVD分解是指将一个的矩阵表示为三个矩阵乘积的形式：，其中为阶方阵，为阶方阵，为阶对角阵，其对角线元素为矩阵的奇异值且满足： 其中为矩阵的秩。 12s = svd(A); % 返回矩阵A的奇异值列向量s[U,S,V] = svd(A); % 返回矩阵A的奇异值分解因子U、S和V","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab元胞与结构体","slug":"matlab-basic-3","date":"2022-08-06T14:46:00.000Z","updated":"2022-08-17T03:52:07.503Z","comments":true,"path":"2022/08/06/matlab-basic-3/","link":"","permalink":"https://pyxblog.cn/2022/08/06/matlab-basic-3/","excerpt":"Matlab系列教程3-元胞与结构体，包括单元型变量（即元胞）和结构型变量（即结构体）的生成及基本操作。","text":"Matlab系列教程3-元胞与结构体，包括单元型变量（即元胞）和结构型变量（即结构体）的生成及基本操作。 Matlab中的特殊变量允许用户将不同但相关的数据类型集成一个单一的变量，以便数据的管理，类似C++中的结构体。 单元型变量（元胞） 单元型变量是以“单元”为元素的数组，每个单元可以包含各种类型的数据（如矩阵、字符串），通过{}创建，通过下标直接引用。 数组类型为cell，其中每个元素的类型也为cell。 12345a = 1:10;b = 'test';c = [1+2i,1 1,1+2i];ce = {a, b, c}; 可以通过cell()函数预先分配空间，再对其中的元素进行逐个赋值。 指令 效果 cell(n) 生成阶空单元数组 cell(m,n)/cell([m,n]) 生成阶空单元数组 cell(m,n,p,...)/cell([...]) 生成阶空单元数组 cell(size(X)) 生成与矩阵同维的空单元数组 有关单元型变量的函数：可以通过lookfor cell查找学习 函数 说明 cellfun(func,C) 对单元型变量中的每个元素依次执行函数func celldisp(C) 在命令行中逐个输出每个元素的具体内容 cellplot(C) 用彩色图形窗口逐个显示元素的内容 num2cell(num) 将数值转换为单元型变量 deal 输入输出处理 cell2struct(C) 将单元型变量转换为结构型变量 struct2cell(St) 将结构型变量转换为单元型变量 iscell(X) 判断是否为单元型变量 reshape(X,[...]) 将中的元素按列取出，再按列重构为[]规定的维度 结构型变量 结构型变量是根据属性名field组织起来的不同数据类型的集合，每个属性可以包含不同的数据类型，如字符串、矩阵等，类似字典。通过函数struct来创建，通过属性名来引用属性值，通过索引来引用相应元素。 1234st = struct('name',{'Tom','Amy'}, 'sex',{'male','female'}, 'age',{18});st(1); % 每个属性的第一个值 name:'Tom', sex:'male', age:18st.sex; % 所有的sex属性 ans='male', ans='female'st(2).name; % name属性的第二个值 ans='Amy' 创建结构型变量时，要求每个属性的长度一致，或者为标量（只有一个值），如上述的name和sex长度一致，age是标量。 有关结构型变量的函数：可以通过lookfor struct查找学习 函数 说明 fieldnames(st) 返回结构型变量的所有属性名 getfield(st,fieldName) 返回指定属性名的所有属性值 setfield(st,fieldName,value) 设定指定属性名的值为value rmfield(st,fieldName) 删除指定属性 isfield(st,fieldName) 判断fieldName是不是st的属性 isstruct(st) 判断st是否是结构型变量","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab向量与多项式","slug":"matlab-basic-2","date":"2022-08-05T14:51:28.000Z","updated":"2022-08-17T03:51:50.168Z","comments":true,"path":"2022/08/05/matlab-basic-2/","link":"","permalink":"https://pyxblog.cn/2022/08/05/matlab-basic-2/","excerpt":"Matlab系列基础教程2-向量与多项式，包括向量的生成与运算、多项式的生成与运算。","text":"Matlab系列基础教程2-向量与多项式，包括向量的生成与运算、多项式的生成与运算。 向量是由个数组成的有序数组，记成或，叫做维向量，向量的第个分量称为。 向量生成与引用 向量生成 直接输入 向量用[]扩起来，元素之间用,或空格隔开，;则相当于换行 冒号法 t = 区间左端点 : 增量 : 区间右端点; 1234567t = first:increment:last;% first - 从first开始（闭区间）% last - 到last为止（闭区间）% increment - 增量，默认为1t = 0:2:10; % [0 2 4 6 8 10]t = 0:5; % [0 1 2 3 4 5]t = 10:-2:0; % [10 8 6 4 2 0] 利用函数linspace(区间左端点, 区间右端点, 个数) 123456linspace(first_value, last_value, number);% 在指定范围内等间隔采样% first_value - 从first_value开始（闭区间）% last_value - 到last_value结束（闭区间）% number - 包含number个元素x = linspace(0,10,5); % [0 2.5 5 7.5 10] 利用函数logspace(区间左端点, 区间右端点, 个数) 123456logspace(first_value, last_value, number);% 在指定范围内等间隔采样，但区间取10的幂% first_value - 从10^first_value开始（闭区间）% last_value - 到10^last_value结束（闭区间）% number - 包含number个元素x = logspace(1,3,3); % [10 100 1000] 可以同时采用多种方法创建向量，并使用[]将它们合并 12x = [2:4 4,5,6 linspace(10,20,2)]; % (2 3 4) (4 5 6) (10 20) 向量引用 格式 说明 x(index) 表示向量中的第个元素 x(i:j) 表示向量中的第到第个元素 x(i:delta:j) 表示向量中的第到第个元素，每个取一个值 向量的索引从1开始 可以用另一个向量作为索引，去访问向量，向量只能包含正整数，且不能超过的索引范围 12345x = 1:2:20;n1 = [1,4,9,7];n2 = 2:3:10; % [2,5,8]x(n1) % [1 7 17 13]x(n2) % [3 9 15] 向量运算 四则运算 相当于对向量中的元素分别进行四则运算 12345x = 2:2:10; % [2 4 6 8 10]x+1 % [3 5 7 9 11]x-1 % [1 3 5 7 9]x*2 % [4 8 12 16 20]x/2 % [1 2 3 4 5] 矩阵运算 向量可以看做特殊的矩阵，可以用矩阵运算的规则进行向量运算 1234567x = 2:2:10; % [2 4 6 8 10]y = 1:5; % [1 2 3 4 5]x+y % [3 6 9 12 15]x-y % [1 2 3 4 5]x.*y % [2 8 18 32 50] 按位乘x./y % [2 2 2 2 2] 按位除x*y' % 110 矩阵乘法 点积（数量积、内积） 向量和的点积定义为 其中，向量和向量必须长度相同。 123dot(a,b);sum(a.*b);sum(a*b'); 向量积（外积、叉积、叉乘） 向量和的向量积模长为 其方向与向量和所在平面垂直，且遵循右手定则。 12345cross(a,b); % 返回a和b的叉积，此时a和b必须是3维的向量% 计算其他维度叉积可以通过help cross查看对应方法x = [1,0,0];y = [0,1,0];z = cross(x,y); % z = [0,0,1] ps. 点积的结果是一个数，向量积的结果是一个同维向量 多项式 在Matlab中，用系数向量表示相应的多项式，以便进行多项式计算： 系数中的0不能省略，如 多项式的创建 使用系数向量p，通过函数poly2sym(p)创建多项式，返回sym类型多项式 1s = poly2sym([1,2,1]); % x^2 + 2*x + 1 使用根向量root，通过函数poly(root)创建多项式，返回系数向量 123root = [1 2];p = poly(root); % [1 -3 2]poly2sym(p) % x^2 - 3*x + 2 也可以编写字符串str，再通过eval(str)函数将其转换为sym类型。 sym类型表示“符号表达式”，也可以直接用于计算，后续的章节中包含相关内容。 多项式运算 多项式运算通过系数向量进行。 加减运算直接用+-实现，相加、相减的两个向量必须大小相等。 多项式乘法 相当于执行两个数组的卷积，用函数conv(p1,p2)实现，返回结果多项式的系数向量 123p1 = [1 2 1];p2 = [1 2 1];conv(p1,p2) % [1 4 6 4 1] 多项式除法 相当于执行两个数组的解卷，用函数deconv(p,q)实现，返回结果多项式的系数向量 123456789[k, r] = deconv(p, q);% k - p除以q的商% r - p除以q的余式% p = conv(q, k) + r;p1 = [1 2 1];p2 = [1 2 1];p = conv(p1,p2); % [1 4 6 4 1]deconv(p, p1) % [1 2 1] 多项式求导 通过函数polyder(p)实现，返回结果多项式的系数向量 12p = [1 1 1 1 1];polyder(p) % [4 3 2 1]","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab基础知识","slug":"matlab-basic-1","date":"2022-08-05T14:19:06.000Z","updated":"2022-08-17T03:51:27.330Z","comments":true,"path":"2022/08/05/matlab-basic-1/","link":"","permalink":"https://pyxblog.cn/2022/08/05/matlab-basic-1/","excerpt":"Matlab系列基础教程1-基础知识，包括Matlab中的常量、数据类型、运算符、复数与三角函数的基本用法。","text":"Matlab系列基础教程1-基础知识，包括Matlab中的常量、数据类型、运算符、复数与三角函数的基本用法。 常量 常量名称 对应含义 pi 圆周率 eps 浮点相对精度，常用于防止0出现在分母上 inf(Inf) 无穷大，如 NaN(nan) 不定值，如、、 i(j) 复数中的虚数单位 realmin 最小正浮点数 realmax 最大正浮点数 ps. 常量可以被赋值，使用命令clear+变量名或重启Matlab可以将常量恢复初始值。 数据类型 整型 含义 占用空间 char 字符型 1字节 unsigned char 无符号字符型 1字节 short 短整型 2字节 unsigned short 无符号短整型 2字节 int 有符号整型 4字节 unsigned int 无符号整型 4字节 long 长整型 4字节 unsigned long 无符号长整型 4字节 浮点型： 十进制数形式：由数字和小数点组成 指数形式：一般形式为 aEn，其中a为10进制数，n为10进制整数，表示 可以分为两类：单精度型和双精度型 单精度 float，占4字节，数值范围，最多7位有效数字 双精度 double，占8字节，数值范围，最多16位有效数字 ps. 使用命令format可以控制命令行的输出格式，参考help format 类型转换 12nu = 123;st = num2str(nu); % '123' 遇到不熟悉的类型转换时，可以使用lookfor指令查找相关函数： 123456789101112131415161718192021&gt;&gt; lookfor num2num2cell - Convert numeric array into cell array.num2hex - Convert singles and doubles to IEEE hexadecimal string formatnum2str - Convert numbers to character representationnum2ruler - Convert numeric array to ruler-appropriate array datatypeenum2val - Converts an enumerated string to its numerical equivalent.num2cell - Convert numeric codistributed array into cell arraynum2str - overloaded for gpuArraysnum2mstr - Convert number to string in maximum precision.iptnum2ordinal - Convert positive integer to ordinal string.num2ordinal - Convert positive integer to ordinal character vector.signal_num2str - Convert the number to a string.num2goid - Converts numbers to Gene Ontology IDs.num2str - Convert numbers to character representationdefnum2 - Sets Default channel namesnum2deriv - Numeric two-point network derivative function.num2base - Convert stored integers to stringsnum2sdec - Convert stored integers of array of fi objects to signed decimal representationnum2fixpt - Quantize a value using a Fixed-Point Designer representation.num2alphaheaders - Generate Alpha headers from a number (usually column).&gt;&gt; 运算符 算数运算符 定义 + 算数加 - 算数减 * 算数乘 .* 点乘 ^ 算数乘方 .^ 点乘方 \\ 算数左除 .\\ 点左除 / 算数右除 ./ 点右除 ' 矩阵共轭转置 .' 矩阵转置，不求共轭 其中： 左除a\\b表示，右除a/b表示 A*B表示矩阵乘法，要求矩阵的第二维度与矩阵的第一维度相等，A.*B表示矩阵按位乘法，要求矩阵和矩阵的形状相同，对乘方具有一致要求 A+B要求矩阵和矩阵的形状相同，对算数减有一致要求 A+a表示对矩阵中的每个元素都，对其他算数运算有一致要求 关系运算符 定义 == 等于 ~= 不等于 &gt;(&lt;) 大于/小于 &gt;=(&lt;=) 大于等于/小于等于 逻辑运算符 定义 &amp; 逻辑与 | 逻辑或 ~ 逻辑非 xor 逻辑异或 any 有非零元素则为真 all 所有元素均非零则为真 ps. 有关优先级 算数运算符 &gt; 关系运算符 &gt; 逻辑运算符 逻辑运算符中，~具有最高优先级，&amp;和|优先级相同 复数及三角运算函数 复数运算函数 对应含义 abs(z) 返回绝对值或复数的模 theta=angle(z) 返回复数的相位，范围 z=complex(a,b) 返回复数 conj(z) 返回复数的共轭 a=real(z) 返回复数的实部 b=imag(z) 返回复数的虚部 isreal(x) 判断矩阵是否含有复数 unwrap 平移相位角 cplxpair 将复数排序为复共轭对组 三角运算函数 对应含义 sin() 正弦函数 cos() 余弦函数 tan() 正切函数 cot() 余切函数 sec() 正割函数 csc() 余割函数 ps. 反三角函数=a+三角函数，如反正弦为asin()","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab命令行","slug":"matlab-basic-0","date":"2022-08-05T13:34:25.000Z","updated":"2022-08-17T03:51:10.630Z","comments":true,"path":"2022/08/05/matlab-basic-0/","link":"","permalink":"https://pyxblog.cn/2022/08/05/matlab-basic-0/","excerpt":"Matlab系列基础教程0-命令行常用指令","text":"Matlab系列基础教程0-命令行常用指令 常用指令 指令含义 指令 help+函数名 精确查询函数 lookfor+函数信息 模糊查询函数 who 内存变量列表 whos 内存变量详细信息 which + 文件名 查找文件位置 exist+变量名 判断变量是否存在 path 查看当前所有路径 addpath+路径 添加路径 clc 清除命令行 clear 清除内存变量 close all 关闭所有窗口 应用示例 使用 help 指令查询函数用法 如同所示，使用 help 指令查询已知函数名的任意函数用法，其中大部分常用函数均有官方的中文版用法详解及相关实例，少部分尚未完成汉化（英文版文档），但也可以通过实例看懂。 使用 lookfor 指令查找相关函数 如同所示，使用 help 指令查询与 plot 相关的函数，会输出函数名/函数描述中带有\"plot\"字段的所有结果以供查看。 一般情况下，在主函数中前三行会写： 123clearclose allclc 作用是在主函数最开始依次执行： 清除内存变量 关闭之前打开的图形窗口 清空命令行（上一次运行代码的输入输出） 大家可以养成习惯哦！","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]}],"categories":[{"name":"分享","slug":"分享","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/"},{"name":"日常","slug":"分享/日常","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/%E6%97%A5%E5%B8%B8/"},{"name":"推免","slug":"分享/推免","permalink":"https://pyxblog.cn/categories/%E5%88%86%E4%BA%AB/%E6%8E%A8%E5%85%8D/"},{"name":"数据压缩","slug":"数据压缩","permalink":"https://pyxblog.cn/categories/%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/"},{"name":"小技巧","slug":"小技巧","permalink":"https://pyxblog.cn/categories/%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/"},{"name":"实战","slug":"爬虫/实战","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/%E5%AE%9E%E6%88%98/"},{"name":"markdown系列教程","slug":"markdown系列教程","permalink":"https://pyxblog.cn/categories/markdown%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/"},{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"实战demo","slug":"深度学习/实战demo","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98demo/"},{"name":"python","slug":"python","permalink":"https://pyxblog.cn/categories/python/"},{"name":"基础教程","slug":"python/基础教程","permalink":"https://pyxblog.cn/categories/python/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"},{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"进阶教程","slug":"Matlab/进阶教程","permalink":"https://pyxblog.cn/categories/Matlab/%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"numpy","slug":"numpy","permalink":"https://pyxblog.cn/tags/numpy/"},{"name":"matplotlib","slug":"matplotlib","permalink":"https://pyxblog.cn/tags/matplotlib/"},{"name":"前端","slug":"前端","permalink":"https://pyxblog.cn/tags/%E5%89%8D%E7%AB%AF/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/tags/%E7%88%AC%E8%99%AB/"},{"name":"scrapy","slug":"scrapy","permalink":"https://pyxblog.cn/tags/scrapy/"},{"name":"latex","slug":"latex","permalink":"https://pyxblog.cn/tags/latex/"},{"name":"markdown","slug":"markdown","permalink":"https://pyxblog.cn/tags/markdown/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://pyxblog.cn/tags/PyTorch/"},{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]}