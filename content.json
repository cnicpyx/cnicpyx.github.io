{"meta":{"title":"清弦小站","subtitle":"","description":"BLOG","author":"庞宇轩","url":"https://pyxblog.cn","root":"/"},"pages":[{"title":"","date":"2022-08-06T02:27:41.716Z","updated":"2022-08-06T02:27:41.716Z","comments":false,"path":"404.html","permalink":"https://pyxblog.cn/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2022-09-03T12:46:41.359Z","updated":"2022-08-17T11:57:36.675Z","comments":false,"path":"about/index.html","permalink":"https://pyxblog.cn/about/index.html","excerpt":"","text":"庞宇轩 中国传媒大学 信息与通信工程学院 2019级广播电视工程专业 教育背景 中国传媒大学-信息与通信工程学院-广播电视工程专业 专业评级：A+中国传媒大学国家特色专业、王牌工科专业，属于电子信息类专业，主修计算机&amp;通信两个方向的课程。 学业成绩 必修GPA 必修&amp;限选GPA 专业排名 专业总人数 3.85 3.86 1 82 证明材料 主修课程 高等数学 概率论与数理统计 C/C++程序设计 数据结构与算法 计算机网络 99 95 100 100 94 数字信号处理 数字视音频处理 信息论与编码原理 电子系统仿真与设计 计算机网络程序设计 97 96 96 99 98 证明材料 英语水平 CET-4 CET-6 IELTS IELTS-Reading IELTS-Listening IELTS-Writing IELTS-Speaking 593 472 6.5 8.0 6.5 6.5 5.5 证明材料 项目经历 首届MCL大学生学术训练季 时间：2020.08-2021.03 大一学年暑期，作为唯一一位2019级成员入选首届MCL大学生学术训练季。 首届MCL大学生学术训练季https://www.cuc.edu.cn/news/2020/0809/c1902a172348/pagem.htm 开启一周一组会的科研道路，初期通过吴恩达机器学习系列课程学习基础知识，后期阅读推荐系统领域经典文献SVD++、FM、BPR、NCF等，并理解学习其源码。 媒体融合与传播国家重点实验室 时间：2020.10-至今 大二上学期，入选我校创新人才“菁英班” 关于创新人才“菁英班”： 同届学生中共30人入选，每人选择一位博导/硕导开展科研训练，两年后毕业，毕业要求包括论文发表、竞赛获奖、大创经历等。相关内容参考： 创新人才“菁英班”http://www.cuc.edu.cn/news/2019/1126/c1902a159436/page.htm 开始跟随广播电视工程专业系主任杨盈昀教授从事智能图像与视音频领域的研究工作，从属于我校「媒体融合与传播国家重点实验室」下的智能视音频与超高清视频技术团队。"},{"title":"所有专栏","date":"2022-08-24T20:08:39.114Z","updated":"2022-08-06T02:27:41.719Z","comments":false,"path":"categories/index.html","permalink":"https://pyxblog.cn/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2022-08-06T02:27:41.720Z","updated":"2022-08-06T02:27:41.720Z","comments":true,"path":"friends/index.html","permalink":"https://pyxblog.cn/friends/index.html","excerpt":"提供一些日常学习生活中常用的网站&我的宝藏网站","text":"提供一些日常学习生活中常用的网站&我的宝藏网站 链接失效请直接在评论区反馈哦～"},{"title":"资源共享","date":"2022-08-06T02:27:41.720Z","updated":"2022-08-06T02:27:41.720Z","comments":true,"path":"share/index.html","permalink":"https://pyxblog.cn/share/index.html","excerpt":"提供一些日常学习生活中常用的网站&我的宝藏网站","text":"提供一些日常学习生活中常用的网站&我的宝藏网站 链接失效请直接在评论区反馈哦～"},{"title":"所有标签","date":"2022-08-06T02:27:41.720Z","updated":"2022-08-06T02:27:41.720Z","comments":false,"path":"tags/index.html","permalink":"https://pyxblog.cn/tags/index.html","excerpt":"","text":""},{"title":"个人作品集","date":"2022-09-03T17:38:16.852Z","updated":"2022-09-01T03:26:12.376Z","comments":false,"path":"portfolio/index.html","permalink":"https://pyxblog.cn/portfolio/index.html","excerpt":"","text":"“互联网+”大赛项目——拾忆 项目发起自2021年4月，以三重态域翻译网络和超分重建算法为核心算法，面向B端用户（档案馆、党史馆等文博机构）开展“AI+人工”影像精修服务，我为该项目的全程负责人 项目内容 随着互联网技术的发展和党史教育的普及，全国各地档案馆、博物馆等机构的馆藏数字化工作陆续开展，数字存储和线上展览对历史影像的质量提出了更高的要求，历史照片、视频的修复逐渐成为热点需求。 然而，现有的人工修复耗时长、效率低，自动修复服务功能单一，效果差，无法满足海量的市场需求。 本项目依托中国传媒大学媒体融合与传播国家重点实验室，开创性地融合了“AI预处理”和“人工细节优化”，面向各大档案馆、党史馆提供高效的影像精修服务，协助馆藏数字化工作的顺利开展。 项目现已申请专利7项，软件著作权6项，发表高水平学术论文2篇，与朝阳区档案馆等多家机构签订合作意向并投入使用，初步取得行业认可。 Your browser does not support the video tag. 产品设计与实现 拾忆是基于AI模型的老旧影像解决方案，在可以提供随时随地、任意设备访问的同时，还需要确保模型端、应用程序的稳定性、可拓展性以及安全性。基于此，我们做了前端基于 Uni-App，后端响应核心基于 Spring Cloud，模型运算接口基于 Flask 的多集群负载均衡的技术选型。 前端设计 我们在前端架构层面致力于实现： 优质的用户交互逻辑，最大化降低操作难度，提升使用欲望； 明晰的媒体展示能力，用户可直观感受修复效果，并根据需求实现基础的二次编辑（裁剪、添加滤镜等）； 设计语言统一，符合大众审美直觉，提升自身品牌辨识度。 基于此，我们做了模块化的前端设计，界面以黑白紫为主色调，按钮及模块均进行圆角化处理，设计语言统一。弹出窗口及操作界面背景均使用磨砂风格，符合大众审美直觉。设计中使用大量图形语言，风格统一，操作含义明晰，为用户操作提供直观指引。 后端架构 我们在后端架构层面致力于实现： 拥有用户鉴权模块及权限组系统，可实现统一管理及调整； 拥有快速扩容能力，基于微服务集群思想，实现分钟级快速扩容； 拥有高并发访问潜力，实现多级缓存，服务集群负载均衡； 拥有数据灾备能力，实现数据库主从热备，主主互备。 基于此，我们做了如下技术构型，下图展示典型部署（站点）中的核心组件及其组成结构： 用户服务及功能服务集群 用户服务及功能服务集群（称为“用户集群”）是拾忆站点的中心管理组件，为实现站点可靠性和可用性，用户集群应安装在多个服务器上。用户集群将与客户端通信实现用户请求的分发，包括用户鉴权，用户请求，数据储存，资源调配。用户上传到云端的媒体资源及处理后的影音文件将储存在 OSS 对象储存中，以实现全球高速数据分发。 数据库 为实现多地负载均衡，用户集群至少需要三个高性能 MySQL 数据库，用于动态数据和会话信息储存及灾备，核心数据库应与用户集群建立持续性链接。站点还使用一个配置数据库和一个日志数据库，默认情况下无需处理高强度请求。所有的数据库链路均加入 Redis 缓存，并进行读写分离操作以实现高并发场景下的稳定应用。 模型运算集群 鉴于修复模型由 Pytorch 训练，尚无法实现模型导出，故在选型中考虑使用基于 Python 的 Flask 框架提供模型运算集群的 Restful API 响应服务。同时模型运算实例成本较高，为降低整体运行成本，引入基于 Eureka 的微服务管理框架实现集群的统一管理，将模型运算实例打包至 Docker，根据用户请求量进行动态拓展。用户请求到达站点后将先由用户集群按任务优先级加入请求队列，获取空闲模型运算实例地址后通过 API 提交媒体资源及修复请求。若队列内请求积压过多用户集群将自动发起扩容流程。 其余性能优化 鉴于老照片修复本身存在出现社交爆点的可能性，拾忆 App 服务可能面临短时间并发量陡增的场景。为实现服务的高可用，请求链路中配置了 Spring Cloud Gateway 作为微服务网关，搭配 Ribbon 框架实现全局负载均衡，将根据用户地域、画像、来源等分配至不同的用户集群处理请求，降低单一集群请求压力。同时，为避免某段时间请求陡增导致部分节点宕机从而影响全局服务稳定性，服务端使用 Hystrix 框架实现熔断机制，当节点请求错误率上升达到阀值，将暂时隔离该节点进而保证用户体验。 所获荣誉 2021.04 2021年大学生创新创业训练计划国家级立项 2021.07 第七届中国国际“互联网+”大学生创新创业大赛北京市一等奖 2021.10 第四届“京津冀-粤港澳”青年创新创业大赛京津冀赛区决赛二等奖，入围全国总决赛（因疫情延期） 2021.11 第七届中国国际“互联网+”大学生创新创业大赛全国铜奖，创造我校参赛以来最高获奖记录 2022.04 2021年大学生创新创业训练计划，获得优秀结项，并被我校唯一推荐至2022大创年会 2022.04 2022年大学生创新创业训练计划国家级立项 2022.05 首届“京彩大创”北京大学生创新创业竞赛“百粒‘金种子’项目（2022）”、文化创意赛道决赛三等奖 2022.07 第八届中国国际“互联网+”大学生创新创业大赛北京市一等奖，再次入围全国总决赛 2022.08 第九届“创青春”中国青年创新创业大赛全国铜奖，创造我校历史新高 “互联网+”大赛项目——起舞元宇宙 项目发起自2021年12月，以舞蹈引擎概念为核心，通过单目摄像头动作捕捉、动作迁移等技术，打造高效、智能、易操作的虚拟人创作工具，我为该项目的技术人员 项目内容 随着5G、虚拟现实、人工智能等技术的日渐成熟，元宇宙概念开始流行。虚拟数字人作为元宇宙的人物要素，受到青年群体的广泛关注，其市场潜力巨大。但目前元宇宙仍处于初期阶段，充满了无生机的算法，项目将舞蹈这种表现形式作为切入点，以舞蹈的生机赋予元宇宙灵动之美。 团队与中传动画与数字艺术学院师生合作，邀请动院师生参与产品测评，与北邮、清华技术相关教师充分交流，攻克技术难关。团队作为唯一一支本科生团队进入创业黑马元宇宙数字人加速器，在2022数字人生态论坛现场取得结业证书，通过创业黑马对接万兴科技、大头兄弟等企业合作，与国内动捕龙头公司诺亦腾成为战略合作伙伴，并且在中传校方的支持下，与诺亦腾共建动捕实验室。目前团队正在与故宫、国家大剧院等洽谈合作意向，打造数字化演出，让艺术无国界，让艺术跨时空。 项目负责人接受人民网、新华社采访报道，已获得80万+阅读量。 Your browser does not support the video tag. 项目简介 产品以“舞蹈引擎”这一理念为核心，类似于游戏引擎的概念，即提供方便创作者简易快捷地创作虚拟人舞蹈的工具。为了降低创作门槛，让非专业人士也能参与到虚拟人创作之中，我们提供了动作库与动作编辑街接算法。 在用户提供模型后，团队拥有“自动绑骨”这一特定功能，这一功能可以把用户提供的图片或模型自动添加骨骼，使其变得可动，完成图像骨骼模型绑定。 在驱动过程中，团队基于用户提供的图像或视频，可以实现面部动作及躯干动作的捕提，在骨骼模型的基础上，我们同时实现了对肌肉皮肤系统的特有优化，在骨骼运动的同时，肌肉和皮肤也同步运动，使整体动态效果更加自然、真实。这一系统也可根据不同用户的体型体态实现虚拟人的个性化差异。同时，可以根据虚拟人的动作意图，实现动作的自动驱动。例如在虚拟人完成“坐下”这一动作的时候，可根据座椅的高度、材质、角度等调整虚拟人坐姿，提升创作效果。 在创作工具上，协作工具允许多人编辑同一模型以及虚拟IP 的动作和模式，同时提供操作简洁易懂的可视化界面，使虚拟人创作无需技术门槛，成为普通大众的乐趣。在这一模式下，协作工具将设置版本管理员，监督参与编辑的用户所编辑的内容，并对其进行管理和调整，维护模型编辑的秩序。自动内容创作功能，是在建立舞蹈动作数据库与音乐片段库后，使产品能够根据音乐实现为虚拟人自动编舞的功能，使创作快捷简便。 个人博客 pyxblog.cn 我的个人博客https://pyxblog.cn采用hexo框架+github page搭建，日常发布一些技术文档，供同学朋友和低年级的师弟师妹查看。 全局配置卡通形象，基于github的开源项目hexo-helper-live2d，位于页面右下角，会根据鼠标的移动产生交互动作，移动端不显示 首页的cover封面采用轮播机制，每30,000ms随机切换一张，切换页面时也会自动切换背景 向下滚动后，进入博客主页，导航栏固定在页面顶端，右侧搜索框可以实现全站的全文搜索，页面按左右两栏格式布局，左侧自动按发布时间顺序显示最新文章，右侧包括「个人信息」、「联系博主」和「专栏」三个模块 进入文章页面，可以从文章顶端的top meta中进入文章所在专栏，依旧采用左右两栏布局，左侧为正文，使用pandoc渲染LaTex公式，右侧包括「个人信息」、「联系博主」和「本文目录」三个模块 文章页面中，右侧的前两个模块会随着页面滚动而滚动，第三个模块「文章目录」在滚动到页面顶端后会固定，并随着文章滚动而折叠、展开三级以下目录，以便阅读 由于博客主要用于计算机学科的文档发布，设置了良好的代码块展示和阅读体验，代码块根据不同语言设置高亮显示，右上角提示该代码块的语言，点击可以一键复制代码，复制代码时博客页面右上角会显示弹窗提示，弹窗自动关闭 导航栏中的「文章」下拉菜单包含「标签」、「专栏」、「时间线」三个页面，均系根据每篇文章的tag、归档和发布时间自动生成 有情链接页面以卡片形式展示，自动检测鼠标轨迹，移动至某个卡片上时图像会自动显示阴影&amp;旋转 每篇文章和部分功能性页面带有独立的评论区，上方可以便捷地添加“反应”，下方评论通过github账户登陆，支持浏览器的cookie识别登陆，支持markdown语法，尤其是对代码块的支持较为良好 全局配置暗黑模式，夜间访问自动切换，可以在导航栏或右键菜单中切换 此外，全局还配置了自定义的鼠标样式和右键唤醒菜单，在不同的部分单击右键会有不同的功能选择，可进入博客自行尝试。 局域网文件分发系统 作品来源：2021-2022春季学期计算机网络程序设计课程结课作业 个人作业，全部内容由我独立完成 基于Java DUI开发的局域网文件分发系统，采用UDP协议封装，文件发送者可选择一个或多个目标发送文件，带有自动的失败重传机制（3次）。 视频演示 Your browser does not support the video tag. 流程图 代码部分 本部分较长，可通过右侧「本文目录」栏跳过 MainActivity 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.io.File;import java.net.DatagramSocket;import java.net.InetAddress;import java.net.MulticastSocket;import java.util.HashMap;import java.util.Vector;// -- main函数 --public class MainActivity &#123; public static int MAX_PER_SLICE = 2048; // 分片文件最大长度 public static int NUM_OF_LINES = 5; // 发送线程数 static public int groupPort; // 组播端口 static public InetAddress groupInetAddress; // 组播地址 static public MulticastSocket multicastSocket; // 组播接口 static public DatagramSocket datagramSocket; // 单播接口 static public String nickname; // 用户名 static public Vector&lt;String&gt; onlineList; // 在线用户列表 static public HashMap&lt;String, User&gt; userMap; // 昵称-用户映射 &lt;username-User&gt; static public HashMap&lt;String, File&gt; sendFileMap; // 文件名-发送文件映射 &lt;filename-SendFile&gt; static public HashMap&lt;String, ReceiveSpace&gt; receiveFileMap; // 文件名-接收文件映射 &lt;filename-ReceiveFile&gt; public static void initList() &#123; onlineList = new Vector&lt;&gt;(); userMap = new HashMap&lt;&gt;(); receiveFileMap = new HashMap&lt;&gt;(); sendFileMap = new HashMap&lt;&gt;(); &#125; public static void main(String[] args) &#123; try &#123; groupPort = 12345; // 组播端口8090 groupInetAddress = InetAddress.getByName(&quot;224.5.6.7&quot;); // 设置组播地址 multicastSocket = new MulticastSocket(groupPort); // 创建组播接口 multicastSocket.joinGroup(groupInetAddress); // 加入组播组 datagramSocket = new DatagramSocket(); // 创建单播接口 initList(); // 初始化列表 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; SetInfoGUI setInfoGUI = new SetInfoGUI(); // 创建SetInfoGUI界面 setInfoGUI.start(); // 进入信息设置界面 &#125;&#125; MeetingGUI 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211import javax.swing.*;import java.awt.*;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;import java.awt.event.WindowEvent;import java.awt.event.WindowListener;import java.io.File;import java.net.DatagramPacket;import java.net.InetAddress;import java.util.List;// -- 主要操作界面 --// 可以进行在线用户显示、文件发送等操作public class MeetingGUI &#123; void start() &#123; // 告知其他用户有新用户上线 try &#123; String onlineMsg = &quot;online;&quot; // 头信息&quot;online&quot;-有新用户上线 + MainActivity.nickname + &quot;;&quot; + &quot;127.0.0.1&quot; + &quot;;&quot; + MainActivity.datagramSocket.getLocalPort(); DatagramPacket onlinePkt = new DatagramPacket(onlineMsg.getBytes(), onlineMsg.getBytes().length, MainActivity.groupInetAddress, MainActivity.groupPort); MainActivity.multicastSocket.send(onlinePkt); // 发送组播 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; // ---- 界面布局 ---- // 创建窗口 JFrame meetingWindow = new JFrame(&quot;疼迅文件传输会议&quot;); meetingWindow.setLayout(null); // 不使用局部管理器 meetingWindow.setSize(1330, 640); // 腾讯会议实测宽高 meetingWindow.setLocationRelativeTo(null); // GUI界面居中 meetingWindow.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); // 设置同步开关-关闭窗口时终止程序 // 静态文本-本地用户昵称 JLabel nickname = new JLabel(&quot;current user: &quot; + MainActivity.nickname); nickname.setBounds(10, 5, 200, 20); nickname.setOpaque(true); // 关闭背景透明 nickname.setBackground(Color.BLACK); // 标签背景色设置为黑色 nickname.setForeground(Color.WHITE); // 文字颜色设置为白色 meetingWindow.add(nickname); // 加入窗口 // 在线用户列表及表头 JList&lt;String&gt; onlineUserList = new JList();// JLabel onlineUserListTitle = new JLabel(&quot;参会成员&quot;);// onlineUserList.setBorder(BorderFactory.createLineBorder(Color.DARK_GRAY,3,true)); onlineUserList.setBorder(BorderFactory.createTitledBorder(&quot;其他参会成员&quot;)); // 设置带表头带边框 onlineUserList.setBounds(970, 10, 350, 590); // 设置位置和宽高// onlineUserListTitle.setBounds(980, 20, 40,15); onlineUserList.setSelectionMode(ListSelectionModel.MULTIPLE_INTERVAL_SELECTION); // 可选一条或连续多条 onlineUserList.setBackground(Color.LIGHT_GRAY); // 亮灰色背景，与信息框加以区分 meetingWindow.add(onlineUserList); // 加入窗口// meetingWindow.add(onlineUserListTitle); // 文件传输信息框 JTextArea msgArea = new JTextArea(); // 创建文本区 msgArea.setEditable(false); // 不可编辑 JScrollPane msgScrollPane = new JScrollPane(msgArea); // 在文本区创建滚动面板 msgScrollPane.setBorder(BorderFactory.createTitledBorder(&quot;信息&quot;)); // 设置带表头边框 msgScrollPane.setBounds(10, 30, 960, 480); // y和width与在线用户列表保持一致 meetingWindow.add(msgScrollPane); // 加入窗口 // 文件路径框 // &quot;选择文件&quot;和&quot;发送文件&quot;之间，通过路径filePath传递文件，而不需要暂存文件本身 // 因此直接编辑文件路径也可以实现发送 JTextField pathField = new JTextField(&quot; 请选择文件...&quot;); // 默认提示信息 pathField.setForeground(Color.LIGHT_GRAY); // 文件路径亮灰色 pathField.setBounds(10, 520, 840, 30); pathField.setBorder(BorderFactory.createLineBorder(Color.GRAY, 4, true)); meetingWindow.add(pathField); // 加入窗口 // 按钮-选择文件 JButton selectFileBtn = new JButton(&quot;选择文件...&quot;); selectFileBtn.setBounds(855, 515, 110, 40); meetingWindow.add(selectFileBtn); // 加入窗口 // 按钮-选择文件-监听事件 selectFileBtn.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; JFileChooser localFileChooser = new JFileChooser(); // 创建文件选择框 localFileChooser.showOpenDialog(null); // 在屏幕中央弹出窗口 pathField.setText(localFileChooser.getSelectedFile().getAbsolutePath()); // 根据选择设置文件路径 &#125; &#125;); // 按钮-发送文件 JButton sendFileBtn = new JButton(&quot;发送文件&quot;); sendFileBtn.setBounds(350, 555, 200, 50); sendFileBtn.setBorder(BorderFactory.createLineBorder(Color.RED, 2, true)); meetingWindow.add(sendFileBtn); // 加入窗口 // 按钮-发送文件-监听事件 sendFileBtn.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; List&lt;String&gt; targetUserList = onlineUserList.getSelectedValuesList(); // 获取目标用户 String filePath = pathField.getText(); // 获取文件路径 File file = new File(filePath); // 根据路径获取文件 MainActivity.sendFileMap.put(file.getName(), file); // 存入发送文件列表 try &#123; // 遍历targetUserList中的每一个用户，依次发送文件 // 对某个用户，先发送请求信息，再多线程发送文件 for (String s : targetUserList) &#123; User targetUser = MainActivity.userMap.get(s); // 根据昵称获取用户实例 InetAddress inetAddress = InetAddress.getByName(targetUser.getIP()); // 获取用户地址 String requestMsg = &quot;request;&quot; // 头信息&quot;request&quot;-请求发送文件 + MainActivity.nickname + &quot;;&quot; + file.getName() + &quot;;&quot; + file.length(); DatagramPacket requestPkt = new DatagramPacket( // 单播数据包 requestMsg.getBytes(), requestMsg.getBytes().length, inetAddress, targetUser.getPort() ); MainActivity.datagramSocket.send(requestPkt); // 发送单播 // 创建NUM_OF_LINES个线程发送文件 long slices = (file.length() / MainActivity.MAX_PER_SLICE) + 1; // 计算文件分片数 int slices_per_thread = (int) (slices / MainActivity.NUM_OF_LINES); // 每个线程需要发送的分片数 for (int i = 0; i &lt; MainActivity.NUM_OF_LINES; i++) &#123; SendThread sendThread = new SendThread(file, i, slices_per_thread, targetUser); sendThread.start(); // 开始发送线程 &#125; msgArea.append(&quot;开始发送文件: &quot; + file.getName() + &quot;\\n&quot;); &#125; &#125; catch (Exception exception) &#123; exception.printStackTrace(); &#125; &#125; &#125;); try &#123; // 创建组播接收线程 MulticastReceive multicastReceive = new MulticastReceive(onlineUserList); multicastReceive.start(); // 创建单播接收线程 for (int i = 0; i &lt; MainActivity.NUM_OF_LINES; i++) &#123; UnicastReceive unicastReceive = new UnicastReceive(onlineUserList, msgArea); unicastReceive.start(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; // 窗口-监听窗口状态 // 主要是在窗口关闭时实现自动发送offline数据包功能 meetingWindow.addWindowListener(new WindowListener() &#123; @Override public void windowOpened(WindowEvent e) &#123; &#125; @Override public void windowClosing(WindowEvent e) &#123; try &#123; String offlineMsg = &quot;offline;&quot; + MainActivity.nickname; // 信息头&quot;offline&quot;-用户下线 DatagramPacket offlinePkt = new DatagramPacket( // 组播数据包 offlineMsg.getBytes(), offlineMsg.getBytes().length, MainActivity.groupInetAddress, MainActivity.groupPort ); MainActivity.multicastSocket.send(offlinePkt); // 发送组播 &#125; catch (Exception exception) &#123; exception.printStackTrace(); &#125; System.exit(0); // 退出 &#125; @Override public void windowClosed(WindowEvent e) &#123; &#125; @Override public void windowIconified(WindowEvent e) &#123; &#125; @Override public void windowDeiconified(WindowEvent e) &#123; &#125; @Override public void windowActivated(WindowEvent e) &#123; &#125; @Override public void windowDeactivated(WindowEvent e) &#123; &#125; &#125;); meetingWindow.setVisible(true); // 显示界面 &#125;&#125; MulticastReceive 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import javax.swing.*;import java.io.IOException;import java.net.DatagramPacket;import java.net.InetAddress;// 用于接收组播信息并产生应答// 组播信息头共两种：// -- &quot;online&quot;: 新用户上线-更新自己的用户列表-把自己的信息通知新用户(单播)// -- &quot;offline&quot;: 某用户下线-更新自己的用户列表public class MulticastReceive extends Thread &#123; private JList&lt;String&gt; onlineUserList; // 在线用户列表 MulticastReceive(JList onlineUserList) &#123; this.onlineUserList = onlineUserList; &#125; @Override public void run() &#123; // 持续接收组播信息 while (true) &#123; byte[] data = new byte[MainActivity.MAX_PER_SLICE]; DatagramPacket receivePkt = new DatagramPacket(data, data.length); // 组播数据包容器 try &#123; MainActivity.multicastSocket.receive(receivePkt); // 接收组播数据包 String receiveMsg = new String(data, 0, receivePkt.getLength()); String[] multicastMsgs = receiveMsg.split(&quot;;&quot;); // 根据&#x27;;&#x27;拆分信息 switch (multicastMsgs[0]) &#123; case &quot;online&quot;: &#123; // 新用户上线 // 1. 更新自己的用户表 // 2. 把自己的信息通知新用户(单播) String newUsername = multicastMsgs[1]; // 上线用户的昵称 String newUserIP = multicastMsgs[2]; // 上线用户的IP int newUserPort = Integer.parseInt(multicastMsgs[3]); // 上线用户的端口号 if (!newUsername.equals(MainActivity.nickname) &amp;&amp; MainActivity.userMap.get(newUsername) == null) &#123; // 验证用户名未重复// User newUser = new User(newUsername, newUserIP, newUserPort); // 为新用户创建User对象 MainActivity.onlineList.add(newUsername); // 加入在线用户列表// MainActivity.userMap.put(newUsername, newUser); // 加入&lt;昵称-用户&gt;映射 MainActivity.userMap.put(newUsername, // 加入&lt;昵称-用户&gt;映射 new User(newUsername, newUserIP, newUserPort)); onlineUserList.setListData(MainActivity.onlineList); // 更新在线用户列表 &#125; String replayNewUserMsg = &quot;newUser;&quot; + MainActivity.nickname + &quot;;&quot; // 把自己的信息通知给其他用户 + &quot;127.0.0.1&quot; + &quot;;&quot; + MainActivity.datagramSocket.getLocalPort(); // 单播数据包 DatagramPacket replayNewUserPkt = new DatagramPacket( replayNewUserMsg.getBytes(), replayNewUserMsg.getBytes().length, InetAddress.getByName(newUserIP), newUserPort); MainActivity.datagramSocket.send(replayNewUserPkt); // 发送单播 break; &#125; case &quot;offline&quot;: &#123; // 某用户下线 // 1. 更新自己的用户表 String leaveUsername = multicastMsgs[1]; // 下线的用户名 if (MainActivity.userMap.get(leaveUsername) != null) &#123; // 验证该用户本来在线 MainActivity.onlineList.remove(leaveUsername); MainActivity.userMap.remove(leaveUsername); onlineUserList.setListData(MainActivity.onlineList); &#125; break; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; ReceiveSpace 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import java.io.File;// -- 接收到的文件信息 --/*#########################考试科目：计算机网络程序设计姓名：庞宇轩学号：2019302110354班级：2019广播电视工程2班######################### */public class ReceiveSpace &#123; private String fileName; // 待接收的文件名 private int fileSize; // 待接收的文件大小 private File file; // 接收到的文件 private int resend; // 重传次数 public ReceiveSpace(String fileName, int fileSize, File file) &#123; this.fileName = fileName; this.fileSize = fileSize; this.file = file; this.resend = 0; &#125; public String getFileName() &#123; return fileName; &#125; public void setFileName(String fileName) &#123; this.fileName = fileName; &#125; public int getFileSize() &#123; return fileSize; &#125; public void setFileSize(int fileSize) &#123; this.fileSize = fileSize; &#125; public File getFile() &#123; return file; &#125; public void setFile(File file) &#123; this.file = file; &#125; public int getResend() &#123; return resend; &#125; public void setResend(int resend) &#123; this.resend = resend; &#125;&#125; SendThread 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106import java.io.File;import java.io.IOException;import java.io.RandomAccessFile;import java.net.DatagramPacket;import java.net.InetAddress;import java.nio.charset.StandardCharsets;// 发送线程// 发送文件数据data和结束提示overpublic class SendThread extends Thread &#123; private final String fileName; // 发送的文件名 private final int threadOrder; // 线程创建顺序-从0到(NUM_OF_LINES-1) private final int num_of_slices; // 需要发送的分片数 private final User targetUser; // 目标用户 private final RandomAccessFile randomAccessFile; // 发送文件对象 byte[] buffer = new byte[MainActivity.MAX_PER_SLICE]; // 字节流容器-长度为最大分片长度 public SendThread(File file, int threadOrder, int num_of_slices, User targetUser) throws IOException &#123; this.fileName = file.getName(); this.threadOrder = threadOrder; this.num_of_slices = num_of_slices; this.targetUser = targetUser; randomAccessFile = new RandomAccessFile(file, &quot;rw&quot;); randomAccessFile.seek(threadOrder * num_of_slices * 2048L); &#125; @Override public void run() &#123; try &#123; InetAddress inetAddress = InetAddress.getByName(targetUser.getIP()); long offset = randomAccessFile.getFilePointer(); // 偏移量 // 判断当前线程是不是第NUM_OF_LINES个线程 if (this.threadOrder != MainActivity.NUM_OF_LINES - 1) &#123; for (int i = 0; i &lt; num_of_slices; i++) &#123; int MAX_WAIT_TIMES = 50000; while (!targetUser.isUserCondition() &amp;&amp; MAX_WAIT_TIMES &gt; 0) &#123; // 等待接收端准备接收文件 Thread.sleep(10); MAX_WAIT_TIMES --; // 防止卡死 &#125; randomAccessFile.readFully(buffer); // 不是最后一个线程-直接全读完 String content = new String(buffer, StandardCharsets.ISO_8859_1); String dataMsg = &quot;data;&quot; // 信息头&quot;data&quot;-传输实际文件数据 + MainActivity.nickname + &quot;;&quot; + fileName + &quot;;&quot; + offset + &quot;;&quot; + content; DatagramPacket dataPkt = new DatagramPacket( // 单播数据包 dataMsg.getBytes(), dataMsg.getBytes().length, inetAddress, targetUser.getPort() ); MainActivity.datagramSocket.send(dataPkt); // 发送单播 offset = randomAccessFile.getFilePointer(); // 更新offset targetUser.setUserCondition(false); // 文件发送后需要重新等待对方准备好 &#125; &#125; else &#123; int len = randomAccessFile.read(buffer); // 当前是最后一个线程，需要一点点读 while (len != -1) &#123; int MAX_WAIT_TIMES = 50000; while (!targetUser.isUserCondition() &amp;&amp; MAX_WAIT_TIMES &gt; 0) &#123; Thread.sleep(10); MAX_WAIT_TIMES --; &#125; String content = new String(buffer, 0, len, StandardCharsets.ISO_8859_1); String dataMsg = &quot;data;&quot; + MainActivity.nickname + &quot;;&quot; + fileName + &quot;;&quot; + offset + &quot;;&quot; + content; DatagramPacket dataPkt = new DatagramPacket( // 单播数据包 dataMsg.getBytes(), dataMsg.getBytes().length, inetAddress, targetUser.getPort() ); MainActivity.datagramSocket.send(dataPkt); // 发送单播 offset = randomAccessFile.getFilePointer(); // 更新偏移量 len = randomAccessFile.read(buffer); // 更新len值继续读取 targetUser.setUserCondition(false); // 更新用户准备状态 &#125; String overMsg = &quot;over;&quot; // 信息头&quot;over&quot;-表示发送结束 + MainActivity.nickname + &quot;;&quot; + fileName + &quot;;&quot;; DatagramPacket over_packet = new DatagramPacket( // 单播数据包 overMsg.getBytes(), overMsg.getBytes().length, inetAddress, targetUser.getPort() ); MainActivity.datagramSocket.send(over_packet); // 发送单播 &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; SetInfoGUI 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import javax.swing.*;import java.awt.*;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;import java.io.File;import java.io.FileInputStream;import java.io.InputStream;// -- 进入会议前的信息确认界面 --// 在此输入用户的会议昵称public class SetInfoGUI &#123; void start() &#123; // 创建窗口 JFrame setInfoWindow = new JFrame(); setInfoWindow.setTitle(&quot;Enter&quot;); // 窗口标题设为&quot;加入会议&quot; setInfoWindow.setSize(375, 667); // 实测腾讯会议&quot;加入会议&quot;宽高 setInfoWindow.setLocationRelativeTo(null); // GUI界面居中// setInfoWindow.setLocation(535,120); // 实测腾讯会议&quot;加入会议&quot;位置 // 设置Logo String path = &quot;/Users/pangyuxuan/Desktop/JavaWebFinal/src/img/icon.jpg&quot;; File imgFile = new File(path); InputStream inputImg = null; byte b[] = new byte[(int) imgFile.length()]; try &#123; inputImg = new FileInputStream(imgFile); inputImg.read(b); inputImg.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; Icon icon = new ImageIcon(b); JLabel staticImg = new JLabel(icon, JLabel.CENTER); // 创建标签-储存静态图像 staticImg.setBounds(138,20,100,100); setInfoWindow.add(staticImg); // 静态文本1 JLabel staticText1 = new JLabel(&quot;疼迅文件传输会议&quot;, JLabel.CENTER); staticText1.setBounds(30,100,315,20); setInfoWindow.add(staticText1); // 将静态文本添加至窗口 // 静态文本2 JLabel staticText2 = new JLabel(&quot;开发者: 庞宇轩 2019302110354&quot;, JLabel.CENTER); staticText2.setBounds(30,125,315,20); setInfoWindow.add(staticText2); // 将静态文本添加至窗口 // 静态文本-昵称 JLabel staticText3 = new JLabel(&quot;昵称&quot;); // 创建标签-储存静态文本 staticText3.setBounds(30,200,40,20); setInfoWindow.add(staticText3); // 将静态文本添加至窗口 // 输入框 JTextField inputText = new JTextField(&quot; 输入您的昵称...&quot;); // 创建文本输入框 inputText.setForeground(Color.LIGHT_GRAY); // 设置字体颜色为灰色 inputText.setBounds(28, 222, 319, 45); inputText.setBorder(BorderFactory.createLineBorder(Color.GRAY, 2, true)); // 设置边框 setInfoWindow.add(inputText); // 将输入框添加至窗口 // 按钮-加入会议 JButton enterMeetingBtn = new JButton(&quot;加入会议&quot;); enterMeetingBtn.setBounds(28, 300, 319, 45); setInfoWindow.add(enterMeetingBtn); // 按钮-加入会议-监听事件 enterMeetingBtn.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; setInfoWindow.setVisible(false); MainActivity.nickname = inputText.getText().trim(); // 获取用户昵称(删除首尾空格) MeetingGUI meetingGUI = new MeetingGUI(); meetingGUI.start(); &#125; &#125;); setInfoWindow.setLayout(null); // 不使用局部管理器 setInfoWindow.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); // 设置同步开关-关闭窗口时终止程序 setInfoWindow.setVisible(true); // 设置窗体可见 &#125;&#125; UnicastReceive 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229import javax.swing.*;import java.io.File;import java.io.IOException;import java.io.RandomAccessFile;import java.net.DatagramPacket;import java.net.InetAddress;import java.nio.charset.StandardCharsets;// 用于接收单播信息并产生应答// 单播信息头有种:// -- &quot;ready&quot;: 表明发送单播的用户已经准备好接收文件-更新该用户的状态// -- &quot;newUser&quot;: 本机上线后发送组播通知，收到回复-将回复的用户加入本机用户列表// -- &quot;request&quot;: 有其他用户向本机请求发送文件-本机根据对方用户名创建文件路径和接收容器// -- &quot;data&quot;: 收到实际文件数据-重新拆分文件-储存文件-更新准备状态(单播)// -- &quot;over&quot;: 文件传输结束-判断文件是否正确接收-进行相应回复(单播)-接收成功/请求重传/接收失败// -- &quot;success&quot;: 本机发送文件，目标用户接收成功-更新本机信息显示框// -- &quot;fail&quot;: 本机发送文件，目标用户接收失败-更新本机信息显示框// -- &quot;resend&quot;: 收到文件重传请求，仿造MeetingGUI中初次发送文件的流程操作public class UnicastReceive extends Thread &#123; private JList&lt;String&gt; onlineUserList; // 在线用户列表 private JTextArea msgArea; // 信息显示框 private int MAX_RESEND_TIME = 5; // 最大重传尝试次数 UnicastReceive(JList onlineUserList, JTextArea msgArea) &#123; this.onlineUserList = onlineUserList; // 传入MeetingGUI在线用户列表 this.msgArea = msgArea; // 传入MeetingGUI信息提示框 &#125; @Override public void run() &#123; while (true) &#123; byte[] data = new byte[4096]; DatagramPacket receivePkt = new DatagramPacket(data, data.length); try &#123; MainActivity.datagramSocket.receive(receivePkt); // 接收单播数据包 String receiveMsg = new String(data, 0, receivePkt.getLength()); String unicastMsgs[] = receiveMsg.split(&quot;;&quot;); // 根据&#x27;;&#x27;拆分信息 switch (unicastMsgs[0]) &#123; case &quot;ready&quot;: &#123; // 表明发送单播的用户已经准备好接收文件 // 更新该用户的准备状态 MainActivity.userMap.get(unicastMsgs[1]).setUserCondition(true); break; &#125; case &quot;newUser&quot;: &#123; // 本机上线后发送组播通知，收到回复 // 将回复的用户信息更新至用户列表 String replyUsername = unicastMsgs[1]; // 回复信息的用户名 String replyUserIP = unicastMsgs[2]; // 回复信息的用户IP int replyUserPort = Integer.parseInt(unicastMsgs[3]); // 回复信息的用户端口 if (!replyUsername.equals(MainActivity.nickname) &amp;&amp; MainActivity.userMap.get(replyUsername) == null) &#123; User user = new User(replyUsername, replyUserIP, replyUserPort); MainActivity.onlineList.add(replyUsername); onlineUserList.setListData(MainActivity.onlineList); MainActivity.userMap.put(replyUsername, user); &#125; break; &#125; case &quot;request&quot;: &#123; // 有其他用户向本机请求发送文件 // 本机根据对方用户名创建文件路径和接收容器 String fileSourceUsername = unicastMsgs[1]; // 文件来源用户名 String fileName = unicastMsgs[2]; // 文件名 int fileSize = Integer.parseInt(unicastMsgs[3]); // 文件大小 File file = new File(&quot;./file_from_&quot; + fileSourceUsername + &quot;/&quot; + fileName); if (!file.exists()) &#123; // 文件路径不存在则创建 file.getParentFile().mkdirs(); &#125; MainActivity.receiveFileMap.put(fileName, new ReceiveSpace(fileName, fileSize, file)); // 加入&lt;文件名, 接收文件&gt;映射 break; &#125; case &quot;data&quot;: &#123; // 收到实际文件数据 // 重新拆分文件(因为;可能在实际文件数据中存在) // 按位置储存文件 // 储存结束后重新进入准备接受状态(回复单播) String[] dataUnicastMsgs = receiveMsg.split(&quot;;&quot;, 5); String fileSourceUsername = dataUnicastMsgs[1]; String fileName = dataUnicastMsgs[2]; // 文件名// int offset = Integer.parseInt(dataUnicastMsgs[3]); long offset = Long.parseLong(dataUnicastMsgs[3]); // 文件长度 String fileData = dataUnicastMsgs[4]; // 实际文件数据 ReceiveSpace receiveSpace = MainActivity.receiveFileMap.get(fileName); // 从接收文件映射中取出 RandomAccessFile randomAccessFile = null; // 接收文件容器 randomAccessFile = new RandomAccessFile(receiveSpace.getFile(), &quot;rw&quot;); randomAccessFile.seek(offset); // 定位到offset randomAccessFile.write(fileData.getBytes(StandardCharsets.ISO_8859_1)); // 写入数据 randomAccessFile.close(); // 关闭文件 User fileSourceUser = MainActivity.userMap.get(fileSourceUsername); // 根据用户名找到对象 InetAddress inetAddress = InetAddress.getByName(fileSourceUser.getIP()); String ready_message = &quot;ready;&quot; + MainActivity.nickname; // 单播数据包-&quot;ready&quot;信息头 DatagramPacket user_packet = new DatagramPacket( ready_message.getBytes(), ready_message.getBytes().length, inetAddress, fileSourceUser.getPort() ); MainActivity.datagramSocket.send(user_packet); // 发送单播回复-更新准备状态 break; &#125; case &quot;over&quot;: &#123; // 表示文件传输结束 // 判断文件是否接收成功: // -- 若成功则回复单播，信息头&quot;success&quot; // -- 若失败则尝试重传： // -- 若重传未到次数限制则回复单播，信息头&quot;resend&quot; // -- 若重传已到次数限制则回复单播，信息头&quot;fail&quot; String fileSourceUsername = unicastMsgs[1]; String fileName = unicastMsgs[2]; User fileSourceUser = MainActivity.userMap.get(fileSourceUsername); // 通过用户映射获取文件来源用户 ReceiveSpace receiveSpace = MainActivity.receiveFileMap.get(fileName); // 通过接收文件映射获取接收文件 InetAddress inetAddress = InetAddress.getByName(fileSourceUser.getIP()); // 判断接收文件的长度和应有长度是否一致 // 实际收到的文件长度=receiveSpace.getFile().length() // 提前读取的文件长度(应有长度)=receiveSpace.getFileSize() if (receiveSpace.getFile().length() == receiveSpace.getFileSize()) &#123; // 接收成功 msgArea.append(&quot;成功接收文件: &quot; + fileName + &quot;, 重传尝试次数: &quot; + receiveSpace.getResend() + &quot;, 文件长度: &quot; + receiveSpace.getFileSize() + &quot;\\n&quot; ); // 成功接收文件: filename, 重传尝试次数: x, 文件长度: len \\n String successMsg = &quot;success;&quot; + MainActivity.nickname + &quot;;&quot; + fileName; DatagramPacket successPkt = new DatagramPacket( // 单播数据包 successMsg.getBytes(), successMsg.getBytes().length, inetAddress, fileSourceUser.getPort() ); MainActivity.datagramSocket.send(successPkt); // 发送单播 &#125; // 若接收失败则尝试重传 else if (receiveSpace.getResend() &lt; MAX_RESEND_TIME) &#123; // 重传次数小于MAX_RESEND_TIME // 请求重传，信息头&quot;resend&quot; msgArea.append(&quot;文件: &quot; + fileName + &quot; 第 &quot; + receiveSpace.getResend()+1 + &quot; 次接收失败，已申请重传\\n&quot;); // 文件: filename 第 y 次接收失败，已申请重传 receiveSpace.setResend(receiveSpace.getResend()+1); // 更新重传次数 String resendMsg = &quot;resend;&quot; + MainActivity.nickname + &quot;;&quot; + fileName; DatagramPacket resendPkt = new DatagramPacket( // 单播数据包 resendMsg.getBytes(), resendMsg.getBytes().length, inetAddress, fileSourceUser.getPort() ); MainActivity.datagramSocket.send(resendPkt); // 发送单播 &#125; else &#123; // 超过重传次数，通知文件发送失败 msgArea.append(&quot;文件: &quot; + fileName + &quot; 接收失败\\n&quot;); String failMsg = &quot;fail;&quot; + MainActivity.nickname + &quot;;&quot; + fileName; DatagramPacket failPkt = new DatagramPacket( // 单播数据包 failMsg.getBytes(), failMsg.getBytes().length, inetAddress, fileSourceUser.getPort() ); MainActivity.datagramSocket.send(failPkt); // 发送单播 &#125; break; &#125; case &quot;success&quot;: &#123; // 本机发送的文件被目标用户接收成功 // 更新信息显示框 msgArea.append(unicastMsgs[1] + &quot;已发送，目标用户: &quot; + unicastMsgs[2] + &quot; 接收【成功】\\n&quot;); break; &#125; case &quot;fail&quot;: &#123; // 本机发送的文件被目标用户接收失败 // 更新信息显示框 msgArea.append(unicastMsgs[1] + &quot;已发送，目标用户: &quot; + unicastMsgs[2] + &quot; 接收【失败】\\n&quot;); break; &#125; case &quot;resend&quot;: &#123; // 本机发送文件，目标用户接收失败，请求重传 msgArea.append(&quot;收到用户 &quot; + unicastMsgs[1] + &quot; 的重传请求，重新发送文件 &quot; + unicastMsgs[2] + &quot;\\n&quot;); File file = MainActivity.sendFileMap.get(unicastMsgs[2]); // 与MeetingGUI中点击&quot;发送&quot;按钮触发的流程一致 User targetUser = MainActivity.userMap.get(unicastMsgs[1]); // 获取目标用户 InetAddress inetAddress = InetAddress.getByName(targetUser.getIP()); // 获取用户地址 String requestMsg = &quot;request;&quot; // 单播信息头&quot;request&quot;-请求发送文件 + MainActivity.nickname + &quot;;&quot; + file.getName() + &quot;;&quot; + file.length(); DatagramPacket requestPkt = new DatagramPacket( // 单播数据包 requestMsg.getBytes(), requestMsg.getBytes().length, inetAddress, targetUser.getPort() ); MainActivity.datagramSocket.send(requestPkt); // 发送单播 long slices = (file.length() / MainActivity.MAX_PER_SLICE) + 1; // 计算文件分片数 int slices_per_thread = (int) (slices / MainActivity.NUM_OF_LINES); // 每个线程需要发送的分片数 for (int i = 0; i &lt; MainActivity.NUM_OF_LINES; i++) &#123; SendThread sendThread = new SendThread(file, i, slices_per_thread, targetUser); sendThread.start(); // 开始发送线程 &#125; break; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; User 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// 用户类public class User &#123; private String nickname; // 用户名 private String IP; // 用户IP地址 private int port; // 用户端口号 private boolean userCondition; // 是否准备接收文件 // 构造函数 public User(String nickname, String IP, int port) &#123; this.nickname = nickname; this.IP = IP; this.port = port; this.userCondition = true; // 初始默认为准备接收文件数据 &#125; public String getNickname() &#123; return nickname; &#125; public void setNickname(String nickname) &#123; this.nickname = nickname; &#125; public String getIP() &#123; return IP; &#125; public void setIP(String IP) &#123; this.IP = IP; &#125; public int getPort() &#123; return port; &#125; public void setPort(int port) &#123; this.port = port; &#125; public void setUserCondition(boolean userCondition) &#123; this.userCondition = userCondition; &#125; public boolean isUserCondition() &#123; return userCondition; &#125;&#125; 资讯类APP 作品来源：2021-2022春季学期Java编程与移动媒体实践结课作业 小组作业，我负责其中的Uni-App前端研发工作 视频讲解为其他组员制作，因而声音和操作系统与上一个视频（本人自己录制）不一致 后端采用SpringBoot框架，用Spring security做了JWT鉴权和完整的接口权限控制，使用RESTful规范接口； 前端采用Vue框架，对页面进行丰富和美化，在实现基础功能的同时增加了HTML浏览器模式阅读方式； 实现多用户登陆模块、内容浏览模块、内容交互模块、用户日志模块，支持HTML浏览器模式阅读； 视频演示 Your browser does not support the video tag. 代码量较大，因而在此不一一展示细节，工程文件下载请点击下载链接 调研报告（数据可视化作品） 作品来源：中国传媒大学暑期实践报告评审三等奖作品《补缀泛黄相纸 追寻峥嵘往昔》 小组作业，本人为组长，报告中的数据可视化部分系本人独立完成 老照片是某个人或某段时期的影像记录，相比文字而言，具有更加直观、更加形象、更加生动的特点，每一张老照片都是一段宝贵历史的载体：它是社会变迁的线索，体现不同时代人民群众的生活场景和历史细节；它是民族情感的载体，是爱乡爱国的根基。即使在今天，照片依旧发挥着重要的作用，而老照片的保存与修复也逐渐成为热议话题。由此，我们设计了本次问卷，探索分析老照片的持有量及当代大学生对老照片保存现状的认知。 感谢观看，我的简历pyxblog.cn/resume，希望能得到宝贵的面试机会！ 如有任何疑问或指导，简历中有我的联系方式～"},{"title":"贲圣林老师博士生申请信息登记","date":"2022-09-04T10:20:11.282Z","updated":"2022-09-04T10:20:11.268Z","comments":true,"path":"zibs-apply/index.html","permalink":"https://pyxblog.cn/zibs-apply/index.html","excerpt":"","text":"基本信息 姓名：庞宇轩出生年月：2000.11出生籍贯：山东青岛性别：男政治面貌：中共党员学历：本科（2023年毕业）最高学历毕业院校及专业：中国传媒大学-信息与通信工程学院-广播电视工程ps. 211院校-国家特色专业 个人简历 点击查看个人简历 获奖材料 点击查看获奖材料 研究能力 研究领域 研究领域：根据您对贲教授的了解，您未来希望主攻的研究领域是什么？ 由于我的计算机背景和创业意愿，结合贲教授的研究方向，我希望在未来主攻能运用较多计算机技能的创业金融领域研究，或从事数据科学相关的研究工作。 科研经历 科研经历：由于数字金融（金融科技）是贲教授最核心的研究方向，请简要介绍下您之前参与过的与数字经济、数字金融、金融科技相关的科研论文或项目经历，若是论文请说明论文题目、发表期刊和时间；若是项目请说明您在其中的角色、工作任务、结果；若论文和项目均有，请分别列出。 我暂未参加过以数字金融为主题的相关科研论文或项目，但我负责的“互联网+”创新创业大赛项目涉及到了一定的金融知识；此外，我也具备一定的爬虫、数据可视化实现能力。 我负责的项目和相关的能力在后文中有较为详细的体现。 论文&amp;项目 介绍下曾有过的论文写作或者项目难点以及解决方案。 [项目1] 历史影像修复 项目发起自2021年4月，以三重态域翻译网络和超分重建算法为核心算法，面向B端用户（档案馆、党史馆等文博机构）开展“AI+人工”影像精修服务，我为该项目的全程负责人。 Your browser does not support the video tag. 随着互联网技术的发展和党史教育的普及，全国各地文博机构（档案馆、博物馆等）的馆藏数字化工作陆续开展，数字存储和线上展览对历史影像的质量提出了更高的要求。 现有的人工修复耗时长、效率低；划痕修复算法多为弱监督算法，难以应对高分辨率场景，而历史照片经高清扫描仪数字化后往往分辨率较高。 本项目依托中国传媒大学媒体融合与传播国家重点实验室，结合三域转换翻译网络和超分辨率重建网络，对历史影像进行分辨率的压缩和重建，解决高分辨率场景下的扫描历史影像修复问题。 我们组建了大学生创新创业团队，申报大创项目，参与“互联网+”、“创青春”等创新创业大赛，将学术成果转化为商业价值，现已申请专利7项，软件著作权6项，与北京市朝阳区档案馆、南通市城市建设档案馆等文博机构开展了十数个公益性合作项目，初步取得了行业认可。 后文为具体的产品前后端设计细节，如需跳过请点击跳过 产品设计与实现 拾忆是基于AI模型的老旧影像解决方案，在可以提供随时随地、任意设备访问的同时，还需要确保模型端、应用程序的稳定性、可拓展性以及安全性。基于此，我们做了前端基于Uni-App，后端响应核心基于Spring Cloud，模型运算接口基于Flask的多集群负载均衡的技术选型。 前端设计 我们在前端架构层面致力于实现： 优质的用户交互逻辑，最大化降低操作难度，提升使用欲望； 明晰的媒体展示能力，用户可直观感受修复效果，并根据需求实现基础的二次编辑（裁剪、添加滤镜等）； 设计语言统一，符合大众审美直觉，提升自身品牌辨识度。 基于此，我们做了模块化的前端设计，界面以黑白紫为主色调，按钮及模块均进行圆角化处理，设计语言统一。弹出窗口及操作界面背景均使用磨砂风格，符合大众审美直觉。设计中使用大量图形语言，风格统一，操作含义明晰，为用户操作提供直观指引。 后端架构 我们在后端架构层面致力于实现： 拥有用户鉴权模块及权限组系统，可实现统一管理及调整； 拥有快速扩容能力，基于微服务集群思想，实现分钟级快速扩容； 拥有高并发访问潜力，实现多级缓存，服务集群负载均衡； 拥有数据灾备能力，实现数据库主从热备，主主互备。 基于此，我们做了如下技术构型，下图展示典型部署（站点）中的核心组件及其组成结构： 用户服务及功能服务集群 用户服务及功能服务集群（称为“用户集群”）是拾忆站点的中心管理组件，为实现站点可靠性和可用性，用户集群应安装在多个服务器上。用户集群将与客户端通信实现用户请求的分发，包括用户鉴权，用户请求，数据储存，资源调配。用户上传到云端的媒体资源及处理后的影音文件将储存在 OSS 对象储存中，以实现全球高速数据分发。 数据库 为实现多地负载均衡，用户集群至少需要三个高性能 MySQL 数据库，用于动态数据和会话信息储存及灾备，核心数据库应与用户集群建立持续性链接。站点还使用一个配置数据库和一个日志数据库，默认情况下无需处理高强度请求。所有的数据库链路均加入 Redis 缓存，并进行读写分离操作以实现高并发场景下的稳定应用。 模型运算集群 鉴于修复模型由 Pytorch 训练，尚无法实现模型导出，故在选型中考虑使用基于 Python 的 Flask 框架提供模型运算集群的 Restful API 响应服务。同时模型运算实例成本较高，为降低整体运行成本，引入基于 Eureka 的微服务管理框架实现集群的统一管理，将模型运算实例打包至 Docker，根据用户请求量进行动态拓展。用户请求到达站点后将先由用户集群按任务优先级加入请求队列，获取空闲模型运算实例地址后通过 API 提交媒体资源及修复请求。若队列内请求积压过多用户集群将自动发起扩容流程。 其余性能优化 鉴于老照片修复本身存在出现社交爆点的可能性，拾忆 App 服务可能面临短时间并发量陡增的场景。为实现服务的高可用，请求链路中配置了 Spring Cloud Gateway 作为微服务网关，搭配 Ribbon 框架实现全局负载均衡，将根据用户地域、画像、来源等分配至不同的用户集群处理请求，降低单一集群请求压力。同时，为避免某段时间请求陡增导致部分节点宕机从而影响全局服务稳定性，服务端使用 Hystrix 框架实现熔断机制，当节点请求错误率上升达到阀值，将暂时隔离该节点进而保证用户体验。 所获荣誉 2021.04 2021年大学生创新创业训练计划国家级立项 2021.07 第七届中国国际“互联网+”大学生创新创业大赛北京市一等奖 2021.10 第四届“京津冀-粤港澳”青年创新创业大赛京津冀赛区决赛二等奖，入围全国总决赛（因疫情延期） 2021.11 第七届中国国际“互联网+”大学生创新创业大赛全国铜奖，创造我校参赛以来最高获奖记录 2022.04 2021年大学生创新创业训练计划，获得优秀结项，并被我校唯一推荐至2022大创年会 2022.04 2022年大学生创新创业训练计划国家级立项 2022.05 首届“京彩大创”北京大学生创新创业竞赛“百粒‘金种子’项目（2022）”、文化创意赛道决赛三等奖 2022.07 第八届中国国际“互联网+”大学生创新创业大赛北京市一等奖，再次入围全国总决赛 2022.08 第九届“创青春”中国青年创新创业大赛全国铜奖，创造我校历史新高 2022.08 大创项目入选第十五届全国大学生创新创业年会改革成果项目 2022.08 论文Real historical video restoration based on deep learning 投稿至EI源刊IJCSE，一作 [项目2] 菜品识别 项目发起自2021年4月，团队成员拍摄、清洗、标注中国传媒大学菜品数据集（含照片40,000+），投入YOLOV3、Faster R-CNN等五种经典目标检测算法做对比实验，得出表现最佳的Faster R-CNN（准确率达98.6%），并基于此搭建智慧餐厅云平台系统实现菜品识别系统。 我的贡献 在本项目中，我作为主要技术人员（项目成员），承担的工作包括： 算法：RCNN、Fast RCNN及Faster RCNN算法体系的学习及代码实现 开发：基于WordPress搭建菜品识别项目网站 产出成果 国家发明专利一项，进入实质审查阶段，我为第二发明人 论文Accurate real-life Chinese dish recognition已被SCI3区期刊ITEES录用，我为学生二作 论文Overview of YOLO Object Detection Algorithm已被国际普刊IJCIT录用，我为学生二作 政府公文写作能力 政府公文写作能力：是否有政府公文、建言献策、政策规划等写作或项目参与经历？若有，请简要列举几项，并说明主题、您在其中的角色、主要收获等。 目前我暂时没有政府公文写作的相关能力，但我有信心参与几次相关工作后能快速上手，原因包括： 我的学生干部经历非常丰富 我的家乡是山东青岛，可能是受到山东人“血脉之力”的影响，我从小到大一直非常热衷于“当官”： 小学期间担任班长，曾获评青岛市市南区优秀学生干部； 初中期间担任班长，曾获评青岛市级三好学生； 高中期间担任班长、团队学生会主席，曾获评山东省优秀学生干部； 大学期间担任班长、系学生党支部副书记，获评优秀学生干部、优秀团干部； 指定格式、内容的文案撰写是学生干部的看家本领之一，相信我可以做到触类旁通。 我负责过两项国家级大创项目，创新创业经历丰富 大创项目每年有10,000的经费，通过这部分经费的使用，我对报销的一般流程有了一定的熟悉；此外，由于项目在各大创新创业竞赛中的突出表现，经常有投资人、创业园的工作人员与我取得联系，因而对创业相关的政策也有一定的了解。 平时负责实验室的部分报销工作 实验室一些项目的经费如果没在指定时间内花完，我会找几位优秀的同学一起组织面向低年级同学的分享讲座，将这部分经费以劳务的形式支出给参与讲座的同学，同学留下100-200之后将其余钱交还。（这是可以说的吗） 数据分析能力 数据分析能力：excel掌握程度？是否会C/R语言软件的，能够编写程序完成什么？是否了解数据的算法构建与开发（数据采集、爬虫编写、数据挖掘、指数可视化）？ excel掌握程度 对excel的基本操作（排序、筛选、条件格式等）、常用函数（SUM、AVERAGE、COUNT等）、图表创建和与python、Matlab的联动有着较为熟练的掌握。 「工业和信息化人才专业知识测评证书-Office办公软件」发证单位：工业和信息化部人才交流中心发证时间：2022.07工业和信息化人才专业知识测评——Office C语言 我对C语言的掌握较为熟练，可以轻松完成面向流程、面向对象（C++）的程序设计工作，对常用算法较为熟悉，包括动态规划、深度/广度优先搜索、快速排序等排序算法、贪心等，对算法的时间、空间复杂度较为敏感。 对C语言的熟练掌握源于课内学习和丰富的算法竞赛经历： C语言相关课程： 课程 成绩 课程 成绩 C/C++程序设计（上） 97 算法入门与应用实践 100 C/C++程序设计（下） 100 数据结构与算法 100 算法竞赛经历： 第11届蓝桥杯全国软件和信息技术专业人才大赛北京赛区C/C++程序设计大学A组二等奖； 第12届蓝桥杯全国软件和信息技术专业人才大赛北京赛区C/C++程序设计大学A组三等奖； 第13届蓝桥杯全国软件和信息技术专业人才大赛北京赛区C/C++程序设计大学A组二等奖； 第二届全国大学生算法设计与编程挑战赛（冬季赛）季军，全场排名4/3043； 第三届全国大学生算法设计与编程挑战赛（秋季赛）银奖； 我对代码有着较强的理解和学习能力，对于新知识能在较短时间内理解掌握，并应用到实战中。 爬虫 我会使用requests库&amp;lxml库和Scrapy框架编写爬虫，有着一定的爬虫&amp;反爬虫攻防实战经验，包括： 添加请求头user agent和Cookie模拟浏览器访问； 设定代理ip和随机的访问间隔时间； 通过post指令传输账号密码，模拟登陆 通过云图等第三方平台解决验证码问题 判断非空以应对网页结构的不一致性 通过selenium行为链模拟鼠标点击&amp;移动 可以参考我独立撰写的四篇爬虫相关博客： python爬虫实战演示 爬虫&反爬虫攻防 Scrapy实战01 Scrapy框架基础 Scrapy实战02 CrawlSpider入门 Scrapy实战03 多媒体数据爬取 数据可视化 会使用Matlab、python和封装可视化工具进行数据可视化： Matlab数据可视化 我对Matlab的绘图操作较为熟悉，可以参考我独立撰写的博客： Matlab绘图 plot等二维绘图函数 python数据可视化 对数据结构库numpy、数据分析库pandas有一定了解，会使用seaborn库（配合matplotlib库）进行基本的数据可视化代码编写，包括： 散点图&amp;折线图 relplot 分类图（柱图、点线图） catplot 单变量分布（直方图）displot 二变量分布（直方散点图）jointplot 线性回归图 regplot 封装可视化工具 使用dycharts制作美观大方的静态/动态/交互式数据可视化图表，结合一定的HTML知识（主要是iframe标签）将其添加至网页文件中，参考案例： 在线积极心理干预实证研究分析 某学期我院成绩分析 中国传媒大学暑期实践报告获奖作品《补缀泛黄相纸 追寻峥嵘往昔》 PPT制作能力 PPT制作能力：请简述自己在PPT制作方面的经验，并列举PPT制作时常使用的网站或美化软件。 在本文的论文&amp;项目 - [项目1] 历史影像修复中，包含了我所负责项目的路演ppt，由我独立制作完成，可供本问题的参考。 制作经验 排版中的网格意识与主次关系 网格意识决定了排版布局的整体性与统一性，使用“格式”中的“对齐”使图片文字图标快速对齐，可以使得页面整洁美观。对于一整段文字，我们需要从内容中抓取重要的信息并加以设计，突出重点内容，放大加粗标题，将主次信息拉开，同时根据这段文字的标题使用一些元素符号进行修饰。 色块设计与图片美化 色块在排版主要有分割内容、突出信息、增加视觉冲击力、装饰等作用。版面中有多个色块时最好要有大小的区分。同时色块内的元素排版要有细节，PPT中色块的配色切忌过多，一般选用3-5个颜色，同一色系的颜色可以有深浅变化。PPT中图片也是增加丰富度的重要手段，可以选择裁切合适的形状搭配色块元素与边框，让图片更好地融入整个PPT的风格，也可以使用PPT自带的美化功能调整对比度、明度、饱和度，使图片更清晰美观。 图标细节增加亮点 Icon是PPT中的点睛之笔，它能帮助人们快速分类有效信息，提取关键元素，提高版面设计性，加深个性化设计风格，提升设计亲和度。图标运用辅助线帮助绘制，对齐像素格，保边缘清晰，长度，粗细，圆角，颜色统一即可。 字体嵌入文件或文字转图片保证兼容性 当做好的PPT在别人的电脑中打开，而对方电脑并没有文档中你使用的字体时，便会被自动替换成其他字体，影响整体效果， 所以需要在文件-工具-选项的常规与保存中，勾选将字体嵌入文件。如果还需到无法兼容的问题，可以选择右击文字，转为图片，再以图片的形式插入，就可以保证万无一失了。 善用平滑切换模拟动画效果 适合并列/总分形式的ppt展示，具体效果参考以下视频： Your browser does not support the video tag. 常用网站 Canva可画 在线设计平台 吾道幻灯片 在线演示文档 创客贴 在线设计平台 图怪兽 在线设计平台 iSlide PowerPoint素材插件 Pinterest 商用图片素材库 Iconfont 阿里巴巴矢量图标库 以方iFonts 可商用字体库 常用研究报告来源 常用研究报告来源有哪些？ 咨询公司行业报告、国内外政府统计局/税务局等官网、会计审计企业综合数据、权威教育机构（或个人）科研成果： 艾媒网：https://www.iimedia.cn/ 洞见研报：https://www.djyanbao.com/index wind：https://www.wind.com.cn/ 镝数聚：https://www.dydata.io/ Ibis world: https://www.ibisworld.com/ 波士顿咨询：https://www.bcg.com/zh-cn/ 贝恩咨询：https://www.bain.cn/ Kantar：https://www.kantarworldpanel.com/cn 国内外政府统计局、税务局等官网（常用于demographic, geographic &amp; economics等的数据收集） Corruption Perceptions Index：https://www.transparency.org/en/cpi/2021 麦肯锡：https://www.mckinsey.com.cn/ 摩根大通：https://www.jpmorgan.com/global 此外，一些研究报告会以论文的形式被收录在知网、万方等数据库中。 常用数据搜集渠道 常用数据搜集渠道有哪些？ 数据可以分为两类：一手数据和二手数据。 一手数据主要为自行收集得来，在实际应用中占比较少，但更为珍贵，获取方法包括： 线上：问卷调查、会议、面试（面谈）、爬虫等后台数据统计 线下：问卷调查、志愿者实验、自我报告、观察统计法、生理测量 二手数据主要通过第三方渠道获得，在实际应用中占比较高，搜集快、方便整合，获取方法包括： 线上：权威数据收集/统计及分析网站（公司）、新闻、企业发布官方声明（招股说明书、年报等） 线下：档案资料、书籍 具体的二手数据获取渠道包括： 联合国商品贸易统计数据库 中国私营企业调查 世界银行中国企业调查数据 中国工业企业数据库 海关数据 实话实说，在我的工科生学习生涯中，用到数据搜集的场景并不多，主要就是在数学建模比赛中使用，上面整理的研究报告来源和数据搜集渠道有部分询问了项目组里的营销人员。 国际化水平 英文水平 英文水平（听说读写能力） 拥有较强的英文阅读和写作能力，有大量的英文文献阅读经验，在对某一领域熟悉后，能几乎不借助翻译软件阅读英文文献。 CET-4 CET-6 IELTS IELTS-Reading IELTS-Listening IELTS-Writing IELTS-Speaking 593 472 6.5 8.0 6.5 6.5 5.5 能力认证「全国商务外语翻译证书-中级笔译」语种：英语考试成绩：Grade B发证日期：2022年1月颁发单位：中国商业联合会全国商务外语翻译证书-中级笔译 海外经历 是否有海外经历或国际项目合作经历？若有则简要描述。 2021.07 - 2021.10 代表中国传媒大学邀请来自世界各地的大学生创业项目参与第七届中国国际“互联网+”大学生创新创业大赛-国际赛道，参与团队对接、项目翻译和部分开发、完善工作。 项目 XIAOSHOUHU —— Children's Intangible Cultural Heritage Learning Platform 获得国际赛道全国银奖。 第七届“互联网+”国际赛道全国银奖 意愿及规划 为什么选贲教授作为导师 受到“互联网+”大赛的影响，我未来有创业的打算，目前的计算机技能也比较偏向工程和实际应用。贲教授有工程学、企业管理和经济学的背景，从事金融科技、创业管理相关的研究，在学术界有着很高的地位，能为学生提供很多方面的帮助。 希望从读博期间获得什么 第一是面向工程的能力，我认为学术应该是为实际应用而服务的，无论未来是否创业，我都希望自己的研究工作能够有充分的商业和社会价值。在未来的研究工作中，我也会主动参与校企合作相关的项目，在实际应用中锻炼我的能力。 第二是若有合适的创业机会，我希望能将一部分精力投入到创业工作中，不强求一次性成功，而是把它当作一种特殊的技能训练，在这一过程中结识各个领域的大牛，对接行业资源，培养自身的团队管理能力、抗压能力和相关的技能。 未来团队贡献&amp;核心优势 对自己在成为贲教授的博士之后，可以在团队中贡献的核心内容是什么？自己的核心优势是什么？ 我的核心优势在于计算机背景，包括灵活的算法设计思维、成熟的前后端开发能力和优秀的技术学习能力。在团队中，我可以承担与代码有关的大部分工作，包括搭建实验室对外宣传的网站、承担数据爬取/清洗/可视化工作、承担可能会有的前后端开发工作等。 我的第二优势在于丰富的学生干部经历——成熟的打工人是心理有活的人，我将愿意主动承担团队中的材料筹备、报销审批、信息收集等工作，充当“小管家”的角色。 我的第三优势在于乐于分享，在成为实验室中的小师哥后，我会主动帮助低年级的成员，形成高年级带低年级的良好风气。本科期间我就是这样做的，经常撰写技术文档分享给同年级和低年级的同学，我的csdn博客累计访问量已经超过52,000人次： 我的csdn主页 点击访问 职业发展路径规划 未来职业发展路径规划？ 我的主要成果源于我负责的互联网+大赛项目，也正是受到它的影响，我希望在未来从事学术成果转化类型的工作，包括产品经理、创业等。 关于未来规划，我一直以来的想法都是“寻求每一步的最优解，以更好地选择、把握机会”。我相信人的目标和理想是会随着知识的丰富和眼界的提升而改变的。我现在只是在带队参赛，没有实际创业，因而我也不敢保证自己真的会喜欢这样的生活。 当机会摆在我面前时，可能会是读博后留校任教，一边带带学生，一边讲讲课；可能会受到山东人的血脉影响，走上从政的道路；可能会以技术岗位进入大厂，成为一名码农；可能会发现合适的商机，走上创业的道路。把握住这些机会的前提，是我有与之相匹配的能力——如果留校任教，我会带着我的学生与企业合作，做做项目，培养学生的工程能力，也丰富我的教师生活；如果从政，我会以技术条件为敲门砖，发挥自己在人际交往方面的能力，一步步实现更高的追求；如果以技术岗位进入大厂，我会一边工作一边学习，培养自己的跨学科能力，从技术岗向管理岗发展；如果创业，我也会拥有参与产品的研发、营销、财务、风险等每一个环节的能力，做好团队领头人······我会踏踏实实走好脚下的每一步，为未来有更多的选择而努力。 可接受的工作强度 由于贲教授及团队非常重视学生的应用能力培养，因此学生在读博期间除了常规课业、论文之外，还鼓励参与课题项目等工作，若BAT等互联网公司工作强度为8分（满分为10分），您可接受的学习工作强度为？也可以简要说明。 我可以保证日常的学习工作强度维持在8左右，关键时期维持在10分。 作为高考大省出来的学生，努力已经成为一种习惯。本科三年期间，在维持课内排名的同时，我的日常生活做到了有规划的充实： 参加了两项投入精力较多的计算机视觉类科研项目，产出论文、专利和创新创业竞赛奖项若干； 广泛涉猎，在学科竞赛、算法竞赛、外语、红色文化和艺术设计等领域累计获得荣誉40余项； 通过工业和信息化部人才交流中心的6项专业技能认证； 连续三年担任班长，积极承担班级工作； 首批入党，担任党支部副书记，积极承担党务工作； 积极参与志愿服务，志愿时长618.5小时； 在日常生活中，我较为自律，习惯使用效率类的app辅助规划我的生活，包括： 使用 forest - 专注森林 杜绝“手机控”，累计专注时间1637小时； 使用 sleeptown - 睡眠小镇 保持规律作息，累计规律作息274天； 在家期间固定前往线下自习室学习，记录时长3103小时； 上面是我日常生活中努力的缩影，可以作为前半句话的佐证； 对于需要拿出超额精力的“关键时期”，我也有着足够的毅力和韧性，具体表现为去年4-6月，我负责的大创-互联网+项目初创期，为了达到参赛要求，每次都卡在ddl前一分钟，提交目前能做到的最好版本，陆续通宵接近一个半月，最终使得初创项目第一年参赛就战胜了很多较为成熟的项目，成为我校首个杀入国赛的项目（互联网+大赛鼓励历年未获得全国银奖及以上的项目继续参赛）。为此，市决赛结束后，我住了半个月的院： 爆肝珍贵留影 虽然透支身体并不是一件值得提倡的事，但也足以作为我在关键时期能付出足够精力的佐证。 锻炼身体已提上日程。 入学前的规划安排 从您填表开始至明年入学，您的时间规划安排如何？是否有意愿提前加入团队参与一些日常科研工作进行双向了解？ 首先，我非常明确自己在经济金融领域缺乏足够的基础知识，因而我会充分利用这段时间，通过书籍、网课的形式系统性地学习必要的课程，在正式入学之前将基础补到和顶尖商科学生同等的水平。 我愿意提前加入团队参与日常的科研工作，如因基础不足而暂时无法涉及太深，我也愿意先承担一些日常性的工作，包括帮组里的师哥师姐收集收集数据、画画图，帮老师干点杂活等；我会尽量发挥自己在计算机方面的优势，承担相关的工作，包括数据爬取、数据清洗、可视化以及实验室网站搭建、相关的产品前后端研发工作。 如有合适的机会，我可以在新的团队中完成本科期间的毕业设计，以期尽快打开科研局面，做出初步的成果。 此外，我计划进一步提升英语水平，为自己设定的目标是在今年12月或明年6月的六级考试中考到550分以上的分数。 希望询问的问题 若您有希望了解的问题，可在此部分列举。 暂无。"},{"title":"本周工作简报 08.17-08.24","date":"2022-08-31T13:07:14.342Z","updated":"2022-08-25T17:08:59.203Z","comments":true,"path":"report0824/index.html","permalink":"https://pyxblog.cn/report0824/index.html","excerpt":"","text":"摘要 文献阅读方面，对共情疲劳的传统检测方法进行了一定的了解和总结，拜读了您的文献了解了一些在线积极心理干预的策略，并大致了解了情感分析的方法。 商业化方面，本周线下参与了第九届“创青春”的全国总决赛路演，认识了几位投资人，与他们探讨了之前商业化思路的可行性，否决了一些之前的想法。 关于预推免报名的准备情况 文献阅读总结 共情疲劳 概念 共情疲劳是指助人群体在向救助对象提供物质或生理等方面的援助过程中，以对现实的、隐含的或想象的救助对象主动付出共情为前提，从而遭受二次创伤，降低其对救助对象共情的能力和兴趣，出现助人工作的倦怠感，甚至改变自身原有的价值观和世界观，同时伴随一系列身心不适症状。 结构 有关共情疲劳的结构主要存在两种观点：二维结构和三维结构 二维：职业倦怠&amp;二次创伤 三维：职业倦怠&amp;二次创伤&amp;共情满足 测量 评估共情疲劳的程度： 共情疲劳自我测验 Compassion Fatigue Self Test, CFST 共情满足和疲劳测验 Compassion Satisfaction and Fatigue Test, CSFT 救助人员生活质量量表 Professional Quality of Life Scale, ProQOL 共情疲劳量表-修订版 Compassion Fatigue Scale-Revised, CFS-R 共情疲劳简短量表 CF-Short Scale 评估共情疲劳的症状： 二次创伤压力量表 Secondary Traumatic Stress Scale, STSS 事件影响量表 lmpact of Event Scale, IES 事件影响量表-修订版 Impact of Event Scale Revised, TES-R 评估共情疲劳的认知图式： 创伤和依附信念量表 Trauma and Attachment Belief Scale, TABS 世界假想量表 World Assumptions Scale, WAS 量表 子量表（项目数） 信度（a值） 效度 时间范围 CFST 共情疲劳 23职业倦怠 17总量表 40 0.86-0.94 因素分析得到一个稳定的因子 无限定 CSFT 共情满足 26共情疲劳 23职业倦怠 16 0.870.870.90 — 无限定 ProQOL 共情满足 10职业倦怠 10二次创伤压力/共情疲劳 10 0.870.720.80 良好的会聚效度与区分效度 过去30天 CFS-R 二次创伤压力/共情疲劳 22职业倦怠 8总量表 30 ——— ——— 无限定 CF-Short Scale 职业倦怠 8二次创伤 5总量表 13 0.900.800.90 良好的因素分析结果、同时效度和预测效度 无限定 STSS 侵扰 5逃避 7唤醒 5总量表 17 0.800.870.830.93 良好的因素分析结果、会聚效度和区分效度 过去一星期 IES 侵扰 7逃避 8 0.860.82 良好的结构效度和会聚效度 过去一星期 IES-R 侵扰 7逃避 8唤醒 6 0.890.840.82 良好的会聚效度和区分效度 过去一星期 TABS 安全、信任、自尊、亲密、控制（共10个子量表、84个项目）总量表 0.77-0.910.98 会聚效度、区分效度及因素分析与其他研究结果不一致 无限定 WAS 世界的真善美 10世界的意义性 10自我价值 10 0.820.740.77 良好的因素分析和结构效度 无限定 影响因素 根本因素：共情 其他因素： 个体的人口统计学变量 个人创伤史 婚姻状况 学历 接触或暴露于创伤事件的程度变量 受创伤程度 工作负荷量 工作卷入程度 心理资源变量 内在心理资源——自我复原力 外在心理资源——社会支持、工作信息量、工作习惯等 ProQOL中文版 条目 因子1 因子2 因子3 因子4 因子5 1. 我对我帮助的对象及我如何帮助他们有快乐的想法和感觉 0.759 2. 我很高兴我能掌握“帮助”的程序和技巧 0.749 3. 我喜欢我作为帮助者的工作 0.747 4. 我为我能帮忙做些什么而感到自豪 0.742 5. 我能从对别人的帮助中获得满足感 0.728 6.我的工作使我很满足 0.724 7. 我想作为帮助者我是成功的 0.719 8.我有信念支撑我 0.710 9. 我相信我的工作能带来改变 0.670 10. 帮助别人后，我觉得精力充沛 0.643 11. 我很高兴我选择了这份工作 0.640 12. 我是那个我想成为的人 0.610 13. 我能感到与别人的联系 0.606 14. 我很快乐 0.598 15. 我想我可能感染了那些我所帮助对象的创伤压力 0.715 16. 我感到好像正在经历我所帮助对象所经历的创伤 0.709 17. 我的工作没有成效，因为我为我所帮助对象的痛苦经历而失眠 0.699 18. 由于我所帮助对象的创伤经历，我感到沮丧 0.616 19. 我很难将我的私人生活与我作为帮助者的生活区分开 0.615 20. 作为帮助者，我觉得我被工作困住了 0.565 21. 由于我的帮助，我感到自己对许多事情已经到了爆发的边缘 0.563 22. 我避免某些活动和场所，因为他们让我想起我帮助对象的可怕经历 0.520 23. 因为从事帮助者的工作，我觉得筋疲力尽 0.681 24. 因为工作负荷大，我觉得自己快被压倒了 0.677 25. 我忙于应对多个需要我帮助的对象 0.591 26. 由于我的帮助工作，我有侵入性的可怕想法 0.680 27. 我觉得陷在帮助的系统里 0.566 28. 我记不住我工作中有关创伤受害者的重要部分 0.564 29. 遇到意想不到的声音时我会被惊吓到 0.715 30. 我是个非常敏感的人 0.626 在线积极心理干预 online positive psychological intenremion，OPPI 含义：基于积极心理学理论与实践开展的、以积极活动为依托、以在线技术为载体，旨在提升人们幸福感和优势的干预 优势：可获得性强、目标群体广、成本低、可持续性强 劣势：脱落率高 干预策略：提升积极情绪、改善积极关系、挖掘个性优势、实施综合干预 干预策略 幸福五要素理论 PERMA：积极情绪positive emotions、参与engagement、关系relationships、意义meaning、成就achievements PPI聚焦于对积极情绪体验（感恩、快乐等）、积极个性特征（性格优势）、积极关系（善行、积极回应）等元素进行干预 提升积极情绪 作用：帮助个体减轻精神压力，获得心流体验，增强身体机能 方法：感恩、三件好事及其变式、积极情感日记、最佳可能自我干预、在线积极情感日志、在线乐观干预、在线自我同情干预等 改善积极关系 积极关系：社会融合感、支持他人以及被他人支持、能够带来更高的生活满意度、希望、感恩、幸福感和灵性 研究结论： 指向他人/世界的善行更能提升幸福感和积极情绪 有自主性支持的善行更能提高幸福感，心理需要的满足在幸福感的提升中起中介作用 利他特质对善行干预效果具有调节作用 挖掘个性优势 个性优势：个体典型的、真正代表个人的优势的性格 模式：认识自己、探索自己的优势并运用到实践中 特点：个性化，贴合在线干预的优势 实施综合干预 目标：提升参与者的幸福感、生活质量、改善抑郁症状 同时采用多种积极活动来提升参与者的积极情绪、人格特征、积极关系等要素 研究者对25项OPPI实证研究的分析： 上图是一张交互式圆角环形图，储存在dycharts.com的服务器中，该服务器不太稳定，可能会因为网不好而加载失败。备用静态图片链接：https://img-1306037672.cos.ap-beijing.myqcloud.com/OPPI.jpg 未来研究方向 探索并形成OPPI的理论基础 降低脱落率，提升干预效果的说服力 寻求个体-活动-技术之间的良好匹配 情感分析 对接收到的模态信息进行情感分类，以识别发表意见者的主观意向，确定发表者对某事件的态度，以及各交流对象意欲表达的情感。 单模态情感分析 模态：人接受信息的方式 主要是基于面部表情、文本、语音三种方式进行情感分析。 获取数据相对容易且有针对性（国内外主流的数据库大多是单模态，部分多模态数据库也因用户隐私问题未完全公开部分数据），但准确性低于多模态情感分析。 基于面部表情的情感分析 常用方法：卷积神经网络CNN 相关文献： Facial expression recognition using ROI-KNN deep convolutional neural networks - 2016 基于卷积神经网络的模型ROI-KNN 通过对表情图片的切割扩大数据集，解决了神经网络模型泛化能力较弱的问题，有效提高了对面部表情识别的准确性 Robust Image Sentiment Analysis Using Progressively Trained and Domain Transferred Deep Networks - 2015 基于卷积神经网络 采用渐进式训练策略克服训练样本的噪声干扰 Sentribute: image sentiment analysis from a mid-level perspective - 2013 将特征脸面部表情作为中级属性的图像情感预测框架 基于文本语句的情感分析 一般流程：建立训练集（爬取&amp;清洗）、利用情感标签对训练数据进行标记、提取训练数据中的特征、利用训练模型对特征进行情感分析 常用方法：支持向量机、朴素贝叶斯法、随机森林、最大熵模型等 相关文献： Thumbs up Sentiment Classification Using Machine Learning Techniques - 2022 比较验证了SVM应用于情感分类工作的有效性 基于 SVM 多特征融合的微博情感多级分类研究 - 2017 从词性、句式、语义等方面提取多种单词的特征，准确率82.40% Current State of Text Sentiment Analysis from Opinion to Emotion Mining - 2017 任务氛围情感挖掘和观点挖掘，微博数据集 基于语音的情感分析 一般流程：提取语音中能够反映情感倾向的特征参数，应用某种识别方法确定语音中所包含的情感 常用方法：马氏距离判别法、神经网络、主成分分析、隐马尔可夫模型、混合高斯模型法等 相关文献： 语音信号中的情感特征分析和识别的研究 - 2004 提出一种改进型马氏距离判别式，准确率94% 多模态情感分析 利用不同模态提取的特征，通过模态融合的方式来实现情感分析，提高情感识别的精确性和稳定性。 核心：模态融合技术——特征级融合、决策级融合、混合融合 特征级融合 通过提取不同的单模态特征，将它们简单地连接并融合成一个多模态特征向量，作为通用特征分析单元，进行情感分析 优势： 充分利用不同模态特征之间的相关性 流程简单，后续只需要一个分类器 劣势： 不同模态特征可能取自不同的媒体文件或语义空间，相互差异较大，很难找到恰当的融合方法 决策级融合 首先独立地抽取每个模态的情感进行分类及分析，再将各个模态特征的分析结果融合。 优势： 自由度高，可以按需选择不同的模态特征进行学习 对每个模态的学习针对性强，学习效果显著 可以自由地选取分类器和提取器 若某一模态的数据缺失，可以利用其他模态的特征来填补空缺 劣势： 未考虑到各个特征之间的联系 并且需要提取、学习多个模态的特征，时间复杂度高 混合融合 将特征级融合和决策级融合相结合，结合二者的优点提高分析的准确性和效率，同时克服二者的缺陷。 商业化思路拓展&amp;可行性讨论 8月20日至24日，我前往江西省共青城参加第九届“创青春”中国青年创新创业大赛（数字经济专项）全国总决赛 组委要求每个项目组的负责人必须到场，不然其实可以安排组里负责路演展示的播音主持专业成员去参与答辩 线下路演期间，我认识了三个投资人，他们对我的项目提出了一些指导意见，趁此机会与他们探讨了一下之前跟您提过的一些商业化思路： 有关骑手穿戴设备的激励思路是有一定可行性的，包括将心理疲劳程度作为影响骑手接单的因素、以第三方机构的名义组织骑手参与统一的心理健康讲座+检测+帮扶，实际的可行性还需参考咱们设备的形状、重量、对配送的影响和法律上的可行性，后续如果真的考虑落地，可以进行问卷调查，我已做好在青岛市区内收集外卖骑手问卷的准备； 利用线下骑手聚集点推广的思路有待商榷，考虑到骑手忙于接单，在聚集点等待的时间并不稳定，因而我原先设想的开展持续体验式服务可行性不高，可以考虑的方案包括： 与上一点中的“以第三方机构的名义组织骑手参与统一的心理健康讲座+检测+帮扶”相结合，在线下聚集点发布讲座通知 探寻“随用随停”的体验式服务，比如简单的心理健康帮扶引导 投放广告 转移阵地，通过线下聚集点为我们的线上交流群/产品引流 之前考虑较为深入的面向C端的心理帮扶社区，考虑到社区引流需要大量的广告资源投入，形成规模的难度较大，如果我们这边有比较合适的技术基础，可以先开发微信小程序，以课题组的名义与高校心理健康教育中心、高校心理相关社团、面向青年群体的心理健康机构合作，通过举办心理沙龙、交流会等活动的形式逐步引流，拥有一定流量后再上线移动端产品； 心理学其实一直是我的一个爱好，也是我希望成为您的学生的原因之一。大三上学期，我和一位好友共同发起了一个心理健康社团——SelfLove自我成长社，主要通过举办一些线下的交流会，启发大学生探索自我、了解自我、热爱自我。我们举办的活动主题如下： 2021.10.15 为什么脱单这么难 2021.10.23 想要勇敢说不 2021.10.29 亲密关系中的安全感 2021.10.31 成年人的朋友圈 2021.11.5 反抗“内卷”联盟 2021.11.12 感情是可以通过努力获得的吗？ 2021.11.19 接受不完美的自己 2021.11.26 小白杨成长攻略 2021.12.3 亲密关系中的自我成长 社团9月30号成立，10月23号就有600+社员了，每一场活动都爆满，后来不得不抽签选人，可见当代大学生对心理健康有着较高的重视，只要能找到合适的形式，肯定不缺流量。 有关“将心理健康作为员工的福利待遇”，可能需要等待国家相关政策的完善，单从企业自身的角度出发缺乏足够的动力，原先考虑的“从产生过用人纠纷的分公司入手，辐射性推广”可以作为一个思路，但在缺乏相关政策要求的支持下，实际利润空间有限； “创青春”是“参赛+创业帮扶“一体化的创新创业大赛，由共青团中央举办，获奖项目在曝光度、政策等方面均享有一定的福利，我们未来如果考虑商业化，可以从创新创业竞赛入手，参加一些官方部委组织的大型创新创业大赛，有助于对接行业资源、提高曝光度，还能享受一些免费的创业园入驻和办公场地； 此外，俺的路演表现还不错，获得了全国铜奖： 杂谈 今天是8月25日，距离预推免系统截止还有6天，我已经提交了报名，还差一些材料正在准备。明天开始我打算把主要精力放在材料筹备和面试准备上，主要是： 材料筹备：打磨简历&amp;个人陈述、整理综合素质材料、准备作品集 面试准备：专业课复习、项目复盘、英文话题准备 我的目标坚定，先报了Open Fiesta的【互联网+创新设计】，看到还可以报一个志愿，就翻了一下其他方向的导师，在【互动媒体设计与技术】方向看到了您，就报名了这个方向。 后者需要提交作品集，我目前的打算是提交： 我负责的老照片修复项目产品、商业计划书 我参与的起舞元宇宙项目产品、商业计划书 我的个人博客pyxblog.cn 我参与设计类比赛的作品（平面设计、MG动画） 我参与设计的外观专利 这个方向好像比较贴合游戏开发、数字媒体艺术、数字媒体技术，与我的专业（广播电视工程）跨度有点大，因而不太确定作品集该如何准备，老师觉得这样准备是否合适？如有必要，我可以利用ddl前的时间找我们学校动画学院的朋友现学一点。"},{"title":"本周工作简报 08.17-08.24","date":"2022-09-03T17:38:34.766Z","updated":"2022-08-31T13:09:59.304Z","comments":true,"path":"report/0824/index.html","permalink":"https://pyxblog.cn/report/0824/index.html","excerpt":"","text":"摘要 文献阅读方面，对共情疲劳的传统检测方法进行了一定的了解和总结，拜读了您的文献了解了一些在线积极心理干预的策略，并大致了解了情感分析的方法。 商业化方面，本周线下参与了第九届“创青春”的全国总决赛路演，认识了几位投资人，与他们探讨了之前商业化思路的可行性，否决了一些之前的想法。 关于预推免报名的准备情况 文献阅读总结 共情疲劳 概念 共情疲劳是指助人群体在向救助对象提供物质或生理等方面的援助过程中，以对现实的、隐含的或想象的救助对象主动付出共情为前提，从而遭受二次创伤，降低其对救助对象共情的能力和兴趣，出现助人工作的倦怠感，甚至改变自身原有的价值观和世界观，同时伴随一系列身心不适症状。 结构 有关共情疲劳的结构主要存在两种观点：二维结构和三维结构 二维：职业倦怠&amp;二次创伤 三维：职业倦怠&amp;二次创伤&amp;共情满足 测量 评估共情疲劳的程度： 共情疲劳自我测验 Compassion Fatigue Self Test, CFST 共情满足和疲劳测验 Compassion Satisfaction and Fatigue Test, CSFT 救助人员生活质量量表 Professional Quality of Life Scale, ProQOL 共情疲劳量表-修订版 Compassion Fatigue Scale-Revised, CFS-R 共情疲劳简短量表 CF-Short Scale 评估共情疲劳的症状： 二次创伤压力量表 Secondary Traumatic Stress Scale, STSS 事件影响量表 lmpact of Event Scale, IES 事件影响量表-修订版 Impact of Event Scale Revised, TES-R 评估共情疲劳的认知图式： 创伤和依附信念量表 Trauma and Attachment Belief Scale, TABS 世界假想量表 World Assumptions Scale, WAS 量表 子量表（项目数） 信度（a值） 效度 时间范围 CFST 共情疲劳 23职业倦怠 17总量表 40 0.86-0.94 因素分析得到一个稳定的因子 无限定 CSFT 共情满足 26共情疲劳 23职业倦怠 16 0.870.870.90 — 无限定 ProQOL 共情满足 10职业倦怠 10二次创伤压力/共情疲劳 10 0.870.720.80 良好的会聚效度与区分效度 过去30天 CFS-R 二次创伤压力/共情疲劳 22职业倦怠 8总量表 30 ——— ——— 无限定 CF-Short Scale 职业倦怠 8二次创伤 5总量表 13 0.900.800.90 良好的因素分析结果、同时效度和预测效度 无限定 STSS 侵扰 5逃避 7唤醒 5总量表 17 0.800.870.830.93 良好的因素分析结果、会聚效度和区分效度 过去一星期 IES 侵扰 7逃避 8 0.860.82 良好的结构效度和会聚效度 过去一星期 IES-R 侵扰 7逃避 8唤醒 6 0.890.840.82 良好的会聚效度和区分效度 过去一星期 TABS 安全、信任、自尊、亲密、控制（共10个子量表、84个项目）总量表 0.77-0.910.98 会聚效度、区分效度及因素分析与其他研究结果不一致 无限定 WAS 世界的真善美 10世界的意义性 10自我价值 10 0.820.740.77 良好的因素分析和结构效度 无限定 影响因素 根本因素：共情 其他因素： 个体的人口统计学变量 个人创伤史 婚姻状况 学历 接触或暴露于创伤事件的程度变量 受创伤程度 工作负荷量 工作卷入程度 心理资源变量 内在心理资源——自我复原力 外在心理资源——社会支持、工作信息量、工作习惯等 ProQOL中文版 条目 因子1 因子2 因子3 因子4 因子5 1. 我对我帮助的对象及我如何帮助他们有快乐的想法和感觉 0.759 2. 我很高兴我能掌握“帮助”的程序和技巧 0.749 3. 我喜欢我作为帮助者的工作 0.747 4. 我为我能帮忙做些什么而感到自豪 0.742 5. 我能从对别人的帮助中获得满足感 0.728 6.我的工作使我很满足 0.724 7. 我想作为帮助者我是成功的 0.719 8.我有信念支撑我 0.710 9. 我相信我的工作能带来改变 0.670 10. 帮助别人后，我觉得精力充沛 0.643 11. 我很高兴我选择了这份工作 0.640 12. 我是那个我想成为的人 0.610 13. 我能感到与别人的联系 0.606 14. 我很快乐 0.598 15. 我想我可能感染了那些我所帮助对象的创伤压力 0.715 16. 我感到好像正在经历我所帮助对象所经历的创伤 0.709 17. 我的工作没有成效，因为我为我所帮助对象的痛苦经历而失眠 0.699 18. 由于我所帮助对象的创伤经历，我感到沮丧 0.616 19. 我很难将我的私人生活与我作为帮助者的生活区分开 0.615 20. 作为帮助者，我觉得我被工作困住了 0.565 21. 由于我的帮助，我感到自己对许多事情已经到了爆发的边缘 0.563 22. 我避免某些活动和场所，因为他们让我想起我帮助对象的可怕经历 0.520 23. 因为从事帮助者的工作，我觉得筋疲力尽 0.681 24. 因为工作负荷大，我觉得自己快被压倒了 0.677 25. 我忙于应对多个需要我帮助的对象 0.591 26. 由于我的帮助工作，我有侵入性的可怕想法 0.680 27. 我觉得陷在帮助的系统里 0.566 28. 我记不住我工作中有关创伤受害者的重要部分 0.564 29. 遇到意想不到的声音时我会被惊吓到 0.715 30. 我是个非常敏感的人 0.626 在线积极心理干预 online positive psychological intenremion，OPPI 含义：基于积极心理学理论与实践开展的、以积极活动为依托、以在线技术为载体，旨在提升人们幸福感和优势的干预 优势：可获得性强、目标群体广、成本低、可持续性强 劣势：脱落率高 干预策略：提升积极情绪、改善积极关系、挖掘个性优势、实施综合干预 干预策略 幸福五要素理论 PERMA：积极情绪positive emotions、参与engagement、关系relationships、意义meaning、成就achievements PPI聚焦于对积极情绪体验（感恩、快乐等）、积极个性特征（性格优势）、积极关系（善行、积极回应）等元素进行干预 提升积极情绪 作用：帮助个体减轻精神压力，获得心流体验，增强身体机能 方法：感恩、三件好事及其变式、积极情感日记、最佳可能自我干预、在线积极情感日志、在线乐观干预、在线自我同情干预等 改善积极关系 积极关系：社会融合感、支持他人以及被他人支持、能够带来更高的生活满意度、希望、感恩、幸福感和灵性 研究结论： 指向他人/世界的善行更能提升幸福感和积极情绪 有自主性支持的善行更能提高幸福感，心理需要的满足在幸福感的提升中起中介作用 利他特质对善行干预效果具有调节作用 挖掘个性优势 个性优势：个体典型的、真正代表个人的优势的性格 模式：认识自己、探索自己的优势并运用到实践中 特点：个性化，贴合在线干预的优势 实施综合干预 目标：提升参与者的幸福感、生活质量、改善抑郁症状 同时采用多种积极活动来提升参与者的积极情绪、人格特征、积极关系等要素 研究者对25项OPPI实证研究的分析： 上图是一张交互式圆角环形图，储存在dycharts.com的服务器中，该服务器不太稳定，可能会因为网不好而加载失败。备用静态图片链接：https://img-1306037672.cos.ap-beijing.myqcloud.com/OPPI.jpg 未来研究方向 探索并形成OPPI的理论基础 降低脱落率，提升干预效果的说服力 寻求个体-活动-技术之间的良好匹配 情感分析 对接收到的模态信息进行情感分类，以识别发表意见者的主观意向，确定发表者对某事件的态度，以及各交流对象意欲表达的情感。 单模态情感分析 模态：人接受信息的方式 主要是基于面部表情、文本、语音三种方式进行情感分析。 获取数据相对容易且有针对性（国内外主流的数据库大多是单模态，部分多模态数据库也因用户隐私问题未完全公开部分数据），但准确性低于多模态情感分析。 基于面部表情的情感分析 常用方法：卷积神经网络CNN 相关文献： Facial expression recognition using ROI-KNN deep convolutional neural networks - 2016 基于卷积神经网络的模型ROI-KNN 通过对表情图片的切割扩大数据集，解决了神经网络模型泛化能力较弱的问题，有效提高了对面部表情识别的准确性 Robust Image Sentiment Analysis Using Progressively Trained and Domain Transferred Deep Networks - 2015 基于卷积神经网络 采用渐进式训练策略克服训练样本的噪声干扰 Sentribute: image sentiment analysis from a mid-level perspective - 2013 将特征脸面部表情作为中级属性的图像情感预测框架 基于文本语句的情感分析 一般流程：建立训练集（爬取&amp;清洗）、利用情感标签对训练数据进行标记、提取训练数据中的特征、利用训练模型对特征进行情感分析 常用方法：支持向量机、朴素贝叶斯法、随机森林、最大熵模型等 相关文献： Thumbs up Sentiment Classification Using Machine Learning Techniques - 2022 比较验证了SVM应用于情感分类工作的有效性 基于 SVM 多特征融合的微博情感多级分类研究 - 2017 从词性、句式、语义等方面提取多种单词的特征，准确率82.40% Current State of Text Sentiment Analysis from Opinion to Emotion Mining - 2017 任务氛围情感挖掘和观点挖掘，微博数据集 基于语音的情感分析 一般流程：提取语音中能够反映情感倾向的特征参数，应用某种识别方法确定语音中所包含的情感 常用方法：马氏距离判别法、神经网络、主成分分析、隐马尔可夫模型、混合高斯模型法等 相关文献： 语音信号中的情感特征分析和识别的研究 - 2004 提出一种改进型马氏距离判别式，准确率94% 多模态情感分析 利用不同模态提取的特征，通过模态融合的方式来实现情感分析，提高情感识别的精确性和稳定性。 核心：模态融合技术——特征级融合、决策级融合、混合融合 特征级融合 通过提取不同的单模态特征，将它们简单地连接并融合成一个多模态特征向量，作为通用特征分析单元，进行情感分析 优势： 充分利用不同模态特征之间的相关性 流程简单，后续只需要一个分类器 劣势： 不同模态特征可能取自不同的媒体文件或语义空间，相互差异较大，很难找到恰当的融合方法 决策级融合 首先独立地抽取每个模态的情感进行分类及分析，再将各个模态特征的分析结果融合。 优势： 自由度高，可以按需选择不同的模态特征进行学习 对每个模态的学习针对性强，学习效果显著 可以自由地选取分类器和提取器 若某一模态的数据缺失，可以利用其他模态的特征来填补空缺 劣势： 未考虑到各个特征之间的联系 并且需要提取、学习多个模态的特征，时间复杂度高 混合融合 将特征级融合和决策级融合相结合，结合二者的优点提高分析的准确性和效率，同时克服二者的缺陷。 商业化思路拓展&amp;可行性讨论 8月20日至24日，我前往江西省共青城参加第九届“创青春”中国青年创新创业大赛（数字经济专项）全国总决赛 组委要求每个项目组的负责人必须到场，不然其实可以安排组里负责路演展示的播音主持专业成员去参与答辩 线下路演期间，我认识了三个投资人，他们对我的项目提出了一些指导意见，趁此机会与他们探讨了一下之前跟您提过的一些商业化思路： 有关骑手穿戴设备的激励思路是有一定可行性的，包括将心理疲劳程度作为影响骑手接单的因素、以第三方机构的名义组织骑手参与统一的心理健康讲座+检测+帮扶，实际的可行性还需参考咱们设备的形状、重量、对配送的影响和法律上的可行性，后续如果真的考虑落地，可以进行问卷调查，我已做好在青岛市区内收集外卖骑手问卷的准备； 利用线下骑手聚集点推广的思路有待商榷，考虑到骑手忙于接单，在聚集点等待的时间并不稳定，因而我原先设想的开展持续体验式服务可行性不高，可以考虑的方案包括： 与上一点中的“以第三方机构的名义组织骑手参与统一的心理健康讲座+检测+帮扶”相结合，在线下聚集点发布讲座通知 探寻“随用随停”的体验式服务，比如简单的心理健康帮扶引导 投放广告 转移阵地，通过线下聚集点为我们的线上交流群/产品引流 之前考虑较为深入的面向C端的心理帮扶社区，考虑到社区引流需要大量的广告资源投入，形成规模的难度较大，如果我们这边有比较合适的技术基础，可以先开发微信小程序，以课题组的名义与高校心理健康教育中心、高校心理相关社团、面向青年群体的心理健康机构合作，通过举办心理沙龙、交流会等活动的形式逐步引流，拥有一定流量后再上线移动端产品； 心理学其实一直是我的一个爱好，也是我希望成为您的学生的原因之一。大三上学期，我和一位好友共同发起了一个心理健康社团——SelfLove自我成长社，主要通过举办一些线下的交流会，启发大学生探索自我、了解自我、热爱自我。我们举办的活动主题如下： 2021.10.15 为什么脱单这么难 2021.10.23 想要勇敢说不 2021.10.29 亲密关系中的安全感 2021.10.31 成年人的朋友圈 2021.11.5 反抗“内卷”联盟 2021.11.12 感情是可以通过努力获得的吗？ 2021.11.19 接受不完美的自己 2021.11.26 小白杨成长攻略 2021.12.3 亲密关系中的自我成长 社团9月30号成立，10月23号就有600+社员了，每一场活动都爆满，后来不得不抽签选人，可见当代大学生对心理健康有着较高的重视，只要能找到合适的形式，肯定不缺流量。 有关“将心理健康作为员工的福利待遇”，可能需要等待国家相关政策的完善，单从企业自身的角度出发缺乏足够的动力，原先考虑的“从产生过用人纠纷的分公司入手，辐射性推广”可以作为一个思路，但在缺乏相关政策要求的支持下，实际利润空间有限； “创青春”是“参赛+创业帮扶“一体化的创新创业大赛，由共青团中央举办，获奖项目在曝光度、政策等方面均享有一定的福利，我们未来如果考虑商业化，可以从创新创业竞赛入手，参加一些官方部委组织的大型创新创业大赛，有助于对接行业资源、提高曝光度，还能享受一些免费的创业园入驻和办公场地； 此外，俺的路演表现还不错，获得了全国铜奖： 杂谈 今天是8月25日，距离预推免系统截止还有6天，我已经提交了报名，还差一些材料正在准备。明天开始我打算把主要精力放在材料筹备和面试准备上，主要是： 材料筹备：打磨简历&amp;个人陈述、整理综合素质材料、准备作品集 面试准备：专业课复习、项目复盘、英文话题准备 我的目标坚定，先报了Open Fiesta的【互联网+创新设计】，看到还可以报一个志愿，就翻了一下其他方向的导师，在【互动媒体设计与技术】方向看到了您，就报名了这个方向。 后者需要提交作品集，我目前的打算是提交： 我负责的老照片修复项目产品、商业计划书 我参与的起舞元宇宙项目产品、商业计划书 我的个人博客pyxblog.cn 我参与设计类比赛的作品（平面设计、MG动画） 我参与设计的外观专利 这个方向好像比较贴合游戏开发、数字媒体艺术、数字媒体技术，与我的专业（广播电视工程）跨度有点大，因而不太确定作品集该如何准备，老师觉得这样准备是否合适？如有必要，我可以利用ddl前的时间找我们学校动画学院的朋友现学一点。"},{"title":"本周工作简报 08.25-08.31","date":"2022-09-03T17:38:24.909Z","updated":"2022-09-01T03:23:54.417Z","comments":true,"path":"report/0831/index.html","permalink":"https://pyxblog.cn/report/0831/index.html","excerpt":"","text":"摘要 文献阅读方面，本周阅读了一些有关心理疲劳的文献，了解了心理疲劳的含义、产生机制、危害、评价指标和干预手段，对经典的心理疲劳领域研究有了一定的认识 预推免准备方面： 对做过的两个项目进行复盘，调整了简历内容，在线版请见传送门，单页pdf版请见传送门 制作了获奖材料传送门和互动媒体设计的报名作品集传送门 心理疲劳 心理耗竭 主要用于描述长期高应激压力工作环境下造成的心理资源耗竭现象 , 突出表现为：情绪耗竭、失去人格（冷漠等）、缺乏成就感 精神疲劳 心理活动过程中产生的疲劳称为心理疲劳 , 即精神疲劳 , 有三种情况：感受疲劳、困欲、心理活动速度疲劳（速度疲劳） 心理厌倦 产业工人长期从事单调重复的操作性工作造成的一种心理倦怠现象 , 以工作动机下降为突出表现 , 主要体现为心理疲劳 , 与生理疲劳关系不大 心理疲劳 在高强度情况下过久地从事过于艰苦的训练所造成的一种身体状况，伴随着理想、精力和目标的逐渐丧失，是由于进行工作（运动）使工作效率降低，出现疲劳感觉及身心功能处于降低状态的现象 真性心理疲劳：伴随着由于过度训练引起的生理疲劳而出现的，是一种真实的心理上的疲劳感和无力感 假性心理疲劳 由生理疲劳以外的其它因素造成，包括常规训练竞赛因素和常规训练竞赛以外的因素。 运动性心理疲劳 由于运动员长期集中于重复性的单调且大强度训练和比赛情况下所造成的一种心理不安和疲劳感 其他定义 《心理学大词典》——心理疲劳指由于工作中紧张程度较大或由于工作过于单调而产生的疲劳，可以通过功效、主观感觉、代谢情况及其它有关的生理、心理反应来判定其程度 Theo等——心理疲劳是因脑力和体力活动过多导致的心理功能衰退 Thorndike等——无能力做一定的心理操作，与实际或感觉相匹配的无力感，即心理疲乏感和心理耗竭感 原因 环境+生理+心理 神经生理机制 长时间的工作或认知活动导致中脑多巴胺能对前有色带环绕皮层投射减少，即不能维持多巴胺能传递到纹状体和前有色带环绕皮层，由线索信息引发的大脑活动显著衰弱，从而导致心理疲劳 动机 延长工作，需要被试者增加努力以维持绩效，心理疲劳源于增加的努力与报酬不均衡，即投入和收获不成正比： 个体认为努力与充足的报酬相匹配，将继续工作 如果努力超过报酬，继续工作的动机将消失，个体想逃离工作，出现心理疲劳感 能量枯竭 工作的时间延长、单调、紧张和强度通过损伤心理能力，或者个体为维持适当工作而耗竭心理能力，引起心理疲劳 危害 降低绩效 心理疲劳时，机警水平降低[1]，对外环境刺激不敏感，反应迟钝[2]，灵活性低，容易被无关信息干扰[1]，出错率增加[3]，重复犯错，即使知道现在活动不适当，但仍然坚持以前的错误工作方法，缺乏有效、精确计划，常常不服从工作规范，工作动机不足，严重影响工作绩效[4] 为我之前提出的激励企业为骑手心理疲劳支持而付费的依据——“提高员工绩效”找到了依据 支撑文献： [1] Linden D V D , Massar S A A , Schellekens A F A , et al. Disrupted sensorimotor gating due to mental fatigue: Preliminary evidence[J]. International Journal of Psychophysiology, 2006, 62(1):168-174. [2] Murata A, Uetake A, Takasawa Y. Evaluation of mental fatigue using feature parameter extracted from event-related potential[J]. International journal of industrial ergonomics, 2005, 35(8): 761-770. [3] Kato Y, Endo H, Kizuka T. Mental fatigue and impaired response processes: event-related brain potentials in a Go/NoGo task[J]. International Journal of Psychophysiology, 2009, 72(2): 204-211. [4] Wright R A, Stewart C C, Barnett B R. Mental fatigue influence on effort-related cardiovascular response: Extension across the regulatory (inhibitory)/non-regulatory performance dimension[J]. International Journal of Psychophysiology, 2008, 69(2): 127-133. 生理影响 影响中枢神经系统和植物神经系统的功能，影响体内的物质代谢 心理影响 认知：使个体感知觉迟钝， 思维迟缓，记忆力减退，注意力不集中，注意水平减弱 情绪：易发怒 行为影响 使感觉运动通道受阻，随意控制受损而影响随意行为 评价 FSYS（青年军人疲劳量表） 由8个条目构成，1～7级评分，涵盖心理疲劳和生理疲劳2个因子，用于评定青年军人疲劳的严重程度，心理疲劳和生理疲劳各有4个条目 从探索性因素分析和验证性因素分析显示此量表具有较好的效度 同质信度0．78～o．85，折半信度0．71～o．80，故此量表有较好的信度 各条目、因子分和总分的高分组与低分组差异显著，故量表鉴别力好 HRV（心率变异性） 心理疲劳时，五个指标显著升高： standard deviation of N-N interval, SDNN 部正常N-N间期的标准差 root mean square of successive differences, RMSSD 全程相邻R-R间期之差的均方根值 standard deviation of successive differences, SDSD 全程相邻R-R间期之差的标准差 very low frequency, VLF 0.003～0.040 Hz频带范围的极低频功率 total spectral power, TP 5 min所有的功率密度 测试HRV：SPIRIT-2/4/8 无线团体多通道生物反馈仪、光体积法等 对心理疲劳测量手段有了较多了解后，深刻体会到了用手机摄像头测HRV在便捷度上带来的巨大意义。 mental fatigue visual analogue scales 精神疲劳视觉模拟评分法 advanced trail making test, ATMT 个体在计算机30min内完成3个简单的工作范式，通过完成工作范式的速度和精确性来判定心理疲劳 通过心节律信号中0.10Hz成分的光谱分析 标准0.10Hz分数偏低，预示心理努力降低，个体出现心理疲劳 脑电图 electroencephalogram，EEG 观察大脑的唤醒水平来评估心理疲劳 事件相关电位 event-related potential，ERP 心率 HR 呼吸率 RR 眨眼、瞳孔直径PPD 肌电、皮肤电阻、体温 心理测验 注意测验（eg. 划消测验） 估计测验（eg. 对时间间隔的估计） 生化测量，如肾上腺皮质激素、脱氢表睾酮水平、细胞与体液免疫机能、血糖血脂水平、血乳酸尿素氮等水平等 SCL-90量表 共有90个项目，包含有较广泛的精神症状学内容，感觉、情感、思维、意识、行为、生活习惯、人际关系、饮食睡眠等均有涉及，分为躯体化、强迫症状、人际关系敏感、抑郁、焦虑、敌对、恐怖、偏执、精神病性和其他，共10个方面。本量表采用5级评分制，按“从无”、“轻度”、“中度”、“偏重”和“严重”，分别记1～5分。量表总分超过160的，阳性项目数超过43项的，任一因子分大于或等于2的为心理健康状况筛查阳性。得分越高，表明心理疲劳程度越严重。 干预 喜情绪诱导：有效改善个体情绪状态，增加心理资源，提升心理恢复力 喜情绪：客观事物符合个体需要而产生的愉快的积极情绪。 口服咖啡、绿茶 有计划地安排工作 加强锻炼 音乐疗法 社会支持 自我接纳 培养正确的工作动机，增强工作兴趣 克服自卑，树立自信 优化和改善工作环境 运动性心理疲劳 我搜集到的有关心理疲劳的文献中，以运动性心理疲劳相关的文献居多，由于研究对象群体具有一定的特殊性（如在产生机制、干预措施等方面的特殊性），我无法判断是否应该将“运动性心理疲劳”与“心理疲劳”简单地合并，因而在本次报告中分开整理。 当然，除少量的特殊性外，在原因、危害、评价和干预几个方面，二者还是有着较大的共性。 由于长时间集中于重复性的自身单调、大强度训练和比赛的情况下所造成的一种心理不安和疲劳感。 运动心理学界对“心理疲劳”这一术语较多地引用为心理耗竭，是一种综合症，是体力和情感被耗竭、运动被贬值、运动成绩下降的综合症，若干关于它的共同点： 心理耗竭中包含一种耗竭感，包括身体的、心理的以及情感的 这种耗竭感会导致个体对他人反应的负性变化，如讥诮(cynicism)、去人性化、缺乏精力和同情心等 心理耗竭具有成就感丧失的特点，这会导致与运动成绩下降之问的恶性循环并使自尊降低进而产生退出念头 心理耗竭是对一直持续存在的压力的慢性反应，这是与剧烈压力下的偶然应激状态相区别的 运动性心理疲劳产生的原因： 个人：个性、自身能力、年龄、运动年限、参与原因、情绪、注意品质特征、自我效能、心理素质等方面导致的心理疲劳 社会：社会交往、人际关系、社会支持等方面导致的心理疲劳 训练：训练的条件、环境、恢复、营养、项目特点、教练员指导等方面导致的心理疲劳 心理疲劳不同阶段的特征如下： 阶段划分 心理疲劳 机体疲劳 早期阶段 患者会您到特续波劳，热情丧失，情绪烦躁，易怒，力不从心，精神恍惚，夜弱等。同时，族病、损伤也随之而来。 患者局部身体疼痛，肠開不适，头痛；还会出现食欲不佳，同时，会感到不可名状的沮丧和恼怒。 中期阶段 患者变得沉默嘉言、孤僻，回答向话时闷闷不乐，甚至迁怒于人。不相信自己还会获得成功。 患者身体感觉長冷、呼吸浅表、气短，十分疲倦，由于食欲反常，体重增加或成少。 后期阶段 惠者已完全丧失自信心、性情孤僻、精神恍惚、玩世不恭，以致引起别人的讨厌。 患者身体极度疲倦，无食欲．没有丝毫勇气和精力去承担面临的任务，普遍采取逃避现实的态度。 评价 运动员心理疲劳量表 POMS量表（心理状态剖面），能较好地监控运动员心理疲劳的情绪变化指标，可以用来测评运动员的心境状态、躯体形状和行为症状，并可以防止心理疲劳的出现。 马斯拉奇心理疲劳量表MBI 伊德斯运动员心理疲劳量表EABI 运动员心理疲劳问卷和运动员训练状态检测量表ABQ 闪光融合频率 心理疲劳时感觉机能下降，对闪光的分辨能力降低，闪光融合频率值普遍较低。 当测得值为 1.0-3.9 周波数每秒时，反映为轻度疲劳； 当测得值为 4.0-7.9 周波数每秒时，反映为中度疲劳 当测得值为 8.0 周波数每秒时，反映为重度疲劳 可以通过增加测量次数来获得更精确的结论 脑电图EEG 心理疲劳时反应迟钝、判断失误、注意不集中，甚至厌练并伴有神经系统症状。EEG诊断运动疲劳有 56.60%-60.00% 的阳性率。 诱发电位ERP 评价心理疲劳的客观指标，ERP 潜伏期和反应时随疲劳指数的变化趋势不一致 , 个体差异较大。 反应时 主要反映大脑神经活动的灵活性。当运动性心理疲劳产生时，其灵活性明显下降，表现为反应时延长。 选择反应时超过0.30s时，就说明有心理疲劳现 象 训练状况良好的运动员简单反应时为0.30s，疲劳时大于此值 体温测量 用温度计测量对侧肢体表面体温： 当对侧肢体表面体温之差大于 0.5 摄氏度时，反映有中度以上的疲劳产生 当体温之差大于 2 摄氏度时，反映疲劳较为严重 恢复 提供多样化的训练和生活，给予社会和人文关怀，注意营养和睡眠的有机结合 借助科学的仪器设备消除心理疲劳，如MC2StudyTM仪器通过各种大脑活动频率波的刺激来调节个体的意识状态 , 帮助其迅速进入与工作任务相适应的脑生理环境 , 如心理的放松、注意的高度集中、神经活动的激发等状态 总结 本周受到返校和预推免报名的干扰，对部分干预方法未进行详细的整理，后续如有必要，可以查找各个方法对应的原始文献进行了解学习。"}],"posts":[{"title":"scrapy爬虫实战03-爬取其他文件格式","slug":"python-spider-scrapy3","date":"2022-08-06T16:15:29.000Z","updated":"2022-08-06T16:18:39.303Z","comments":true,"path":"2022/08/07/python-spider-scrapy3/","link":"","permalink":"https://pyxblog.cn/2022/08/07/python-spider-scrapy3/","excerpt":"","text":"本次实战中，我们以图片为例，演示使用Scrapy框架爬取非文本内容的方法。 在前面两次的Scrapy框架爬虫实战中，已经对基础操作有了较为详细的解释说明，因此本次教程中的基础操作将不再过多赘述。 目标网站：传送门 爬虫编写 我们以CrawlSpider为工具进行爬取。 创建CrawlSpider爬虫 在命令行中创建爬虫： 1234cd zcoolscrapy startproject zcoolcd zcoolscrapy genspider -t crawl zcoolSpider https://www.zcool.com.cn/ 基础设置 进行一些常规化的基础设置，后续使用Scrapy框架时可以按照这样的思路直接往下进行。 创建start.py 创建start.py以实现在pycharm内运行Scrapy爬虫 12from scrapy import cmdlinecmdline.execute(&quot;scrapy crawl zcoolSpider&quot;.split(&quot; &quot;)) 关闭协议、设置ua 在settings.py中关闭那个君子协议，然后设置好自己的user-agent 1234567891011121314BOT_NAME = &#x27;zcool&#x27;SPIDER_MODULES = [&#x27;zcool.spiders&#x27;]NEWSPIDER_MODULE = &#x27;zcool.spiders&#x27;# Obey robots.txt rulesROBOTSTXT_OBEY = False# Override the default request headers:DEFAULT_REQUEST_HEADERS = &#123; &#x27;Accept&#x27;: &#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;, &#x27;Accept-Language&#x27;: &#x27;en&#x27;, &#x27;User-Agent&#x27; : &#x27;我的user-agent&#x27;&#125; 设置初始页面 设置一下zcoolSpider.py（就是爬虫文件）里的start_urls，本次实战中我们爬取的是“精选部分”，页面链接在这：传送门 123name = &#x27;zcoolSpider&#x27; allowed_domains = [&#x27;zcool.com.cn&#x27;] start_urls = [&#x27;https://www.zcool.com.cn/discover/0!3!0!0!0!!!!1!1!1&#x27;] 编写灵魂——rules规则 页码对应url 不难找到不同页码对应链接的规律： 均为https://www.zcool.com.cn/discover/0!3!0!0!0!!!!1!1!+页码的形式 规则（正则表达式）应该这样写： 1Rule(LinkExtractor(allow=r&#x27;.+0!3!0!0!0!!!!1!1!\\d+&#x27;),follow=True) 详情页 详情页的规则也很明显，均为https://www.zcool.com.cn/work/+一串字母+=.html 规则（正则表达式）应该这样写： 1Rule(LinkExtractor(allow=r&#x27;.+work/.+html&#x27;),follow=False,callback=&quot;parse_detail&quot;) 数据解析与存储 上面已经写好了rules，使crawlSpider有了自己找到每一个详情页的能力，接下来我们就处理这些详情页。 编写回调函数parse_details 由于每个详情页里都有很多张图，所以我们期望把每一页里的图放在同一个文件夹里，然后以那一页的标题为文件名，这样便于我们以后查看。因此，在回调函数中，我们需要获取的内容主要有两个：标题和图片链接 获取标题 12title = response.xpath(&quot;//div[@class=&#x27;details-contitle-box&#x27;]/h2/text()&quot;).getall() # getall返回列表title = &quot;&quot;.join(title).strip() # 用于将列表拼接并删掉首尾的空格 获取图片url 利用div标签的class属性，定位图片的链接 1image_urls = response.xpath(&quot;//div[@class=&#x27;photo-information-content&#x27;]/img/@src&quot;).getall() ps. 我们可以在插件XPath Helper中验证自己找的xpath路径是否正确，如图： 的确是可以成功获取url 编写items.py 12345import scrapyclass ZcoolItem(scrapy.Item): title = scrapy.Field() # 标题 image_urls = scrapy.Field() # 图片链接 images = scrapy.Field() # 图片本身 在zcoolSpider.py中调用items.py 12345678from ..items import ZcoolItem...class ZcoolspiderSpider(CrawlSpider): ... def parse_detail(self, response): ... item = ZcoolItem(title=title,image_urls=image_urls) return item 在setting.py中打开piplines，并编写文件存储路径 12345678import osIMAGES_STORE = os.path.join(os.path.dirname(os.path.dirname(__file__)),&#x27;images&#x27;)# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = &#123; &#x27;zcool.pipelines.ZcoolPipeline&#x27;: 300,&#125; 其中os.path.dirname的作用是获取上层文件夹路径，__file__就是只这个文件本身，os.path.join则实现了将路径拼接的作用。 编写piplines.py 12345678910111213141516171819from scrapy.pipelines.images import ImagesPipelinefrom zcool import settings # 这是想调用settings.py里写的IMAGE_STOREimport osimport re # 正则表达式库class ZcoolPipeline(ImagesPipeline): def get_media_requests(self, item, info): media_requests = super(ZcoolPipeline, self).get_media_requests(item,info) for media_request in media_requests: media_request.item = item return media_requests def file_path(self, request, response=None, info=None, *, item=None): origin_path = super(ZcoolPipeline, self).file_path(request, response, info) # 先执行一遍原函数 title = request.item[&#x27;title&#x27;] title = re.sub(r&#x27;[\\\\/:\\*\\?&quot;&lt;&gt;\\|]&#x27;,&quot;&quot;,title) # 删除非法字符 save_path = os.path.join(settings.IMAGES_STORE,title) image_name = origin_path.replace(&quot;full/&quot;,&quot;&quot;) return os.path.join(save_path,image_name) 注意到上面的title = re.sub(r'[\\\\/:\\*\\?\"&lt;&gt;\\|]',\"\",title)一句中，因为我们想用详情页的标题作为文件夹名，但文件夹名中不可以出现这些字符：\\ / : * ? \" &lt; &gt; |，因此我们要用正则表达式的方法，把标题中的这些字符删除。 至此，我们编写完了本次实战的爬虫，运行可得结果如下： 最终代码参考： zcoolSpider.py 123456789101112131415161718192021import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Rulefrom ..items import ZcoolItemclass ZcoolspiderSpider(CrawlSpider): name = &#x27;zcoolSpider&#x27; allowed_domains = [&#x27;zcool.com.cn&#x27;] start_urls = [&#x27;https://www.zcool.com.cn/discover/0!3!0!0!0!!!!1!1!1&#x27;] rules = ( Rule(LinkExtractor(allow=r&#x27;.+0!3!0!0!0!!!!1!1!\\d+&#x27;),follow=True), Rule(LinkExtractor(allow=r&#x27;.+work/.+html&#x27;),follow=False,callback=&quot;parse_detail&quot;) ) def parse_detail(self, response): image_urls = response.xpath(&quot;//div[@class=&#x27;photo-information-content&#x27;]/img/@src&quot;).getall() title = response.xpath(&quot;//div[@class=&#x27;details-contitle-box&#x27;]/h2/text()&quot;).getall() title = &quot;&quot;.join(title).strip() item = ZcoolItem(title=title,image_urls=image_urls) return item items.py 12345import scrapyclass ZcoolItem(scrapy.Item): title = scrapy.Field() image_urls = scrapy.Field() images = scrapy.Field() piplines.py 123456789101112131415161718from scrapy.pipelines.images import ImagesPipelinefrom zcool import settingsimport osimport reclass ZcoolPipeline(ImagesPipeline): def get_media_requests(self, item, info): media_requests = super(ZcoolPipeline, self).get_media_requests(item,info) for media_request in media_requests: media_request.item = item return media_requests def file_path(self, request, response=None, info=None, *, item=None): origin_path = super(ZcoolPipeline, self).file_path(request, response, info) # 先执行一遍原函数 title = request.item[&#x27;title&#x27;] title = re.sub(r&#x27;[\\\\/:\\*\\?&quot;&lt;&gt;\\|]&#x27;,&quot;&quot;,title) save_path = os.path.join(settings.IMAGES_STORE,title) image_name = origin_path.replace(&quot;full/&quot;,&quot;&quot;) return os.path.join(save_path,image_name) settings.py 123456789101112131415161718192021222324252627BOT_NAME = &#x27;zcool&#x27;SPIDER_MODULES = [&#x27;zcool.spiders&#x27;]NEWSPIDER_MODULE = &#x27;zcool.spiders&#x27;# Obey robots.txt rulesROBOTSTXT_OBEY = False# Override the default request headers:DEFAULT_REQUEST_HEADERS = &#123; &#x27;Accept&#x27;: &#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;, &#x27;Accept-Language&#x27;: &#x27;en&#x27;, &#x27;User-Agent&#x27; : &#x27;我的user-agent&#x27;&#125;# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = &#123; &#x27;zcool.pipelines.ZcoolPipeline&#x27;: 300,&#125;import osIMAGES_STORE = os.path.join(os.path.dirname(os.path.dirname(__file__)),&#x27;images&#x27;)","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/"},{"name":"实战","slug":"爬虫/实战","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/tags/%E7%88%AC%E8%99%AB/"},{"name":"scrapy","slug":"scrapy","permalink":"https://pyxblog.cn/tags/scrapy/"}]},{"title":"scrapy爬虫实战02-CrawlSpider入门","slug":"python-spider-scrapy2","date":"2022-08-06T16:12:29.000Z","updated":"2022-08-06T16:16:02.052Z","comments":true,"path":"2022/08/07/python-spider-scrapy2/","link":"","permalink":"https://pyxblog.cn/2022/08/07/python-spider-scrapy2/","excerpt":"","text":"目标网站：传送门 CrawlSpider爬虫的创建 为什么要有CrawlSpider爬虫 spider是Scrapy框架中的基础爬虫，在翻页的时候，我们是这样操作的： 123456# 获取下一页next_href = response.xpath(\"//a[@id='amore']/@href\").get()if next_href: next_url = response.urljoin(next_href) request = scrapy.Request(next_url) yield request 而比spider高级一点的CrawlSpider爬虫，其主要特色是不用手动yield，可以实现遇到指定URL后自动翻页，这就比spider方便一些。 创建CrawlSpider爬虫的命令： 1scrapy genspider -t crawl [爬虫名字] [域名] 参考上面的创建流程，我们在终端中输入下面四行代码： 12345cd /Users/pangyuxuan/lyCrawlSpider # cd到文件夹lyCrawlSpiderscrapy startproject lycs # 创建Scrapy项目，项目名称为lycscd lycs # 进入项目路径scrapy genspider -t crawl lycSpider https://www.lieyunwang.com/ # 创建crawl爬虫，爬虫名称为lycSpider，目标域名为https://www.lieyunwang.com/ 得到了这样的爬虫文件： 与spider的区别——“规则”的定义 spiders文件夹中的lycSpider.py与基础案例中的gsw_spider.py相对应，其默认的代码如下： 123456789101112131415161718192021import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Ruleclass LycspiderSpider(CrawlSpider): name = 'lycSpider' # 没变 allowed_domains = ['https://www.lieyunwang.com/'] # 没变 start_urls = ['http://https://www.lieyunwang.com//'] # 没变 rules = ( # 满足rules时自动爬取，不用再手动yield Rule(LinkExtractor(allow=r'Items/'), callback='parse_item', follow=True), ) def parse_item(self, response): item = {} #item['domain_id'] = response.xpath('//input[@id=\"sid\"]/@value').get() #item['name'] = response.xpath('//div[@id=\"name\"]').get() #item['description'] = response.xpath('//div[@id=\"description\"]').get() return item 其中： LinkExtractor 使用LinkExtractor可以在页面中自动找到所有满足规则的url，实现自动的爬取。 1class scrapy.linkextractors.LinkExtractor(allow = (),deny = (),allow_domains = (),deny_domains = (),deny_extensions = None,restrict_xpaths = (),tags = ('a','area'),attrs = ('href'),canonicalize = True,unique = True,process_value = None) 常用参数： allow ：允许的url——所有满足这个正则表达式的url都会被提取。 deny ：禁止的url——所有满足这个正则表达式的url都不会被提取。 allow_domains ：允许的域名——只有在这个里面指定的域名的url才会被提取。 deny_domains ：禁止的域名——所有在这个里面指定的域名的url都不会被提取。 restrict_xpaths ：使用xpath——和allow共同过滤链接。 Rule 用来定义这个url爬取后的处理方式，比如是否需要跟进，是否需要执行回调函数等。 1class scrapy.spiders.Rule(link_extractor, callback = None, cb_kwargs = None, follow = None,process_links = None, process_request = None) 常用参数： link_extractor ：一个LinkExtractor对象，用于定义爬取规则 callback ：满足这个规则的url，应该要执行哪个回调函数。 follow ：指定根据该规则从response中提取的链接是否需要跟进，也就是需不需要找这个链接的页面里还有没有其他符合要求的链接 process_links ：从link_extractor中获取到链接后会传递给这个函数，用来过滤不需要爬取的链接 实操 先在settings.py里关闭协议、设置ua 123456789# Obey robots.txt rulesROBOTSTXT_OBEY = False# Override the default request headers:DEFAULT_REQUEST_HEADERS = { 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en', 'User-Agent' : '我的user-'} 我们打开猎云网主页https://www.lieyunwang.com/ 调整start_urls 在页码1处点击检查，点击下方的链接进入第一页，复制此时浏览器内的链接即可： 1start_urls = ['https://www.lieyunwang.com/latest/p1.html'] 编写rules 我们的思路是： 找到每一页的链接，再从每一页里找每一篇文章的链接。 规则应该是这样： 1234rules = ( Rule(LinkExtractor(allow=r'/latest/p\\d+\\.html'), follow=True), Rule(LinkExtractor(allow=r'/archives/\\d+'), callback=\"parse_detail\", follow=False), ) 其中： 第一条规则用于找到每一页，因为页面的格式都是这样： 所以使用正则表达式匹配字符，即为/latest/p\\d+\\.html，其中： 页码可能是两位数，所以用d+ .是特殊符号，需要额外加一个反斜杠\\ 此外，找到每一页并不是终点，我们还需要找这一页里的文章，也就是还需要从这一页里面找其他链接，所以follow=True 第二条规则用于找每一页里的所有文章，因为文章的格式都是这样： 所以我们的正则表达式写为/archives/\\d+ 此外，我们找到文章以后，并不需要通过该文章找其他文章，所以follow=False，另外我们需要调用函数来获取它的内容了，所以callback=\"parse_detail\"，其中parse_detail是后面要写的函数 在parse_detail函数里测试一下我们的rules写没写对： 1234567891011121314151617181920import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Ruleclass LycspiderSpider(CrawlSpider): name = 'lycSpider' allowed_domains = ['lieyunwang.com'] start_urls = ['https://www.lieyunwang.com/latest/p1.html'] rules = ( Rule(LinkExtractor(allow=r'/latest/p\\d+\\.html'), follow=True), Rule(LinkExtractor(allow=r'/archives/\\d+'), callback=\"parse_detail\", follow=False), ) def parse_detail(self, response): print(\"=\"*50) print(response.url) # 输出找到的url来验证 print(\"=\"*50) 哈哈对了！不对我会写在博客里吗 ps. 运行方法与前面的运行方法一致，都是新建一个start.py文件，可以先跳到后面去看一下start.py文件怎么写，也可以省略这一步测试（反正它一定是对的就是了，哼） 数据解析与存储 方便起见，我们只爬取文章的标题title、导语conclude和段落内容content 数据解析和存储的方式与之前的完全一样，在这里直接给出操作流程，不做过多的赘述： 1. 使用xpath获取三个部分的内容 直接右键-检查-copy xpath即可 1234567def parse_detail(self, response): title = response.xpath('//*[@id=\"fixed_container\"]/div[1]/div[2]/div[1]/h1/text()').getall() title = \"\".join(title).strip() content = response.xpath('//*[@id=\"main-text-id\"]').getall() content = \"\".join(content).strip() conclude = response.xpath('//*[@id=\"fixed_container\"]/div[1]/div[2]/div[3]').getall() conclude = \"\".join(conclude).strip() 2. 在settings.py中解除piplines的注释 12345# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = { 'lycs.pipelines.LycsPipeline': 300,} 3. 编写piplines.py 12345678910111213from itemadapter import ItemAdapterimport jsonclass LycsPipeline: def open_spider(self,spider): self.fp = open(\"简讯.txt\",'w',encoding='utf-8') def process_item(self, item, spider): self.fp.write(json.dumps(dict(item),ensure_ascii=False)+'\\n') return item def close_spider(self,spider): self.fp.close() 4. 编写items.py 12345import scrapyclass LycsItem(scrapy.Item): title = scrapy.Field() # 标题 content = scrapy.Field() # 导语 conclude = scrapy.Field() # 结论 5. 在lycSPider.py里导入items并传入要保存的参数 1234567... # 省略其他部分代码from ..items import LycsItem... # 省略其他部分代码 def parse_detail(self, response): ... # 省略其他部分代码 item = LycsItem(title=title,content=content,conclude=conclude) return item # 写yield应该也可以 运行 CrawlSpider的运行与spider完全一样，都是在终端输入命令以运行，方便起见，我们还是编写start.py文件来实现在pycharm里的运行： 12from scrapy import cmdlinecmdline.execute(\"scrapy crawl lycSpider\".split(\" \")) ps. 为了秀一把这里给出了另一种发送命令的方式，本质上与之前那一种是一样的。 直接成功！ 总结 相比于spider，CrawlSpider的核心优势就是可以自己找新的页面，不用我们手动设置翻页方法。 最终的参考代码 lycSpider.py 123456789101112131415161718192021222324import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Rulefrom ..items import LycsItemclass LycspiderSpider(CrawlSpider): name = 'lycSpider' allowed_domains = ['lieyunwang.com'] start_urls = ['https://www.lieyunwang.com/latest/p1.html'] rules = ( Rule(LinkExtractor(allow=r'/latest/p\\d+\\.html'), follow=True), Rule(LinkExtractor(allow=r'/archives/\\d+'), callback=\"parse_detail\", follow=False), ) def parse_detail(self, response): title = response.xpath('//*[@id=\"fixed_container\"]/div[1]/div[2]/div[1]/h1/text()').getall() title = \"\".join(title).strip() content = response.xpath('//*[@id=\"main-text-id\"]').getall() content = \"\".join(content).strip() conclude = response.xpath('//*[@id=\"fixed_container\"]/div[1]/div[2]/div[3]').getall() conclude = \"\".join(conclude).strip() item = LycsItem(title=title,content=content,conclude=conclude) return item items.py 12345import scrapyclass LycsItem(scrapy.Item): title = scrapy.Field() content = scrapy.Field() conclude = scrapy.Field() piplines.py 1234567891011from itemadapter import ItemAdapterimport jsonclass LycsPipeline: def open_spider(self,spider): self.fp = open(\"简讯.txt\",'w',encoding='utf-8') def process_item(self, item, spider): self.fp.write(json.dumps(dict(item),ensure_ascii=False)+'\\n') return item def close_spider(self,spider): self.fp.close() settings.py 123456789101112131415161718192021222324252627BOT_NAME = 'lycs'SPIDER_MODULES = ['lycs.spiders']NEWSPIDER_MODULE = 'lycs.spiders'# Obey robots.txt rulesROBOTSTXT_OBEY = False# Override the default request headers:DEFAULT_REQUEST_HEADERS = { 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en', 'User-Agent' : '我的user-agent'}# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = { 'lycs.pipelines.LycsPipeline': 300,}# Override the default request headers:DEFAULT_REQUEST_HEADERS = { 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en', 'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36'}","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/"},{"name":"实战","slug":"爬虫/实战","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/tags/%E7%88%AC%E8%99%AB/"},{"name":"scrapy","slug":"scrapy","permalink":"https://pyxblog.cn/tags/scrapy/"}]},{"title":"Scrapy爬虫实战01-古诗文网","slug":"python-spider-scrapy1","date":"2022-08-06T16:06:53.000Z","updated":"2022-08-06T16:12:16.581Z","comments":true,"path":"2022/08/07/python-spider-scrapy1/","link":"","permalink":"https://pyxblog.cn/2022/08/07/python-spider-scrapy1/","excerpt":"","text":"ps. 案例制作时的操作环境是MacOS，如果是windows用户，下文中提到的“终端”指的就是cmd命令行窗口。 pps. 本文省略了安装过程，尚未安装scrapy的用户可以直接在pycharm的preference内搜索安装。 目标网站：传送门 任务：使用Scrapy框架爬虫，爬取“推荐”中共10页的古诗题目、作者、朝代和内容 ps. 各类教程都拿它举例子，古诗文网好惨 项目创建 创建Scrapy爬虫项目需要在终端中进行 先打开一个文件路径，即你希望的爬虫文件存放路径，比如我放在创建好的spidertest 文件夹中： 1cd /Users/pangyuxuan/spidertest # 这是文件夹路径 使用命令创建项目： 1scrapy startproject [项目名称] 创建爬虫： 12cd [项目名称] # 先进入项目路径scrapy genspider [爬虫名称] [目标域名] # 再创建爬虫文件 至此你已经创建好了scrapy爬虫文件，它应该长这样： 其中[项目名称]为gsw_test，[爬虫名称]为gsw_spider 综上，创建一个基本的scrapy爬虫文件，一共在终端的命令行中输入了4行代码： 12345cd /Users/pangyuxuan/spidertest # 打开一个文件路径，作为爬虫的存放路径scrapy startproject gsw_test # 创建scrapy项目，名为gsw_testcd gsw_test # 打开项目路径scrapy genspider gsw_spider https://www.gushiwen.org # 创建scrapy爬虫，爬虫名为gsw_spider，目标域名为 https://www.gushiwen.org 各个文件的作用 后续的编写还是依赖pycharm，所以在pycharm中打开项目文件： 其中各个文件的作用如下： settings.py：用来配置爬虫的，比如设置User-Agent、下载延时、ip代理。 middlewares.py：用来定义中间件。 items.py：用来提前定义好需要下载的数据字段。 pipelines.py：用来保存数据。 scrapy.cfg：用来配置项目。 爬取第一页的内容并保存 以下内容请按顺序阅读并实现 设置settings.py 先在settings.py中做两项工作： 设置robots.txt协议为“不遵守” robots.txt是一个互联网爬虫许可协议，默认是True（遵守协议），如果遵守的话大部分网站都无法进行爬取，所以先把这个协议的状态设为不遵守 12# Obey robots.txt rulesROBOTSTXT_OBEY = False ps. 所以这个协议的意义是什么。。。 配置请求头（设置user-agent） 123456# Override the default request headers:DEFAULT_REQUEST_HEADERS = &#123; &#x27;Accept&#x27;: &#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;, &#x27;Accept-Language&#x27;: &#x27;en&#x27;, &#x27;user-agent&#x27; : &#x27;我自己的ua&#x27;&#125; 主要工作——编写gsw_spider.py 123456789import scrapyclass GswSpiderSpider(scrapy.Spider): # 我们的代码都写在这个类里面 name = &#x27;gsw_spider&#x27; # 爬虫的名字 allowed_domains = [&#x27;https://www.gushiwen.org&#x27;] # 目标域名 start_urls = [&#x27;http://https://www.gushiwen.org/&#x27;] # 爬虫的起始网页 def parse(self, response): 目前的爬虫起始网页start_urls是自动生成的，我们把它换成古诗文网的第一页 1start_urls = [&#x27;https://www.gushiwen.cn/default_1.aspx&#x27;] 为了使打印出来的结果更加直观，我们编写myprint函数如下： 1234def myprint(self,value): print(&quot;=&quot;*30) # 在输出内容的上、下加一些&#x27;=&#x27;，找起来方便 print(value) print(&quot;=&quot;*30) 然后我们尝试打印一下当前爬取到的内容，应该为古诗文网第一页的信息。 目前为止，gsw_spider.py被改成了这样： 12345678910111213141516import scrapyclass GswSpiderSpider(scrapy.Spider): name = &#x27;gsw_spider&#x27; # 爬虫的名字 allowed_domains = [&#x27;https://www.gushiwen.org&#x27;] # 目标域名 start_urls = [&#x27;https://www.gushiwen.cn/default_1.aspx&#x27;] # 起始页面 def myprint(self,value): print(&quot;=&quot;*30) print(value) print(&quot;=&quot;*30) def parse(self, response): self.myprint(response.text) # 打印网页源代码 运行的方法 scrapy爬虫需要在终端里输入命令来运行，输入命令如下： 1scrapy crawl gsw_spider # gsw_spider是爬虫名 方便起见，我们在项目目录里新建一个start.py，通过cmdline库里的函数来向终端发送命令，这样就不用不停地切换窗口了，而且运行结果可以在pycharm里直接展现，这样就与我们之前学的爬虫一样了。 后续我们无论修改哪个代码，都是运行start.py这个文件。 123from scrapy import cmdlinecmds = [&#x27;scrapy&#x27;,&#x27;crawl&#x27;,&#x27;gsw_spider&#x27;] # 拼接命令语句cmdline.execute(cmds) # 执行 点击运行，可以在运行窗口中看到结果： 截至目前为止，我们已经获取了网页源代码，接下来的工作就是从源代码中解析想要的数据了。 无需导入新的库，Scrapy框架为我们内置了许多函数，使我们仍可以用之前学习的数据解析知识（xpath、bs4和正则表达式）来完成数据提取。 使用xpath提取数据 使用xpath语法提取数据，返回的结果是选择器列表类型SelectorList，选择器列表里包含很多选择器Selector，即： response.xpath返回的是SelectorList对象 SelectorList存储的是Selector对象 我们获取一下所有包含古诗标题的标签，输出返回值类型，以验证上面的结论： 12345def parse(self, response): gsw_divs = response.xpath(&quot;//div[@class=&#x27;left&#x27;]/div[@class=&#x27;sons&#x27;]&quot;) self.myprint(type(gsw_divs)) # 打印获取到的div标签集的类型 for gsw_div in gsw_divs : self.myprint(type(gsw_div)) # 打印标签集中的每个元素的类型 运行结果： 使用get()或getall()函数从选择器类型的数据中提取需要的数据： get()返回选择器的第一个值（字符串类型） getall()返回选择器的所有值（列表类型） 12345for gsw_div in gsw_divs : title_get = gsw_div.xpath(&quot;.//b/text()&quot;).get() title_getall = gsw_div.xpath(&quot;.//b/text()&quot;).getall() self.myprint(title_get) # 打印get函数的结果 self.myprint(title_getall) # 打印getall函数的结果 输出： 我们共提取标题、朝代、作者、内容四部分信息，gsw_spider.py代码如下： 1234567891011121314151617181920212223242526import scrapyclass GswSpiderSpider(scrapy.Spider): name = &#x27;gsw_spider&#x27; # 爬虫的名字 allowed_domains = [&#x27;https://www.gushiwen.org&#x27;] # 目标域名 start_urls = [&#x27;https://www.gushiwen.cn/default_1.aspx&#x27;] # 起始页面 def myprint(self,value): # 用于打印的函数 print(&quot;=&quot;*30) print(value) print(&quot;=&quot;*30) def parse(self, response): gsw_divs = response.xpath(&quot;//div[@class=&#x27;left&#x27;]/div[@class=&#x27;sons&#x27;]&quot;) for gsw_div in gsw_divs : title = gsw_div.xpath(&quot;.//b/text()&quot;).get() # 题目 source = gsw_div.xpath(&quot;.//p[@class=&#x27;source&#x27;]/a/text()&quot;).getall() # 朝代+作者 # source是getall函数的返回值，是个列表，故可以直接用下标调用 dynasty = source[0] # 朝代 writer = source[1] # 作者 self.myprint(source) content = gsw_div.xpath(&quot;.//div[@class=&#x27;contson&#x27;]//text()&quot;).getall() # 诗文内容 # 用//text()获取标签下的所有文本 content = &#x27;&#x27;.join(content).strip() # 将列表拼接,并用strip()删除前后的换行/空格 你可以在任意地方插入self.myprint(内容)来进行打印，以验证数据是否被成功提取 接下来就是保存数据，我们先在items.py中配置好要保存的数据有哪些。 配置items.py 还记得这个文件是干什么用的吗？ items.py：用来提前定义好需要下载的数据字段。 一共有上述四部分内容需要保存，因此我们的items.py应该这样写： 1234567import scrapyclass GswTestItem(scrapy.Item): title = scrapy.Field() # 标题 dynasty = scrapy.Field() # 朝代 writer = scrapy.Field() # 作者 content = scrapy.Field() # 内容 其中Field()可以理解为一种普适的变量类型，不管是字符串还是列表，都用scrapy.Field()来接收。 在gsw_spider.py里导入items 定义完items.py后，我们在gsw_spiders.py里导入它。需要注意的是，gsw_spiders.py在spiders文件夹里，也就是说items.py在gsw_spiders.py的上层目录中： 因此导入时，应该这样写： 1from ..items import GswTestItem # ..表示上层目录 导入后，我们将对应参数传入，然后使用yield关键字进行返回 12item = GswTestItem(title=title,dynasty=dynasty,writer=writer,content=content)yield item 进入pipelines.py和settings.py 先在settings.py里把pipelines.py打开： 123456# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = &#123; &#x27;gsw_test.pipelines.GswTestPipeline&#x27;: 300, # 300是这个pipeline的优先级，代表了执行顺序，数值越小优先级越大&#125; 再编写pipelines.py 123456789101112131415161718from itemadapter import ItemAdapterimport json # 记得自己导入json库class GswTestPipeline: def open_spider(self,spider): self.fp = open(&quot;古诗文.txt&quot;,&#x27;w&#x27;,encoding=&#x27;utf-8&#x27;) # 制定文件名和编码格式 def process_item(self, item, spider): self.fp.write(json.dumps(dict(item),ensure_ascii=False)+&#x27;\\n&#x27;) # dict函数将item转化为字典 # json.dumps()将字典格式的item转换为json字段 # 参数ensure_ascii=False,用于存储中文 # +&#x27;\\n&#x27;用于将保存的内容自动换行 return item def close_spider(self,spider): # 关闭文件 self.fp.close() 上面的open_spider函数和close_spider函数虽然不是自带的，但它是一种模版化的函数（套路），是一种Scrapy框架提供的高效的文件存储形式。 我们自己写的时候，只要按上述样式编（默）写即可，根据自己的需求修改存储文件的文件名、格式和编码方式，但不能改变两个函数名！ 现在我们运行start.py，就会发现路径下多了一个古诗文.txt，打开以后是这样： 至此，第一页爬取成功！（不要在意为什么只爬了一点就结束了，先往下看，最后会有修正） 爬取后续内容 爬取了第一页的内容以后，我们还需要继续往后寻找，先来找一下第二页的url： 右键检查“下一页”按钮以获取下一页的url 为了测试寻找下一页的功能，我们暂时忽略之前的代码 1234def parse(self, response): next_href = response.xpath(&quot;//a[@id=&#x27;amore&#x27;]/@href&quot;).get() # 获取href属性 next_url = response.urljoin(next_href) # 给/default_2.aspx添加前缀域名使其变完整 self.myprint(next_url) # 输出以验证 找到了！ 接下来我们就用一个request来接收scrapy.Request(next_url)的返回值，并使用yield关键字来返回即可： 1234next_href = response.xpath(&quot;//a[@id=&#x27;amore&#x27;]/@href&quot;).get()next_url = response.urljoin(next_href)request = scrapy.Request(next_url)yield request 需要注意的是，我们需要给“寻找下一页”操作设立一个终止条件，当下一页不存在的时候停止访问，所以最后的代码长这个样子： 123456# 获取下一页next_href = response.xpath(&quot;//a[@id=&#x27;amore&#x27;]/@href&quot;).get()if next_href: next_url = response.urljoin(next_href) request = scrapy.Request(next_url) yield request 针对反爬虫机制的修改完善 此时我们的代码是这样的： gsw_spider.py 123456789101112131415161718192021222324252627282930313233import scrapyfrom ..items import GswTestItemclass GswSpiderSpider(scrapy.Spider): name = &#x27;gsw_spider&#x27; # 爬虫的名字 allowed_domains = [&#x27;https://www.gushiwen.org&#x27;] # 目标域名 start_urls = [&#x27;https://www.gushiwen.cn/default_1.aspx&#x27;] def myprint(self,value): print(&quot;=&quot;*30) print(value) print(&quot;=&quot;*30) def parse(self, response): gsw_divs = response.xpath(&quot;//div[@class=&#x27;left&#x27;]/div[@class=&#x27;sons&#x27;]&quot;) for gsw_div in gsw_divs : title = gsw_div.xpath(&quot;.//b/text()&quot;).get() # 古诗题目 source = gsw_div.xpath(&quot;.//p[@class=&#x27;source&#x27;]/a/text()&quot;).getall() # 朝代+作者 # source是getall函数的返回值，是个列表，直接用下标调用 dynasty = source[0] # 朝代 writer = source[1] # 作者 content = gsw_div.xpath(&quot;.//div[@class=&#x27;contson&#x27;]//text()&quot;).getall() # 诗文内容 # 用//text()获取标签下的所有文本 content = &#x27;&#x27;.join(content).strip() # 将列表拼接,并用strip()删除前后的换行/空格 item = GswTestItem(title=title,dynasty=dynasty,writer=writer,content=content) yield item # 获取下一页 next_href = response.xpath(&quot;//a[@id=&#x27;amore&#x27;]/@href&quot;).get() if next_href: next_url = response.urljoin(next_href) request = scrapy.Request(next_url) yield request 运行后，会报这样一个错误：IndexError: list index out of range，意思是“列表的下标索引超过最大区间”。 为什么会有这样的错误呢？ 我们可以在网页上看到，页面上不全是古诗文： 除了古诗文外，这种短句子也是在class=sons的标签下，按照我们的查找方式： 123gsw_divs = response.xpath(&quot;//div[@class=&#x27;left&#x27;]/div[@class=&#x27;sons&#x27;]&quot;)for gsw_div in gsw_divs : source = gsw_div.xpath(&quot;.//p[@class=&#x27;source&#x27;]/a/text()&quot;).getall() 找到图中蓝色的div标签以后，它里面是没有p标签的，也就是说此时的source是个空表，直接调用source[0]那必然是要报错的。 这算是网站的一种反爬虫机制，利用格式不完全相同的网页结构来让你的爬虫报错，太狠了！！ 为了解决这个问题，我们添加try...except结构如下： 123456789101112for gsw_div in gsw_divs : title = gsw_div.xpath(&quot;.//b/text()&quot;).get() source = gsw_div.xpath(&quot;.//p[@class=&#x27;source&#x27;]/a/text()&quot;).getall() try: dynasty = source[0] writer = source[1] content = gsw_div.xpath(&quot;.//div[@class=&#x27;contson&#x27;]//text()&quot;).getall() content = &#x27;&#x27;.join(content).strip() item = GswTestItem(title=title,dynasty=dynasty,writer=writer,content=content) yield item except: print(title) # 打印出错的标题以备检查 这样，上面的报错就被完美解决了。 然鹅，一波未平一波又起，bug永远是生生不息源源不绝的 我们发现了一个新的报错：DEBUG: Filtered offsite request to 'www.gushiwen.cn': &lt;GET https://www.gushiwen.cn/default_2.aspx&gt; 这是因为我们在最开始的allowed_domains里限制了访问的域名：\"https://www.gushiwen.org\" 而到了第二页的时候，网站偷偷把域名换成.cn了！ .cn不是.org，我们的爬虫没法继续访问，所以就停了。这又是这个网站的一个反爬虫机制，我们只需要在allowed_domains里添加一个.cn的域名，这个问题就可以得到妥善的解决： 1allowed_domains = [&#x27;gushiwen.org&#x27;,&#x27;gushiwen.cn&#x27;] 运行可得到期望结果： 最终的古诗文网Scrapy爬虫代码 gsw_spider.py 12345678910111213141516171819202122232425262728293031323334353637import scrapyfrom ..items import GswTestItemclass GswSpiderSpider(scrapy.Spider): name = &#x27;gsw_spider&#x27; # 爬虫的名字 # allowed_domains = [&#x27;https://www.gushiwen.org&#x27;] # 目标域名 allowed_domains = [&#x27;gushiwen.org&#x27;,&#x27;gushiwen.cn&#x27;] start_urls = [&#x27;https://www.gushiwen.cn/default_1.aspx&#x27;] def myprint(self,value): print(&quot;=&quot;*30) print(value) print(&quot;=&quot;*30) def parse(self, response): gsw_divs = response.xpath(&quot;//div[@class=&#x27;left&#x27;]/div[@class=&#x27;sons&#x27;]&quot;) for gsw_div in gsw_divs : title = gsw_div.xpath(&quot;.//b/text()&quot;).get() # 古诗题目 source = gsw_div.xpath(&quot;.//p[@class=&#x27;source&#x27;]/a/text()&quot;).getall() # 朝代+作者 # source是getall函数的返回值，是个列表，直接用下标调用 try: dynasty = source[0] # 朝代 writer = source[1] # 作者 content = gsw_div.xpath(&quot;.//div[@class=&#x27;contson&#x27;]//text()&quot;).getall() # 诗文内容 # 用//text()获取标签下的所有文本 content = &#x27;&#x27;.join(content).strip() # 将列表拼接,并用strip()删除前后的换行/空格 item = GswTestItem(title=title,dynasty=dynasty,writer=writer,content=content) yield item except: print(title) # 获取下一页 next_href = response.xpath(&quot;//a[@id=&#x27;amore&#x27;]/@href&quot;).get() if next_href: next_url = response.urljoin(next_href) request = scrapy.Request(next_url) yield request items.py 123456789101112131415# Define here the models for your scraped items## See documentation in:# https://docs.scrapy.org/en/latest/topics/items.htmlimport scrapyclass GswTestItem(scrapy.Item): # define the fields for your item here like: title = scrapy.Field() dynasty = scrapy.Field() writer = scrapy.Field() content = scrapy.Field() pipelines.py 12345678910111213from itemadapter import ItemAdapterimport jsonclass GswTestPipeline: def open_spider(self,spider): self.fp = open(&quot;古诗文.txt&quot;,&#x27;w&#x27;,encoding=&#x27;utf-8&#x27;) def process_item(self, item, spider): self.fp.write(json.dumps(dict(item),ensure_ascii=False)+&#x27;\\n&#x27;) # dict函数将item转化为字典,再转换为json字段进行保存 return item def close_spider(self,spider): self.fp.close() settings.py 为了看起来简洁一点，注释部分我就都删了 123456789101112131415161718192021BOT_NAME = &#x27;gsw_test&#x27;SPIDER_MODULES = [&#x27;gsw_test.spiders&#x27;]NEWSPIDER_MODULE = &#x27;gsw_test.spiders&#x27;# Obey robots.txt rulesROBOTSTXT_OBEY = False# Override the default request headers:DEFAULT_REQUEST_HEADERS = &#123; &#x27;Accept&#x27;: &#x27;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#x27;, &#x27;Accept-Language&#x27;: &#x27;en&#x27;, &#x27;user-agent&#x27; : &#x27;我的user-agent&#x27;&#125;# Configure item pipelines# See https://docs.scrapy.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = &#123; &#x27;gsw_test.pipelines.GswTestPipeline&#x27;: 300,&#125; 大功告成！自己试一下吧！","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/"},{"name":"实战","slug":"爬虫/实战","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/tags/%E7%88%AC%E8%99%AB/"},{"name":"scrapy","slug":"scrapy","permalink":"https://pyxblog.cn/tags/scrapy/"}]},{"title":"python爬虫实战演示","slug":"python-spider-demo1","date":"2022-08-06T15:56:53.000Z","updated":"2022-08-06T16:06:17.936Z","comments":true,"path":"2022/08/06/python-spider-demo1/","link":"","permalink":"https://pyxblog.cn/2022/08/06/python-spider-demo1/","excerpt":"","text":"猫眼专业版实时票房数据获取 网址：http://piaofang.maoyan.com/dashboard 错误方法1： 1234import requestsurl = &#x27;http://piaofang.maoyan.com/dashboard&#x27;resp = requests.get(url)print(resp.content.decode(&#x27;utf-8&#x27;)) 点开“检查网页源代码”，发现输出和源代码不一样 问题出在请求头上，连User-agent都没有，稍微走点心的网站都知道你是爬虫了 Ps.user-agent是什么：user-agent会告诉网站，访问者是通过什么工具来请求的，如果是爬虫请求，一般会拒绝；如果是用户浏览器，就会应答。我们在浏览器里获取的user-agent添加到爬虫中，网站检测这项数据时会把它当成你自己用的那个浏览器，以起到瞒天过海的作用。 错误方法2： 1234567import requestsurl = &#x27;http://piaofang.maoyan.com/dashboard&#x27;headers = &#123; # 添加一个请求头 &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36&#x27;&#125;resp = requests.get(url,headers=headers)print(resp.content.decode(&#x27;utf-8&#x27;)) 这下输出和网页源代码一样了，兴高采烈找数据，发现没有！ 原来是因为猫眼专业版的数据是实时更新的，因此它没有保存在静态的网页结构里，而是通过json文件实时发送，所以我们在网页源代码中是找不到数据的，数据在哪呢？ 点开“检查”，在Network里你会发现，网页在不停的请求文件，选中右边的Response，仔细一找，数据就在里面！ 当然，如果你觉得麻烦，这里推荐一个格式解析工具，可以自动把json文件里的代码以更美观的角度呈现。 在线的json解析工具：https://www.json.cn/ 所以，我们请求静态网页的链接，是找不到数据的，而把链接换成发送数据包的链接，就可以得到数据了。 正确方法： 12345678910import requests# 使用json文件里的urlurl = &#x27;http://piaofang.maoyan.com/dashboard-ajax?orderType=0&amp;uuid=176e6479baec8-0cc8072b9a3fd4-171d4b58-13c680-176e6479bafc8&amp;riskLevel=71&amp;optimusCode=10&amp;_token=eJxNkctqw0AMRf9l1sKRRvOyIYtAoaTQRUPaTchi8qgTSuLgmNJS%2Bu%2BVJi4tGO7x1cOS%2FGX6%2Bc40COZ935vGUIVVMGCGq2koEHmk6DlhALP98yySxTqC2fQvd6ZZEXECcdbqLMRYkXMINeIa%2FiGjPJozlxRzGIZLM5lcjrl7zee2OuXuM5%2BrbXea7PL1sOlyv5NJjBScllrAkQHF4RiBVJP0K8rgiyZIqjVDXTQBWQGHDigUiCNQDVZ7OGtHYAZbQhxGcBG4hLwF5gI1cAkFcaJCRHDlEzrDDTz4kixTeB3DI0PkAgGiVnkrB7mBBULdyTMBldG8XIvYKXnxSi8fZIGou%2Fmoh056lDc9imgedfh9f5T%2FKKnXY3sW2j98LJ%2Fb%2BWx2384WT9Op%2Bf4B3HBuKQ%3D%3D&#x27;headers = &#123; &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36&#x27;&#125;resp = requests.get(url,headers=headers)print(resp.content.decode(&#x27;utf-8&#x27;)) 一些其他的动态网页，可能并不是实时更新，但也是采用同样的数据显示方式，这就需要你仔细的找一下数据到底藏在哪个文件里，点开Response后从上往下捋就行了。 当然你也可以使用selenium方法去模拟浏览器的行为，在这里就不细说了 石头阅读模拟登陆 石头阅读是一款免费的小说阅读器，书库覆盖面广，资源丰富，可以免费看各类需要付费的小说，堪称白嫖党的利器，趁此机会安利一下 网址：https://www.stoneread.com/ 登陆在右上角，有点隐蔽： 模拟登陆大体上有两种，即添加cookie和使用post请求添加账号密码。由于后面的实战会涉及到前一种，所以这个实战就先用后一种了。 核心思路是，获取网站用以验证账号密码的url，然后把我们准备好的账号密码以post请求的形式发给它，这样就相当于登陆成功了。 怎么找目标url？ 我们先手动登陆试试，点击登录后，注视着“检查”里的Network栏，你会发现一个“一闪即逝”的文件： \"小老弟，跑的挺快啊\" 我们点击左上角的停止键，就可以获得这个文件，点开就有了url，顺便再抄一下user-agent 翻到下面，有一个“Form Data”，一看就是我们提交的账号密码： 不许盗号！！！ 这个checkbox代表的是那个“下次自动登录”选项，on自然就是表示“勾选” 代码： 1234567891011121314import requestsurl = &#x27;https://www.stoneread.com/login/logincheck?ur=&#x27;headers = &#123; &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36&#x27;&#125;data = &#123; &#x27;username&#x27; : &#x27;kaitoukiddo@yeah.net&#x27;, &#x27;password&#x27; : &#x27;12345ssdlh&#x27;, &#x27;checkbox&#x27; : &#x27;on&#x27;&#125;resp = requests.post(url,headers=headers,data=data)print(resp.content.decode(&#x27;utf-8&#x27;)) 结果中有“登陆成功”字样，和我们看到的页面一致。嘿嘿，成功啦～ 设置代理ip 这个方法它成功几率不太大，因为我用的是免费的代理ip，没氪金怎么会变强呢它就不太稳定。我先把验证方法给一下。 获取免费ip的网址： * 快代理：https://www.kuaidaili.com/free/ * 芝麻代理：http://http.zhimaruanjian.com/ * 太阳代理：http://http.taiyangruanjian.com/ * 讯代理：http://www.xdaili.cn/ * 蚂蚁代理：http://www.mayidaili.com/ * 极光代理：http://www.jiguangdaili.com/ 查看当前ip的请求url：http://www.httpbin.org/ip ps. http://www.httpbin.org/是一个功能很强大的网站，大家可以访问一下康康 我们先不用代理，看一下自己的ip地址 1234import requestsurl = &#x27;http://www.httpbin.org/ip&#x27;resp = requests.get(url)print(resp.text) 这个时候，就会打印出我自己电脑的真实ip 然后我们为它添加代理： 1234567import requestsproxy = &#123; # 免费的代理ip，这会儿估计已经没法用了 &#x27;http&#x27;:&#x27;111.77.197.127:9999&#x27;&#125;url = &#x27;http://www.httpbin.org/ip&#x27;resp = requests.get(url,proxies=proxy)print(resp.text) 这个时候如果你欧了一把，选的代理ip恰好是可以用的，那你就会看到程序打印出了你选的ip地址。 附： urllib库设置代理的方法——ProxyHandler处理器 12345678910111213from urllib import requesturl = &#x27;http://httpbin.org/ip&#x27;#1. 使用ProxyHandler,传入代理构建一个handler,代理的结构是字典handler = request.ProxyHandler(&#123;&#x27;http&#x27;:&#x27;122.193.244.243:9999&#x27;&#125;)#2. 使用上面创建的handler构建一个openeropener = request.build_opener(handler)#3. 使用opener去发送一个请求resp = opener.open(url)print(resp.read()) selenium设置代理的方法 1234options = webdriver.ChromeOptions() # 创建ChromeOptions对象options.add_argument(&quot;--proxy-server=htto://175.43.151.209:9999&quot;) # 代理driver = webdriver.Chrome(executable_path=&quot;/Users/pangyuxuan/Desktop/chromedriver&quot;,chrome_options=options) # 在driver路径后添加代理参数driver.get(&quot;http://httpbin.org/ip&quot;) 在Scrapy中设置代理 设置普通代理 12345678class IPProxyDownloadMiddleware(object): PROXIES = [ &quot;5.196.189.50:8080&quot;, ] def process_request(self,request,spider): proxy = random.choice(self.PROXIES) print(&#x27;被选中的代理：%s&#x27; % proxy) request.meta[&#x27;proxy&#x27;] = &quot;http://&quot; + proxy 设置独享代理 12345678class IPProxyDownloadMiddleware(object): def process_request(self,request,spider): proxy = &#x27;121.199.6.124:16816&#x27; user_password = &quot;970138074:rcdj35xx&quot; request.meta[&#x27;proxy&#x27;] = proxy # bytes b64_user_password = base64.b64encode(user_password.encode(&#x27;utf-8&#x27;)) request.headers[&#x27;Proxy-Authorization&#x27;] = &#x27;Basic &#x27; + b64_user_password.decode(&#x27;utf-8&#x27;) 爬取瓜子二手车交易信息 网址：https://www.guazi.com/www/buy/ 我们先什么都不加，直接请求网址，看输出是什么，再逐渐的添加请求头里的内容，来尝试网站究竟是用什么作为反爬虫的检测依据的。 什么都不加： 12345import requestsfrom lxml import etreeurl = &#x27;https://www.guazi.com/www/buy/&#x27;resp = requests.get(url)print(resp.text) 输出： 经过比较，它和网页源代码不一致，且最后还出现了乱码现象，说明text把解码方法猜错了——体现了content.decode('utf-8')的稳定性 添加User-agent： 12345678import requestsfrom lxml import etreeurl = &#x27;https://www.guazi.com/www/buy/&#x27;headers = &#123; &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36&#x27;&#125;resp = requests.get(url,headers=headers)print(resp.content.decode(&#x27;utf-8&#x27;)) 哈哈！还是不行。 添加cookie： 123456789import requestsfrom lxml import etreeurl = &#x27;https://www.guazi.com/www/buy/&#x27;headers = &#123; &#x27;Cookie&#x27; : &#x27;uuid=8375fbff-6a87-4130-8c96-7a4aa8d30728; ganji_uuid=8329982395237678242215; cainfo=%7B%22ca_a%22%3A%22-%22%2C%22ca_b%22%3A%22-%22%2C%22ca_s%22%3A%22self%22%2C%22ca_n%22%3A%22self%22%2C%22ca_medium%22%3A%22-%22%2C%22ca_term%22%3A%22-%22%2C%22ca_content%22%3A%22-%22%2C%22ca_campaign%22%3A%22-%22%2C%22ca_kw%22%3A%22-%22%2C%22ca_i%22%3A%22-%22%2C%22scode%22%3A%22-%22%2C%22keyword%22%3A%22-%22%2C%22ca_keywordid%22%3A%22-%22%2C%22display_finance_flag%22%3A%22-%22%2C%22platform%22%3A%221%22%2C%22version%22%3A1%2C%22client_ab%22%3A%22-%22%2C%22guid%22%3A%228375fbff-6a87-4130-8c96-7a4aa8d30728%22%2C%22ca_city%22%3A%22qd%22%2C%22sessionid%22%3A%22dbe4532a-24f9-45fc-8c5f-b9518a2efb46%22%7D; antipas=93901707482fmWd51E58673WzOJ; cityDomain=www; clueSourceCode=%2A%2300; user_city_id=-1; preTime=%7B%22last%22%3A1611505261%2C%22this%22%3A1610175479%2C%22pre%22%3A1610175479%7D; sessionid=30370a7d-e999-43e4-a614-4ffacc7c8e75; lg=1; Hm_lvt_bf3ee5b290ce731c7a4ce7a617256354=1610175480,1610175573,1610524515,1611505262; Hm_lpvt_bf3ee5b290ce731c7a4ce7a617256354=1611505262&#x27;, &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36&#x27;&#125;resp = requests.get(url,headers=headers)print(resp.content.decode(&#x27;utf-8&#x27;)) 哈哈！竟然行了！ 虽然我自己试的时候还额外添加了Host，但不知道为什么现在只加一个cookie就行了。 后续的思路就是我们通过“检查”，在Elements里找到详情页的链接如图： 并且不同的车存放在不同的&lt;li&gt;标签中： 所以我们遍历所有&lt;li&gt;标签，依次访问每辆车的详情页面，再获取详情页面的车辆信息，进行存储即可。感兴趣的同学可以自行完成后面的代码，也可以找我要一下之前的代码 爬取豆瓣top250 网址：https://movie.douban.com/top250 这个案例也是我学习时候，花比较多时间做的一个案例，虽然它没有什么很惊艳的实现技巧，但我在做的时候遇到了这样一个问题：我被封号了！ 考虑到我囊中羞涩，没有租60r/月的代理服务器，而免费代理它又不太稳定，于是我选择老老实实的注册登陆。没错我就是前几天才注册豆瓣 很简单，只要登录以后添加cookie信息就可以了。 代码如下，做到存储数据之前： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import requestsfrom bs4 import BeautifulSoupheaders = &#123; &#x27;User-Agent&#x27; : &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&#x27;, &#x27;Cookie&#x27; : &#x27;ll=&quot;118221&quot;; bid=Dp60PRKNGWI; __yadk_uid=t4cy7TbKsr834lpYtjbt0Vn6au2yF7oP; _vwo_uuid_v2=D181BE4292803A62776208FF476CE0C21|403fd897a559fbd412c3a7530efb5d2f; __gads=ID=546d1adef9db7e77-221ec2b1c5c5000a:T=1611226743:RT=1611226743:S=ALNI_MZmgV9oiEJeTVAfAnDiNlwsRm8WMQ; ap_v=0,6.0; __utmc=30149280; __utmz=30149280.1611299250.2.2.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; __utmc=223695111; __utmz=223695111.1611299250.2.2.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; _pk_ref.100001.4cf6=%5B%22%22%2C%22%22%2C1611302352%2C%22https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3DStwtEMgge76IHS2f9aoITF2La9KliUfVdz-ShjuHwB78oJQFmijIAnaCAMgiQfxo%26wd%3D%26eqid%3Dd8a7eb3b0003fac200000002600a79b0%22%5D; _pk_ses.100001.4cf6=*; __utma=30149280.233705150.1611225868.1611299250.1611302352.3; __utma=223695111.583107523.1611225868.1611299250.1611302352.3; __utmb=223695111.0.10.1611302352; dbcl2=&quot;231087110:rCDcDbFTf0I&quot;; ck=rEkU; push_noty_num=0; push_doumail_num=0; __utmt=1; __utmv=30149280.23108; __utmb=30149280.2.10.1611302352; _pk_id.100001.4cf6=fcbcfa39023ea437.1611225868.3.1611304162.1611299286.&#x27;&#125;# 函数：获取详情页面的url，返回一个列表def get_detail_urls(url): resp = requests.get(url, headers=headers) # 获取详情页面url html = resp.text soup = BeautifulSoup(html, &#x27;lxml&#x27;) lis = soup.find(&#x27;ol&#x27;, class_=&#x27;grid_view&#x27;).find_all(&#x27;li&#x27;) # 经搜索，grid_view属性值唯一，故用find直接找到即可 detail_urls = [] # 列表 for li in lis: detail_url = li.find(&#x27;a&#x27;)[&#x27;href&#x27;] detail_urls.append(detail_url) return detail_urlsdef parse_detail_url(url): resp = requests.get(url,headers=headers) html = resp.text soup = BeautifulSoup(html,&#x27;lxml&#x27;) lis = [] name = list(soup.find(&#x27;span&#x27;,property=&#x27;v:itemreviewed&#x27;).stripped_strings) name = &#x27;&#x27;.join(name) lis.append(name) director = list(soup.find(&#x27;div&#x27;,id=&#x27;info&#x27;).find_all(&#x27;span&#x27;)[0].stripped_strings) director = &#x27;&#x27;.join(director) lis.append(director) actor = list(soup.find(&#x27;div&#x27;,id=&#x27;info&#x27;).find(&#x27;span&#x27;,class_=&#x27;actor&#x27;).stripped_strings) actor = &#x27;&#x27;.join(actor) lis.append(actor) score = soup.find(&#x27;strong&#x27;,class_=&#x27;ll rating_num&#x27;).string lis.append(score) remark = list(soup.find(&#x27;span&#x27;,property=&#x27;v:summary&#x27;).stripped_strings) remark = &#x27;&#x27;.join(remark) lis.append(remark) print(lis)def main(): base_url = &#x27;https://movie.douban.com/top250?start=&#123;&#125;&amp;filter=&#x27; for x in range(0,251,25): url = base_url.format(x) detail_urls = get_detail_urls(url) for detail_url in detail_urls: parse_detail_url(detail_url) # resp = requests.get(detail_url,headers=headers) # html = resp.text # soup = BeautifulSoup(html,&#x27;lxml&#x27;) # name = list(soup.find(&#x27;div&#x27;,id=&#x27;content&#x27;).find(&#x27;h1&#x27;).stripped_strings) # title = list(soup.find(&#x27;span&#x27;,property=&#x27;v:itemreviewed&#x27;).stripped_strings) # name = &#x27;&#x27;.join(name) # 将列表转化为字符串 # director = list(soup.find(&#x27;a&#x27;,rel=&#x27;v:directedBy&#x27;)) # director = list(soup.find(&#x27;div&#x27;,id=&#x27;info&#x27;).find(&#x27;span&#x27;,class_=&#x27;attrs&#x27;).stripped_strings) # print(director) # writer = list(soup.find(&#x27;div&#x27;,id=&#x27;info&#x27;).find_all(&#x27;span&#x27;)[3].find(&#x27;span&#x27;,class_=&#x27;attrs&#x27;).stripped_strings) # writer = &#x27;&#x27;.join(writer) # print(writer) # actor = list(soup.find(&#x27;div&#x27;,id=&#x27;info&#x27;).find(&#x27;span&#x27;,class_=&#x27;actor&#x27;).stripped_strings) # actor = &#x27;&#x27;.join(actor) # print(actor) # remark = list(soup.find(&#x27;span&#x27;,class_=&#x27;all hidden&#x27;).stripped_strings) # print(remark) # score = list(soup.find(&#x27;strong&#x27;,class_=&#x27;ll rating_num&#x27;).stripped_strings) # print(score)if __name__ == &#x27;__main__&#x27;: main() 好家伙，我写这个文档时候，为了要上面那个“状态异常”的截图，把cookie删了以后疯狂爬取，直接导致我被封号了： 而且好像还没那么容易解锁。 哎，先看最后一个吧 selenium行为链实战 有些厉害的网站会根据鼠标行为判断你是人还是爬虫，这个时候selenium库的行为链就可以帮你的爬虫躲过检查。因为我还没遇到这么牛逼的网站，所以就随便举个例子，说一下行为链的语法了。 比如我想在百度主页搜索“元尊” 123456789101112131415161718192021from selenium import webdriverfrom selenium.webdriver.common.action_chains import ActionChainsdriver = webdriver.Chrome(executable_path=&quot;/Users/pangyuxuan/Desktop/chromedriver&quot;)driver.get(&quot;https://www.baidu.com/&quot;)inputTag = driver.find_element_by_id(&#x27;kw&#x27;) # 获取输入框submitTag = driver.find_element_by_id(&#x27;su&#x27;) # 获取按钮&quot;百度一下&quot;actions = ActionChains(driver) # 创建行为链对象actionsactions.move_to_element(inputTag) # 鼠标移动到inputTagactions.send_keys_to_element(inputTag,&#x27;元尊&#x27;) # 输入要搜索的内容actions.move_to_element(submitTag) # 鼠标移动到提交按钮actions.click(submitTag) # 点击提交actions.perform() # 上面的都是在定义，还没执行，通过perform执行 还有更多的鼠标相关的操作。 click_and_hold(element) ：点击但不松开鼠标。 context_click(element) ：右键点击。 double_click(element) ：双击。 更多方法请参考：http://selenium-python.readthedocs.io/api.html 彩蛋：关于我被封号这件事","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/"},{"name":"实战","slug":"爬虫/实战","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/%E5%AE%9E%E6%88%98/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"常用LaTex公式及用法","slug":"latex-toolbook","date":"2022-08-06T15:46:36.000Z","updated":"2022-08-24T14:26:33.311Z","comments":true,"path":"2022/08/06/latex-toolbook/","link":"","permalink":"https://pyxblog.cn/2022/08/06/latex-toolbook/","excerpt":"整理了一些使用频率相对较高的LaTex公式，用到新的会不断往里补充，也欢迎大家在评论区补充！","text":"整理了一些使用频率相对较高的LaTex公式，用到新的会不断往里补充，也欢迎大家在评论区补充！ 运算符 常用二元运算 \\pm \\cdot \\times \\mp \\div \\frac{1}{1} 常用巨算符 \\sum \\prod \\int \\bigcup \\bigcap \\oint 关系符 常用二元关系 \\leq or \\le \\geq or \\ge \\ll \\gg \\in \\subset \\subseteq \\equiv \\approx \\propto 取反 加\\not来实现取反，如:\\not \\subset 特殊字符 常用希腊字母 \\alpha \\beta \\gamma \\delta \\epsoilon \\zeta \\theta \\lambda \\pi \\xi \\rho \\sigma \\eta \\phi \\psi \\omega 将首字母大写即可获得相应大写字母 特殊符号 特殊符号 \\{ \\} \\% \\dots \\cdots \\vdots \\to \\Rightarrow \\varnothing \\forall \\exists \\infty 公式块的相关写法 等式对齐写法 开头写\\begin{aligned}，结尾写\\end{aligned}，中间需要对其的等式用&amp;&amp;包裹，再换行\\\\ 例如 12345$$\\begin{aligned} S(n) &amp; = 1+2+ \\dots +n &amp; \\\\ &amp; = \\frac{(n+1) \\times n}{2} &amp;\\end{aligned}$$ 大括号的用法 开头写\\begin{cases}，结尾写\\end{cases}，中间如下，例如 1234567$$1+(-1)^k=\\begin{cases}2 &amp; \\text{k=2n-1}\\\\0 &amp; \\text{k=2n}\\end{cases}$$ 组合数的写法 可以强行写： 123$$C_n^m$$ 也可以使用大括号的描写方式，注意上面的是范围，下面的数是要取的个数，与的上下相反 123$$\\tbinom{n}{m}$$ 求和符号的行内写法 若直接写 1$\\sum_{i=0}^n a_n$ 会显示为 若想将和挪到的上下，可以如下写 1$\\sum\\limits_{i=0}^n a_n$ 效果： 矩阵的写法 123456\\begin{matrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{matrix} \\\\\\begin{pmatrix} 0 &amp; -i \\\\ i &amp; 0 \\end{pmatrix} \\\\\\begin{bmatrix} 0 &amp; -1 \\\\ 1 &amp; 0 \\end{bmatrix} \\\\\\begin{Bmatrix} 1 &amp; 0 \\\\ 0 &amp; -1 \\end{Bmatrix} \\\\\\begin{vmatrix} a &amp; b \\\\ c &amp; d \\end{vmatrix} \\\\\\begin{Vmatrix} i &amp; 0 \\\\ 0 &amp; -i \\end{Vmatrix} 大佬的文章备查 LaTex符号大全-基于lshort-zh-cn 转载自王美庭 2019-03-26 Latex所有常用数学符号吐血整理！（包含大括号、等式对齐） 原创繁凡さん 2020-05-27 常用LaTex表达式&amp;符号——组合数学篇 原创__hep__ 2020-05-03","categories":[{"name":"markdown系列教程","slug":"markdown系列教程","permalink":"https://pyxblog.cn/categories/markdown%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"latex","slug":"latex","permalink":"https://pyxblog.cn/tags/latex/"},{"name":"markdown","slug":"markdown","permalink":"https://pyxblog.cn/tags/markdown/"}]},{"title":"pytorch实现线性回归","slug":"pytorch-demo-2","date":"2022-08-06T15:42:03.000Z","updated":"2022-08-06T15:44:48.720Z","comments":true,"path":"2022/08/06/pytorch-demo-2/","link":"","permalink":"https://pyxblog.cn/2022/08/06/pytorch-demo-2/","excerpt":"","text":"用cpu就能很快跑出来 不需要额外的输入文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import torchimport numpy as npimport torch.nn as nnx_values = [i for i in range(11)] # [0,1,2,3,4,5,6,7,8,9,10]x_train = np.array(x_values, dtype=np.float32)x_train = x_train.reshape(-1, 1) # 将x_train调整为11*1的矩阵y_values = [2.5*i+3.5 for i in x_values] # y=2.5x+3.5y_train = np.array(y_values, dtype=np.float32)y_train = y_train.reshape(-1, 1)class LinearRegressionModel(nn.Module): # 继承自nn包的Module类 def __init__(self, input_dim, output_dim): super(LinearRegressionModel, self).__init__() # 执行父类的构造函数 self.linear = nn.Linear(input_dim, output_dim) # nn.Linear(输入数据维度, 输出数据维度) 全连接层 def forward(self, x): out = self.linear(x) return outinput_dim = 1output_dim = 1model = LinearRegressionModel(input_dim, output_dim)epochs = 1000 # 训练次数learning_rate = 0.01 # 学习率optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)# 优化器，使用基本的优化器SGD，传入需要更新的参数（model中的全部参数）和学习率criterion = nn.MSELoss() # 回归任务可选用MSE等for epoch in range(epochs): epoch += 1 # x_train和y_train均为numpy.ndarry格式，需要转换为tensor格式才可以传入框架 inputs = torch.from_numpy(x_train) labels = torch.from_numpy(y_train) # 每次迭代开始时 梯度需要清零 optimizer.zero_grad() # 前向传播 outputs = model.forward(inputs) # 计算损失 loss = criterion(outputs, labels) # 反向传播 loss.backward() # 更新权重参数 optimizer.step() # 每50个epoch输出一次，以显示训练进度 if epoch % 50 == 0: print('epoch {}, loss {}'.format(epoch, loss.item()))y_predicted = model.forward(torch.from_numpy(x_train)).data.numpy()# 前向传播 传入训练数据x 输出预测结果y 用以测试# .data.numpy() 将结果转换成numpyprint(y_predicted)","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"实战demo","slug":"深度学习/实战demo","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98demo/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://pyxblog.cn/tags/PyTorch/"},{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"pytorch实现Minist手写数字识别","slug":"pytorch-demo-1","date":"2022-08-06T15:30:43.688Z","updated":"2022-08-06T15:44:45.804Z","comments":true,"path":"2022/08/06/pytorch-demo-1/","link":"","permalink":"https://pyxblog.cn/2022/08/06/pytorch-demo-1/","excerpt":"","text":"代码中的 import xxx 和 from xxx import xxx 为依赖包，可按编译器的提示自行安装。 数据集下载地址：http://deeplearning.net/data/mnist/ 考虑到外网下载较慢，提供国内的镜像下载链接： Github仓库：https://github.com/zionfuo/keras-datasets 数据集下载后，代码中读取文件： 12345with gzip.open(&#x27;data/mnist/mnist.pkl.gz&#x27;, &#x27;rb&#x27;) as f: # 读取数据 ((x_train, y_train), (x_test, y_test), _) = pickle.load(f, encoding=&#x27;latin-1&#x27;)x_train, y_train, x_test, y_test = map( # 将数据类型转换为tensor torch.tensor, (x_train, y_train, x_test, y_test)) 注意将上面的文件路径换成自己数据集的路径。下面是完整代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091# -- 构造网络 --# mnist数据集50000个样本，每个样本28*28=784个像素点# 输入数据1*784，设计三层网络，第一层784*128，第二层128*256，第三层256*10from torch import nnimport torch.nn.functional as Fclass Mnist_NN(nn.Module): # 继承父类 def __init__(self): super().__init__() # 继承父类的构造函数 self.hidden1 = nn.Linear(784, 128) # 隐层1 784*128 self.hidden2 = nn.Linear(128, 256) # 隐层2 128*256 self.out = nn.Linear(256, 10) # 输出层 def forward(self, x): # 前向传播 x = F.relu(self.hidden1(x)) # 输入-隐层1，激活函数relu x = F.relu(self.hidden2(x)) # 隐层1-隐层2，激活函数relu x = self.out(x) # 隐层2-输出 return x # 返回前向传播计算结果# -- 构造数据集 --import gzipimport pickleimport torchfrom torch.utils.data import TensorDataset # 用于创建数据集from torch.utils.data import DataLoader # 用于加载数据集# 使用TensorDataset和DataLoader创建的数据集可以根据传入的batch自动抽样# 也可自动在每次分组时洗牌with gzip.open(&#x27;data/mnist/mnist.pkl.gz&#x27;, &#x27;rb&#x27;) as f: # 读取数据 ((x_train, y_train), (x_test, y_test), _) = pickle.load(f, encoding=&#x27;latin-1&#x27;)x_train, y_train, x_test, y_test = map( # 将数据类型转换为tensor torch.tensor, (x_train, y_train, x_test, y_test))train_dataset = TensorDataset(x_train, y_train) # 训练数据集test_dataset = TensorDataset(x_test, y_test) # 测试数据集def getData(train_dataset, test_dataset, batch_size): # 加载数据集 return ( DataLoader(train_dataset, batch_size=batch_size, shuffle=True), DataLoader(test_dataset, batch_size=batch_size * 2), )# -- 训练 --import numpy as npfrom torch import optimloss_func = F.cross_entropy # 损失函数，直接从functional中调用交叉熵函数def getModel(): # 获取实例化模型和优化器 model = Mnist_NN() return model, optim.SGD(model.parameters(), lr=0.001)def loss_batch(model, loss_func, x_bath, y_bath, opt=None): loss = loss_func(model(x_bath), y_bath) # 有优化器，即训练，需要进行更新参数等操作 # 无优化器，即测试，只求损失值即可 if opt is not None: loss.backward() # 反向传播 opt.step() # 更新参数 opt.zero_grad() # 梯度清零 return loss.item(), len(x_bath)def mnist(steps, model, loss_func, opt, train_data, test_data): # steps 迭代多少次 # model 网络的实例 # loss_func 损失函数 # opt 优化器 # train_data 训练数据 # test_data 测试数据 for step in range(steps): for x_bath, y_bath in train_data: # 训练 loss_batch(model, loss_func, x_bath, y_bath, opt) with torch.no_grad(): # 测试，不更新参数 losses, nums = zip( *[loss_batch(model, loss_func, x_bath, y_bath) for x_bath, y_bath in test_data] ) val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums) print(&#x27;当前step:&#x27; + str(step), &#x27;验证集损失：&#x27; + str(val_loss)) 训练： 123train_data, test_data = getData(train_dataset, test_dataset, 64)model, opt = getModel()mnist(25, model, loss_func, opt, train_data, test_data)","categories":[{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"实战demo","slug":"深度学习/实战demo","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98demo/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://pyxblog.cn/tags/PyTorch/"},{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"python快速入门","slug":"python-basic","date":"2022-08-06T15:27:25.000Z","updated":"2022-08-06T15:30:10.360Z","comments":true,"path":"2022/08/06/python-basic/","link":"","permalink":"https://pyxblog.cn/2022/08/06/python-basic/","excerpt":"","text":"数值类型与基本操作 12345678910112**5 # 2的5次方1.3e5 1.3e-5 # 科学计数法0xFF # 16进制 0x是16进制前缀type(a) # 打印数据类型a = int(input('请输入数据')) # 类型转换# input()输入数据默认为字符串# 常见类型 int float str bool list dict-字典 set-集合abs(5.2) # abs函数——取绝对值round(5.2) # round函数——四舍五入min(2,3,4) # min函数——取最小值 可以有若干参数max(2,3,4) # max函数——取最大值 可以有若干参数 基本数据结构 字符串 str 123456789101112131415161718192021222324252627282930313233343536st = 'jupyter ' + 'python' # 字符串加法 -&gt; 有序拼接 'jupyter python'st = 'jupyter ' * 3 # 字符串数乘 -&gt; 重复 'jupyter jupyter jupyter'len(st) # 字符串长度# 拆分st = 'Gin Vodka Vermouth Bourbon'st.split() # 默认按空格拆分字符串 返回列表 ['Gin','Vodka','Vermouth','Bourbon']st.split('Vodka') # 也可指定拆分间隔 间隔不会计入结果# 合并li = ['Gin','Vodka','Vermouth','Bourbon']st = '\\\\'st.join(li) # 以st为衔接合并列表，要求列表中的元素均为字符串类型 # 'Gin\\\\Vodka\\\\Vermouth\\\\Bourbon'# 替换st = 'Gin Vodka Vermouth Bourbon'st.replace('Bourbon','Zero')# 大小写st = 'Vermouth'st.lower() # vermouthst.upper() # VERMOUTHst.strip() # 去除首尾多余空格st.lstrip() # 去除左边多余空格st.rstrip() # 去除右边多余空格# format占位'{} and {} are black'.format('Gin','Vodka')# Gin and Vodka are black'{2} and {1} are black'.format('Gin','Vodka') # 指定索引# Vodka and Gin are black'{a} and {b} are black'.format(a='Gin',b='Vodka') # 指定参数# Gin and Vodka are black 列表 list 有序，可以混合存放任意类型数据，可嵌套，通过索引访问 123456789101112131415161718192021222324li = [1,2] + [3,4] # 列表相加 -&gt; 有序拼接 [1,2,3,4]li = [1,2] * 3 # 列表数乘 -&gt; 重复 [1,2,1,2,1,2]len(li) # 求列表长度del li[3:] # 按索引删除某元素tmp in li # 判断元素tmp是否在列表li中 返回True or Falseli.count(tmp) # 计算元素tmp在列表中的个数li.index(tmp) # 返回元素tmp在列表中首次出现的索引 没找到报错ValueErrorli.append(tmp) # 将元素tmp添加进列表最后li.insert(ind,tmp) # 将元素tmp添加在列表索引ind位置li.remove(tmp) # 将列表中首个tmp从列表中移除li.pop() # 将列表尾部的元素弹出 并返回该元素li.pop(ind) # 将索引ind位置的元素弹出 并返回该元素li.sort() # 列表升序排序li.sort(reverse=1) # 列表降序排序li_sort = sorted(li) # 列表升序排序 将结果储存在新列表中 不改变原列表li.reverse() # 列表翻转# 按索引遍历for i in range(len(li)): print(li[i])# 按元素遍历for t in li: print(t) 索引 用于有序数据结构，如字符串和列表，不用于字典和集合 123456789101112# 首端正数从0开始，尾端倒数从-1开始st = '01234567'st[0] # '0'st[-1] # '7' # 切片st[0:4] # 左闭右开区间 '0123'st[4:] # 4到无穷 '4567'st[:4] # 0到4 '0123'st[-2:] # 倒数第二到无穷 '67'st[::3] # 每3个取一个值 '036' 字典 dict 基本结构：key-value 无序，使用key访问value，不可使用索引 12345678910111213141516171819202122232425di = {'Gin':'black','Bourbon':'red'}di['Gin'] # 'black'# 列表转化为字典di = dict([('amy',89), ('tom',90)])# {'amy': 89, 'tom': 90}di.get('amy') # 89 di.get('sam') # 没找到 但不会报错di.get('sam','none') # 返回nonedi.pop('amy') # 弹出指定key-value 并返回valuedi['tom'] +=10 # {'tom',100} value可以被运算del di['tom'] # 删除指定key-valuedi = {'Gin':'black','Bourbon':'red'}di.update({'Gin':'black','Vodka':'black'}) # 更新'Gin' in di # Truedi.keys() # 返回字典di的所有key 类型为dict_keys 可用于遍历di.values() # 返回字典di的所有value 类型为dict_values 可用于遍历tang.items() # 返回字典di的所有key-value对# 遍历for key in di.keys(): print(di[key]) 集合 set 集合内元素不重复，无序，可以进行一些集合间的数学运算/判断 123456789101112131415li = [1,1,2,3,5,8]se = set(li) # {1,2,3,5,8}li = list(se) # 与list可以互相转化a = {1,2,3,4}b = {2,3,4}a | b # 并集 {1,2,3,4}a &amp; b # 交集 {2,3,4}a - b # 在a里面 不在b里面的元素 {1}b &lt;= a # True 判断子集a &lt;= a # Truea.update([4,5,6]) # 更新 {1,2,3,4,5,6}a.remove(1) # 移除指定元素a.pop() # 弹出并返回首部元素 逻辑结构 判断结构 通过and/or连接多个判断条件 三个及以上判断结果用elif表示 使用: 和缩进表示逻辑从属 123456789a = 90if a &gt; 100 and a &lt;= 200: print('if')elif a == 50 or a == 90: print('elif1')elif (a &lt;10 and a &gt; 0) or a &gt; 200: print('elif2')else: print('else') 循环结构 while 循环 12345678a = 0while a &lt; 5: print(a) a += 1se = {'Gin','Vodka','Bourbon'}while se: print(se.pop()) for循环 1234567for i in range(1,5): print(i)di = {'Gin':'black','Vodka':'black','Bourbon':'red'}for key in di.keys(): print(di[key]) 函数 参数和返回值根据需要设定，通过def关键字、:和缩进表示逻辑从属 12345678910111213141516171819202122def print_value(a): print('The value of a is ',a) def add_value(a=1,b=2): # 为参数设置默认值 print('a+b is ',a+b) def add_number(a,*args): # 接受不定个数的参数 b = 0 for i in args: a += i b += a return a,b # 返回值可以有多个a,b = add_number(1,2,3)print (a,b) # 6 9 def add_2(a,**kwargs): # **kwargs可传入不定个数的key-value对 for arg,value in kwargs.items(): print(arg,value)add_2(1,x=2,y=3)# x 2# y 3 包 12345678%%writefile test.py # writefile用于在jupyter中新建文件value = 10010def test_function(): print('success') 123456789101112# 导入包import test as te # 整个导入包 调用时需用te.print(te.value) # 10010te.test_function() # successfrom test import value,test_function # 导入包中的部分变量和函数 直接使用无需.print(value) # 10010te.test_function() # successfrom test import * # 导入包中的部分变量和函数 直接使用无需.print(te.value) # 10010te.test_function() # success 类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class people: '帮助信息：这是一个帮助信息' # 类的自带属性 location = 'earth' # 所有实例都会共享number def __init__(self,name,age): # 构造函数 self.name = name self.age = age def show_name(self): print(self.name)per1 = people('Vodka',40) # 实例化per1.name = 'Gin' # 访问per1的name变量per2.show_name() # 访问per2的show_name函数del per1.name # 删除实例per1的name属性hasattr(per1,'age') # True 查看实例是否具有某一属性hasattr(per1,'name') # False 被删除的属性和不存在的属性返回Falsegetattr(per1,'age') # 获取实例per1的属性agesetattr(per1,'name','Gin') # 为实例per1设置name属性setattr(per1,'sex','male') # 可以设置类中没有的属性delattr(per1,'sex') # 删除per1的sex属性print(peolpe.__doc__) # 帮助信息print (people.__name__) # 类的名字print (people.__module__) # 类的定义所在的模块print (people.__bases__) # 父类的构成print (people.__dict__) # 类的组成# 继承class Dad: # 父类 def __init__(self): print ('父类构造函数') def dadFunction(self): print ('父类方法') def sameName(self): print ('来自dad') class son(Dad): # Dad的子类 def __init__(self): print ('子类构造函数') def sonFunction(self): print ('子类方法') def sameName(self): print ('来自子类')child = son() # 子类构造函数child.dadFunction() # 父类方法child.sonFunction() # 子类方法child.sameName() # 来自子类 基础操作 异常处理 用以防止报错导致的程序中断 12345678910111213141516171819202122232425262728293031323334353637383940414243444546li = [1,0]for tmp in li: try: print('front') # 报错语句前的语句可以被执行 print(1/tmp) # 报错 跳转至except 该语句不会被执行 print('last') # 报错语句后的语句不可以被执行 except ZeroDivisionError: print('不可以除0') # 涵盖所有报错类型import mathfor i in range(10): try: input_number = input('write a number') if input_number == 'q': break result = 1/math.log(float(input_number)) print (result) except ValueError: print ('ValueError: input must &gt; 0') except ZeroDivisionError: print ('log(value) must != 0') except Exception: # 其他的可能性 print ('unknow error') # finallytry: 1 / 0except: print('不可以除0')finally: print('finally') # 无论try中是否有异常，finally都会被执行 # 自定义错误类型class NumNotInList(ValueError): # 自定义的一种异常 passli = [1,2,3]while True: num = int(input('input a number: ')) if num not in li: raise NumNotInList('数字{}不在列表中'.format(num)) # 抛出一个错误 输入不在列表中的数字时报错终止 并显示错误类型为NumNotInList 文件处理 1234567891011121314151617181920txt = open('./test.txt') # ./ 即本代码所在的路径txt_str = txt.read() # read函数返回文本内容txt_lines = txt.readlines() # readlines返回列表 文本每一行组成一个元素 包括换行符txt.close() # 文件打开后要记得关闭txt = open('test.txt','w') # 以覆盖写入模式打开文件 一旦写入丢失原有数据txt.write('123')txt.close()txt = open('test.txt','a') # 以追加写入模式打开文件 在原有数据后面写入新的数据txt.write('\\n321')txt.close()txt = open('test.txt','r') # 以只读模式打开文件 可以读取文件内容print (txt.read())txt.close()with open('test.txt','w') as f: f.write('123\\n321') # with方法会自动close 且自带类似try-except的防止报错功能 较为常用 系统时间 所在包：time.py 123456789import timeprint(time.time()) # 从1970年1月1日到现在经过了多长时间print (time.localtime(time.time()))# time.struct_time(tm_year=2022, tm_mon=2, tm_mday=4, tm_hour=23, tm_min=18, tm_sec=46, tm_wday=4, tm_yday=35, tm_isdst=0)print (time.asctime(time.localtime(time.time())))# Fri Feb 4 23:18:38 2022print (time.strftime('%Y-%m-%d %H:%M:%S',time.localtime()))# 2022-02-04 23:19:17time.sleep(10) # 程序停止十秒","categories":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/categories/python/"},{"name":"基础教程","slug":"python/基础教程","permalink":"https://pyxblog.cn/categories/python/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"}]},{"title":"Matlab二维绘图","slug":"matlab-basic-6","date":"2022-08-06T15:11:00.000Z","updated":"2022-09-04T09:56:31.739Z","comments":true,"path":"2022/08/06/matlab-basic-6/","link":"","permalink":"https://pyxblog.cn/2022/08/06/matlab-basic-6/","excerpt":"Matlab基础教程6-二维绘图，包含基本的绘图函数，坐标系的切换，图形窗口，图形标注及特殊图形的绘制（饼图、条形图等）。","text":"Matlab基础教程6-二维绘图，包含基本的绘图函数，坐标系的切换，图形窗口，图形标注及特殊图形的绘制（饼图、条形图等）。 基本绘图函数 plot 最基本的绘图函数。执行plot函数时，若当前已有图形窗口，则将图画在现有图形窗口上，覆盖原有图形；若当前没有图形窗口，则自动创建新的图形窗口。 1plot(X,Y); % 创建以X为自变量、Y为因变量的二维线图 X和Y必须是同维向量，绘制以X为横坐标、Y为纵坐标的曲线。若： X是向量，Y是矩阵，则X的维数应与Y的某一维相等，绘制多条颜色不同的曲线，曲线数等于Y的另一维数，X则仍作为横坐标。当Y是方阵时，Matlab会优先处理列，即绘制Y的每一列对X的曲线。 123x = 0:0.01:10; % 1*1001y = [sin(x);sin(x)+1;sin(x)-1]; % 3*1001plot(x,y); grid on; % 3条曲线 X是矩阵，Y是向量时，规则同上，但Y会被当作横坐标 X与Y皆为矩阵时，要求二者必须同维，以X的每一列作为横坐标、以Y对应对列元素作为纵坐标绘制曲线，曲线数等于列数。 12plot(x,y,LineSpec); % 设置线型、标记符号和颜色plot(x,y,&#x27;--or&#x27;); % 带有圆形标记的红色虚线 LineSpec是一个字符串，可以包含上述若干要素，基本线型、标记和颜色如下： 线型 说明 -(default) 实线 -- 虚线 : 点线 -. 点划线 颜色 说明 w 白 white y 黄 yellow c 青 cyan g 绿 green m 品 magenta r 红 red b 蓝 blue k 黑 black 标记 说明 o 圆圈 + 加号 * 星号 . 点 x 叉号 s 方形 square p 五角形 pentagonal d 菱形 diamond ^ 上三角 v 下三角 &gt; 右三角 &lt; 左三角 h 六角形 hexagon ps. 如果仅指定标记而忽略线型，则绘图时不会显示线条，只显示标记。 12plot(x1,y1,...,xn,yn); % 在同一个坐标区域内绘制多张图plot(x1,y1,LineSpec1,...,xn,yn,LineSpecn); 也可以使用hold on命令，将不同的图画在同一个坐标系里。 12plot(y); % 创建以y中数据为因变量、相应索引为自变量的二维线图plot(y,LineSpec) 若y是实向量，则x轴刻度范围为\\([1,length(y)]\\) 若y是实矩阵，则按列绘制曲线，相当于plot(索引矩阵,y)，自变量为索引 若y是复矩阵，则按列绘制曲线，相当于plot(real(y),imag(y))，自变量为实部，因变量为虚部 123plot(ax,_); % 指定坐标范围plot(_,Name,Value); % 使用一个或多个(Name,Value)对，单独指定某些属性的值h = plot(_); % 用变量h将图形储存，可以通过改变h的属性来实时修改图形 图形线条属性可以通过输出h来查看： 123456789 Color: [0.8500 0.3250 0.0980] % 颜色 LineStyle: &#x27;-&#x27; % 线型 LineWidth: 0.5000 % 线宽 Marker: &#x27;none&#x27; % 符号 MarkerSize: 6 % 符号大小MarkerFaceColor: &#x27;none&#x27; % 符号填充颜色 XData: [1×1001 double] % x轴数据 YData: [1×1001 double] % y轴数据 ZData: [1×0 double] % z轴数据 修改示例如下： 123x = 0:0.01:10;y = [sin(x);cos(x)];h = plot(x,y); 12&gt;&gt; h(2).YData = 0.1*x; % 修改第二条线的y轴数据&gt;&gt; h(1).LineStyle = &#x27;--&#x27;; % 修改第一条线的线型 此外，还有一些常用的属性如下 属性 说明 值 LineJoin 线条边角样式 round(default) miter chamfer MarkerEdgeColor 标记轮廓颜色 none(default) auto 颜色 fplot 专门用于绘制一元函数的命令。相比于plot()根据指定数据点绘图，fplot()会自适应地选取数据点，即在平滑处选取数据点稀疏、在陡峭处选取数据点密集，使图像更加光滑准确。 12fplot(f); % 在x的默认区间[-5,5]绘制由函数y=f(x)定义的曲线fplot(f,x_interval); % 在x的指定区间x_interval绘制由函数y=f(x)定义的曲线 f 为m文件函数名或系统自带函数名，x_interval为一个二元向量，包含区间的两个端点。示例如下： 1fplot(@exp,[-1,1]); grid on; 1234fplot(funx,funy);% 在t的默认区间[-5,5]绘制由参数方程x=funx(t),y=funy(t)定义的曲线fplot(funx,funy,t_interval);% 在t指定区间t_interval绘制由参数方程x=funx(t),y=funy(t)定义的曲线 funx和funy为参数方程函数名，t_interval为一个二元向量，包含区间的两个端点。 123xt = @(t) 2*cos(t);yt = @(t) sin(t);fplot(xt, yt); grid on; 1234fplot(_,LineSpec); % 指定线型、标记符号和颜色fplot(_,Name,Value); % 指定线条属性fplot(ax,_); % 指定坐标范围fp = fplot(_); % 返回可修改的图形对象 subplot 用于在同一个图形窗口中分割出多个视图区域。 1subplot(m,n,p); % 将当前窗口分割成m行n列的区域，用p指定当前位置 对p的编号采用从左至右、从上至下的原则。 12subplot(m,n,p,&#x27;replace&#x27;); % 将视图替换为空坐标区subplot(&#x27;Position&#x27;,pos); % 在pos指定的自定义位置创建坐标区 pos的格式为[left, bottom, width, height]，即以左下角坐标、宽度和高度定义，若新坐标区与原有坐标区重叠，则原有坐标区会被替换。 不同坐标系下的绘图 上述所有绘图命令均建立在平面直角坐标系中，下面介绍几种其他坐标系的绘图方法。 极坐标系 polarplot 与直角坐标系的plot函数几乎一致，只是将x换做theta，将y换做rho 12345678polarplot(theta,rho); % theta-极角(rad),rho-极半径polarplot(theta,rho,LineSpec);polarplot(theta1,rho1,...,thetan,rhon);polarplot(theta1,rho1,LineSpec1,...,thetan,rhon,LineSpecn);polarplot(z); % rho对应复数z的模长，theta对应幅角主值polarplot(z,LineSpec);ploarplot(_,Name,Value);p = polarplot(_); 示例： 1234theta = 0:0.01*pi:6*pi;rho1 = theta/10;rho2 = theta/12;polarplot(theta,rho1,&#x27;-b&#x27;,theta,rho2,&#x27;--r&#x27;); 坐标转化： 1234[theta, rho] = cart2pol(x, y); % 直角坐标转极坐标[x, y] = pol2cart(theta, rho); % 极坐标转直角坐标R = deg2rad(D); % 角度转弧度D = rad2deg(R); % 弧度转角度 对数坐标系 对于某些变化迅速的变量，线性坐标可能无法形象展示其变化过程。若将部分或全部坐标取对数，就可以减缓变量的变化过程。常用的对数坐标系有： semilogx() - x轴为对数坐标，y轴为线性坐标 semilogy() - y轴为对数坐标，x轴为线性坐标 loglog() - x、y轴均为对数坐标 函数调用规则与plot类似。示例如下： 1234x = 0:0.01:10;y = exp(x);subplot(2,1,1); plot(x,y); grid on; % 直接绘制subplot(2,1,2); semilogy(x,y); grid on; % 对y轴取对数 ps. 对数以10为底 双y轴坐标系 对于同一个坐标系内的两条曲线，若二者的变化范围差距过大，会导致变化范围较小的曲线无法清晰显示。此时，可以使用yyaxis left与yyaxis right命令为坐标系创建两个y轴，并分别绘制。该命令仅起到定位作用，与subplot类似。 示例如下： 1234567x = 0:0.01:10;y_large = sin(x);y_small = 0.1*cos(x);subplot(2,1,1); plot(x,y_large,x,y_small); grid on;subplot(2,1,2); grid on;yyaxis left; plot(x,y_large);yyaxis right;plot(x,y_small); 图形窗口 Matlab的图形窗口和命令行窗口是相互独立的，通过图形窗口可以修改和编辑图形界面、实现大量数据计算结果的可视化。 创建 使用figure命令创建图形窗口 12345figure % 创建一个图形窗口figure(Name,Value); % 使用(Name,Value)对来修改属性，如(&#x27;Name&#x27;,&#x27;图1&#x27;)f = figure(_); % 使用变量f储存窗口对象，可以通过它改变窗口的属性figure(f); % 指定当前绘图窗口为ffigure(num); % 创建一个编号为num的图形窗口 相关命令 命令 说明 set(f,[Name1,...],[Value1,...]) 设定图形窗口的属性值 get(f) 获取图形窗口的属性值 close close all 关闭图形窗口 clf 清空图形窗口（不会关闭） 图形标注 坐标轴范围 使用axis(limit)指定当前坐标区的范围，limit只能是长度为4、6、8的向量。 123axis([Xmin,Xmax,Ymin,Ymax]); % 2维axis([Xmin,Xmax,Ymin,Ymax,Zmin,Zmax]); % 3维axis([Xmin,Xmax,Ymin,Ymax,Zmin,Zmax,Cmin,Cmax]); % 4维 图形注释 123456fill(x,y,&#x27;color&#x27;); % 用指定颜色填充数据(x,y)构成的多边形title(&#x27;string&#x27;); % 为图形添加标题xlabel(&#x27;string&#x27;); % 为x轴添加标注ylabel(&#x27;string&#x27;);zlabel(&#x27;string&#x27;);text(x,y,&#x27;string&#x27;); % 在指定位置添加字符串 可以配合num2str(num)函数，为图像添加与数值有关的标注，字符串之间使用[]衔接。 12345x = 0:0.01:10;k = rand(1,1);y = sin(x) * k;plot(x, y);title([&#x27;k=&#x27;, num2str(k)]); % 标题显示随机数k的取值 图例 12345legend(label1,...,labeln); % 按照曲线顺序设置图例legend(_,&#x27;Location&#x27;,lcn); % 指定图例的位置% &#x27;north&#x27;|&#x27;south&#x27;|&#x27;east&#x27;|&#x27;west&#x27;|&#x27;northeast&#x27;|...legend(_,&#x27;Orientation&#x27;,ornt); % 指定图例的显示方式% &#x27;vertical&#x27;(defalut)|&#x27;horizontal&#x27; 网格线 123grid on; % 为当前坐标区添加主网格线grid; % 切换主网格线可见性grid minor; % 切换次网格线可见性 绘制特殊图形 条形图bar 12bar(y); % 创建一个条形图，y中的每个元素对应一个条形。bar([1,2,3,4,5]); 当y是\\(m\\times n\\)的矩阵时，创建\\(m\\)组，每组包含\\(n\\)个条形： 1bar(rand(2,5)); 123456bar(x,y); % 在横坐标x指定的位置绘制y，要求x为严格单调递增的向量bar(_,width); % 设置条形的相对宽度bar(_,style); % 设置条形组的样式 % &#x27;grouped&#x27;(defalut)|&#x27;stacked&#x27;|&#x27;hist&#x27;|&#x27;histc&#x27;bar(_,color); % 设置条形的颜色b = bar(_); % 保存对象，可以修改其属性值 此外，还有其他形式的条形图，调用格式类似： 函数 说明 barh() 水平条形图 bar3() 竖直三维条形图 bar3h() 水平三维条形图 区域图area 12345area(x); % 与plot(x)一致，但会将曲线下方区域填充颜色area(x,y); % 与plot(x,y)一致，但会将曲线下方区域填充颜色area(x,Y); % 矩阵Y按列对向量x绘图，图像依次累加area(_,basevalue); % 指定区域填充的基值，默认为0ar = area(_); % 保存对象，可以修改其属性值 123456x = 0:0.5:5;Y = [ones(size(x)) rand(size(x))+1 rand(size(x))+1 rand(size(x))+1];area(x,Y&#x27;,-1); % 矩阵Y的行数须与向量x一致，指定基值为-1 饼图pie 12345pie(x); % 使用x中的数据绘制饼图pie(x,explode); % 将扇区从饼图偏移一定位置% explode与向量x长度相同，其中的值分别对应偏移大小pie(x,labels); % 指定扇区的文本标签，标签数必须等于向量x的长度，采用元胞表示pie(x,explode,labels); 1234x = [1, 3, 1, 5];explode = [0, 0.1, 0.2, 0.3];labels = &#123;&#x27;无偏移&#x27;, &#x27;偏移0.1&#x27;, &#x27;偏移0.2&#x27;, &#x27;偏移0.3&#x27;&#125;;pie(x, explode, labels); 可以用pie3绘制三维饼图。 直方图histogram与polarhistogram 通过help指令查询详细信息。 12x = randn(10000, 1);histogram(x); 12theta = [0.1 1.1 5.4 3.4 2.3 4.5 3.2 3.4 5.6 2.3 2.1 3.5 0.6 6.1];polarhistogram(theta,6); 含误差的线图errorbar 123456errorbar(y,err); % 创建y中数据的线图，并在每个数据点绘制一个垂直误差条% err和y长度相同，对应了每个数据点的误差大小errorbar(x,y,err); % 横坐标xerrorbar(x,y,neg,pos); % neg确定数据点向下误差，pos确定数据点向上误差errorbar(_,ornt); % 设置误差条的方向 &#x27;vertical&#x27;(default)|&#x27;horizontal&#x27;|&#x27;both&#x27;e = errorbar(_); 1234x = 1:10;y = x;err = [0.1:0.1:0.5, 0.1:0.1:0.5];errorbar(x,y,err,&#x27;both&#x27;); 离散图（针状图）stem 用法与plot一致。 1234y = 1:6;stem(y);hold on;stem(y+1,&#x27;filled&#x27;); % 绘制实心点 可以用stem3绘制三维针状图 阶梯图stairs 用法与plot一致 1234x = 0:0.1:2*pi;stairs(x, sin(x));hold on; grid on;stairs(x, cos(x)); 罗盘图compass 用箭头显示坐标为\\((u,v)\\)的向量，\\(u\\)和\\(v\\)长度一致，箭头起点位于原点。 12compass(u,v);compass(z); % 相当于compass(real(z), imag(z)); 与其他画图函数类似，可以指定线型、标记符号和颜色，可以用对象保存图像。 123u = [1, 0, -3, 0];v = [0, 2, 0, -4];compass(u,v); 箭头图quiver 12quiver(x,y,u,v); % 在(x,y)位置绘制由(u,v)确定的向量quiver(u,v); % 相当于quiver(1:n,1:m,u,v),其中u,v为m*n的矩阵 1234567[x, y] = meshgrid(-2:.2:2); % 返回网格坐标z = x.*exp(-x.^2 - y.^2);[dx, dy] = gradient(z, .2, .2); % 返回梯度contour(x, y, z); % 绘制等高线hold on;quiver(x, y, dx, dy);","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab符号运算","slug":"matlab-basic-5","date":"2022-08-06T15:06:23.000Z","updated":"2022-08-17T03:52:55.112Z","comments":true,"path":"2022/08/06/matlab-basic-5/","link":"","permalink":"https://pyxblog.cn/2022/08/06/matlab-basic-5/","excerpt":"Matlab系列教程5-符号运算，包括符号表达式的创建，符号矩阵运算，符号运算及带入求值的基本操作。","text":"Matlab系列教程5-符号运算，包括符号表达式的创建，符号矩阵运算，符号运算及带入求值的基本操作。 符号运算是数值计算的扩展，在运算过程中以符号表达式或符号矩阵为运算对象，实现了符号计算和数值计算的相互结合，使应用更灵活。 创建符号表达式 创建符号表达式，需要先创建符号变量，再使用它们编写表达式。 使用关键字syms创建符号变量： 123456789101112131415161718192021syms a b c % 一次可以创建多个变量，变量之间只能用空格衔接syms A [3 4] % 创建符号矩阵% A =% % [ A1_1, A1_2, A1_3, A1_4]% [ A2_1, A2_2, A2_3, A2_4]% [ A3_1, A3_2, A3_3, A3_4]syms &#x27;A%d%d&#x27; [2 2] % 可以通过占位符%d来改变默认格式% A =% % [ A11, A12]% [ A21, A22]syms M 3 % 3阶方阵% M =% % [ M1_1, M1_2, M1_3]% [ M2_1, M2_2, M2_3]% [ M3_1, M3_2, M3_3] 先将变量创建好，才能将含有该变量字符串转化为符号表达式 123456syms xstr = &#x27;x^3+2*x+1&#x27;; % 不识别2x，即*不可省略S = eval(str); % 将字符串转化为符号表达式% S =% % x^3 + 2*x + 1 也可以通过多项式部分提到的函数ploy2sym(p)，将系数向量转化为符号表达式 12345P = [1 2 2 1];S = poly2sym(P);% S =% % x^3 + 2*x^2 + 2*x + 1 可以通过函数sym(A)将矩阵\\(A\\)转化为符号表达式sym格式。只有符号表达式可以与符号表达式计算，数值表达式无法直接与符号表达式进行计算。 123456A = ones(2,3);S = sym(A) % 2*3 sym% S =% % [ 1, 1, 1]% [ 1, 1, 1] 使用sym()函数处理数值表达式时，应从尽量小的单位入手，以免产生精度上的误差，如 12345678910111213141516171819202122232425&gt;&gt; sym(1/1234567) % 错误 ans = 7650239286923505/9444732965739290427392 &gt;&gt; 1/sym(1234567) % 正确 ans = 1/1234567% ------------------------------------------------&gt;&gt; sym(exp(pi)) % 错误 ans = 6513525919879993/281474976710656 &gt;&gt; exp(sym(pi)) % 正确 ans = exp(pi) 符号矩阵运算 转置 Matlab默认符号属于复数，在使用'求转置时，会自动求出共轭转置。因此若只想求转置，应该使用.' 12345678910111213syms &#x27;A%d%d&#x27; [2 3]% A =% % [ A11, A12, A13]% [ A21, A22, A23]B = A.&#x27;% B =% % [ A11, A21]% [ A12, A22]% [ A13, A23] 行列式 12345678910syms &#x27;A%d%d&#x27; 2% A =% % [ A11, A12]% [ A21, A22]d = det(A)% d =% % A11*A22 - A12*A21 求逆 1inv(A); % A必须是方阵，结果用A中元素表示 求秩 1rank(A); % 返回一个整数 其他 函数 说明 inv(A) 求矩阵的逆，结果用\\(A\\)中的元素表示 rank(A) 求矩阵的秩，返回一个整数 eig(A) 求特征值、特征向量 svd(A) 奇异值分解 jordan(A) Jordan标准形运算 符号运算 因式分解 使用函数factor(S)实现 12345S = poly2sym([1 3 2]); % S = X^2+3*x+2factor(S)% ans =% % [ x + 2, x + 1] 也可用于质因数分解 12S = sym(276);factor(S) % [2 2 3 23] 表达式展开 123syms xS = eval(&#x27;(x+1)*(x+2)&#x27;);expand(S) % x^2 + 3*x + 2 也可以用于三角函数、指数函数、对数函数的展开 123syms x yS = eval(&#x27;sin(x+y)&#x27;);expand(S) % cos(x)*sin(y) + cos(y)*sin(x) 表达式化简 123syms xS = eval(&#x27;sin(x)^2+cos(x)^2&#x27;);simplify(S) % x+1 分式通分 12345syms x yS = eval(&#x27;1/x+1/y&#x27;);[n, d] = numden(S)% n - 分子 n=x+y% d - 分母 d=x*y 代入/计算结果 通过函数subs(S,old,new)实现，返回值仍是sym类型。 12345678910111213syms F m a Ffstr = &#x27;Ff+F&#x27;;S = eval(str);S = subs(S,F,a*m) % 用a*m代换F% S =% % Ff + a*mres = subs(S,[a m Ff],[2 10 15]) % 分别给[a m Ff]赋值为[2 10 15]% res =% % 35","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab矩阵","slug":"matlab-basic-4","date":"2022-08-06T14:50:17.000Z","updated":"2022-08-17T03:52:20.793Z","comments":true,"path":"2022/08/06/matlab-basic-4/","link":"","permalink":"https://pyxblog.cn/2022/08/06/matlab-basic-4/","excerpt":"Matlab系列教程4-矩阵，包括基本的矩阵创建、编辑和运算操作。","text":"Matlab系列教程4-矩阵，包括基本的矩阵创建、编辑和运算操作。 矩阵是由个数排成的行列数表，记成 含有个维行向量，个维列向量。 矩阵创建 创建 - 直接输入 用[]定义矩阵，同一行的元素用,或空格分割，不同行的元素用;或回车分割 矩阵的大小不需要预先定义，若[]中不写元素，表示空矩阵 创建 - 从文件中读取 可以将较为常用的矩阵写入.m文件，调用时直接运行该文件，即可在工作台看到相应矩阵。除此之外，可以使用load命令调用.txt等类型的文件。 创建 - 用函数生成特殊矩阵 可以用某些函数生成具有某些特点的矩阵，常用函数如下 函数 说明 eye(n) eye(m,n) eye(size(A)) 创建指定大小的单位矩阵 ones(n) ones(m,n) ones(size(A)) 创建指定大小矩阵，其中元素均为1 zeros(n) zeros(m,n) zeros(size(A)) 创建指定大小矩阵，其中元素均为0 rand(n) rand(m,n) rand(size(A)) 创建指定大小矩阵，其中元素服从范围内的均匀分布 randn(n) randn(m,n) randn(size(A)) 创建指定大小矩阵，其中元素服从标准正态分布 compan(P) 创建系数向量为的多项式的伴随矩阵 diag(v) 创建以向量中的元素为对角线的对角阵 hilb(n) 创建一个的Hilbert矩阵 magic(n) 创建一个阶幻方 sparse(A) 将矩阵转化为稀疏矩阵形式，即由的非零元素和下标构成稀疏矩阵 矩阵编辑 矩阵拼接 123456789A = [1 2 3 4];B = zeros(2);C = ones(2);D = [A; B C]% D =% % 1 2 3 4% 0 0 1 1% 0 0 1 1 用,或空格衔接，以实现矩阵的横向拼接，如上例中的矩阵与矩阵 用;或换行衔接，以实现矩阵的纵向拼接，如上例中的矩阵与拼接矩阵 引用矩阵中的某些元素 对矩阵的每个维度均指定一个索引，即可引用相应的数据。 索引可以是标量（一个数）、向量（只能包含正整数）和:（表示全部）。 12345678910A = [1 2 3 4 5 6 7 8 9 10 11 12];A(2,2) % 第2行第2列，即元素6A(3,[2,4]) % 第3行第2和第4列，即[10 12]A(1:3,3) % 第3列第1行至第4行，即[3;7;11]A(3,:) % 第3行所有元素，即[9 10 11 12]A(:,4) % 第4列所有元素，即[4;8;12] 矩阵变形 变换维度：通过函数reshape(X,m,n)实现：将中的数据按列取出，再根据指定的维度，从左至右按列填充 123456789101112t = 1:12;A = reshape(t, 2, 6)% A =% 1 3 5 7 9 11% 2 4 6 8 10 12B = reshape(A, 4, 3)% B =% 1 5 9% 2 6 10% 3 7 11% 4 8 12 也可以仅指定一个维度，让函数自适应另一个维度的大小 12C = reshape(B, 3, []); % 重构为3*4的矩阵D = reshape(C, [], 2); % 重构为6*2的矩阵 旋转与翻转 函数 说明 rot90(X) rot90(X,k) 将矩阵逆时针方向旋转 fliplr(X) 将矩阵左右翻转 flipud(X) 将矩阵上下翻转 flipdim(X,dim) dim=1时对行翻转，dim=2时对列翻转 三角阵/对角阵的抽取 提取对角线/用对角线构造对角阵 12345678910111213141516171819202122v = 1:3;A = diag(v) % 生成以向量v为对角线的对角阵% 1 0 0% A = 0 2 0% 0 0 3v = diag(A) % 提取矩阵A的对角线，生成列向量% 1% v = 2% 3A = diag(v,2) % 生成以向量v为主对角线上第2条对角线的对角阵% 0 0 1 0 0% 0 0 0 2 0% A = 0 0 0 0 3% 0 0 0 0 0% 0 0 0 0 0v = diag(A,2) % 提取主对角线上第2条对角线，生成列向% 1% v = 2% 3 提取上/下三角阵 123456789101112131415161718192021A = ones(3);tril(A) % 提取下三角阵% 1 0 0% 1 1 0% 1 1 1tril(A,1) % 从主对角线上第一条对角线开始提取下三角阵% 1 1 0% 1 1 1% 1 1 1triu(A) % 提取上三角阵% 1 1 1% 0 1 1% 0 0 1triu(A,-1) % 从主对角线下第一条对角线开始提取上三角阵% 1 1 1% 1 1 1% 0 1 1 几个函数虽然功能不同，但第二个参数中对角线的定位规则一致，正数代表主对角线上的对角线，负数代表下面的对角线，提取时取闭区间。 矩阵运算 加减运算 要求进行运算的矩阵形状一致（即各维度长度一致），计算时对应位置相加减即可，有交换律和结合律。 乘运算 若有三个矩阵，则对矩阵中的任意一个元素，有 即 其中矩阵的列数（第二维度）需要等于矩阵的行数（第一维度）。 矩阵乘运算不满足交换律。 点乘运算 两个形状一致的矩阵，对应位相乘，得到一个形状不变的矩阵。 除法运算 - 左除 线性方程组，若非奇异，即它的逆矩阵存在，则可解出X=inv(D)*B=D\\B 条件：的阶数等于的行数。（非奇异表明是方阵） 除法运算 - 右除 线性方程组，若非奇异，即它的逆矩阵存在，则可解出X=B*inv(D)=B/D 条件：的列数等于的阶数。 除号偏向哪边，哪边要求非奇异 使用除法运算解线性方程组比使用inv求逆的方法更迅速，且拥有更小的残差 常用矩阵运算函数 函数 说明 cond(A) 返回2-范数逆运算的条件数，即最大奇异值与最小奇异值之比 condest(A) 返回 1-范数条件数的下限 det(A) 返回矩阵的行列式（一个值） eig(A) 返回矩阵的特征值/特征向量 inv(A) 返回矩阵的逆 norm(A,p) 返回矩阵的范数，p可以为1 2 Inf 'fro'，不填默认为2 normest(A) 返回矩阵的2-范数，相当于norm(A,2) rank(A) 返回矩阵的秩 orth(A) 矩阵的正交化运算，返回适用于矩阵范围的标准正交基，列数等于秩 rcond(A) 返回1-范数的逆条件数 trace(A) 返回矩阵对角线之和，即矩阵的迹 expm(A) 矩阵指数运算，每个元素变为 logm(A) 矩阵对数运算，每个元素变为 sqrtm(A) 矩阵开方运算，返回使 cdf2rdf 将复数对角矩阵转换成实数块对角矩阵 rsf2csf 将实数块对角矩阵转换成复数对角矩阵 rref 将矩阵转换成逐行递减的阶梯矩阵 funm 一般的矩阵函数 关于矩阵的条件数与“病态”： 矩阵的条件数用于刻画矩阵的“病态”程度，定义为： 它是一个不小于1的实数，当时，说矩阵是“病态”的，反之则是“良态”的。 奇异值分解 SVD SVD分解是指将一个的矩阵表示为三个矩阵乘积的形式：，其中为阶方阵，为阶方阵，为阶对角阵，其对角线元素为矩阵的奇异值且满足： 其中为矩阵的秩。 12s = svd(A); % 返回矩阵A的奇异值列向量s[U,S,V] = svd(A); % 返回矩阵A的奇异值分解因子U、S和V","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab元胞与结构体","slug":"matlab-basic-3","date":"2022-08-06T14:46:00.000Z","updated":"2022-08-17T03:52:07.503Z","comments":true,"path":"2022/08/06/matlab-basic-3/","link":"","permalink":"https://pyxblog.cn/2022/08/06/matlab-basic-3/","excerpt":"Matlab系列教程3-元胞与结构体，包括单元型变量（即元胞）和结构型变量（即结构体）的生成及基本操作。","text":"Matlab系列教程3-元胞与结构体，包括单元型变量（即元胞）和结构型变量（即结构体）的生成及基本操作。 Matlab中的特殊变量允许用户将不同但相关的数据类型集成一个单一的变量，以便数据的管理，类似C++中的结构体。 单元型变量（元胞） 单元型变量是以“单元”为元素的数组，每个单元可以包含各种类型的数据（如矩阵、字符串），通过{}创建，通过下标直接引用。 数组类型为cell，其中每个元素的类型也为cell。 12345a = 1:10;b = 'test';c = [1+2i,1 1,1+2i];ce = {a, b, c}; 可以通过cell()函数预先分配空间，再对其中的元素进行逐个赋值。 指令 效果 cell(n) 生成阶空单元数组 cell(m,n)/cell([m,n]) 生成阶空单元数组 cell(m,n,p,...)/cell([...]) 生成阶空单元数组 cell(size(X)) 生成与矩阵同维的空单元数组 有关单元型变量的函数：可以通过lookfor cell查找学习 函数 说明 cellfun(func,C) 对单元型变量中的每个元素依次执行函数func celldisp(C) 在命令行中逐个输出每个元素的具体内容 cellplot(C) 用彩色图形窗口逐个显示元素的内容 num2cell(num) 将数值转换为单元型变量 deal 输入输出处理 cell2struct(C) 将单元型变量转换为结构型变量 struct2cell(St) 将结构型变量转换为单元型变量 iscell(X) 判断是否为单元型变量 reshape(X,[...]) 将中的元素按列取出，再按列重构为[]规定的维度 结构型变量 结构型变量是根据属性名field组织起来的不同数据类型的集合，每个属性可以包含不同的数据类型，如字符串、矩阵等，类似字典。通过函数struct来创建，通过属性名来引用属性值，通过索引来引用相应元素。 1234st = struct('name',{'Tom','Amy'}, 'sex',{'male','female'}, 'age',{18});st(1); % 每个属性的第一个值 name:'Tom', sex:'male', age:18st.sex; % 所有的sex属性 ans='male', ans='female'st(2).name; % name属性的第二个值 ans='Amy' 创建结构型变量时，要求每个属性的长度一致，或者为标量（只有一个值），如上述的name和sex长度一致，age是标量。 有关结构型变量的函数：可以通过lookfor struct查找学习 函数 说明 fieldnames(st) 返回结构型变量的所有属性名 getfield(st,fieldName) 返回指定属性名的所有属性值 setfield(st,fieldName,value) 设定指定属性名的值为value rmfield(st,fieldName) 删除指定属性 isfield(st,fieldName) 判断fieldName是不是st的属性 isstruct(st) 判断st是否是结构型变量","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab向量与多项式","slug":"matlab-basic-2","date":"2022-08-05T14:51:28.000Z","updated":"2022-08-17T03:51:50.168Z","comments":true,"path":"2022/08/05/matlab-basic-2/","link":"","permalink":"https://pyxblog.cn/2022/08/05/matlab-basic-2/","excerpt":"Matlab系列基础教程2-向量与多项式，包括向量的生成与运算、多项式的生成与运算。","text":"Matlab系列基础教程2-向量与多项式，包括向量的生成与运算、多项式的生成与运算。 向量是由个数组成的有序数组，记成或，叫做维向量，向量的第个分量称为。 向量生成与引用 向量生成 直接输入 向量用[]扩起来，元素之间用,或空格隔开，;则相当于换行 冒号法 t = 区间左端点 : 增量 : 区间右端点; 1234567t = first:increment:last;% first - 从first开始（闭区间）% last - 到last为止（闭区间）% increment - 增量，默认为1t = 0:2:10; % [0 2 4 6 8 10]t = 0:5; % [0 1 2 3 4 5]t = 10:-2:0; % [10 8 6 4 2 0] 利用函数linspace(区间左端点, 区间右端点, 个数) 123456linspace(first_value, last_value, number);% 在指定范围内等间隔采样% first_value - 从first_value开始（闭区间）% last_value - 到last_value结束（闭区间）% number - 包含number个元素x = linspace(0,10,5); % [0 2.5 5 7.5 10] 利用函数logspace(区间左端点, 区间右端点, 个数) 123456logspace(first_value, last_value, number);% 在指定范围内等间隔采样，但区间取10的幂% first_value - 从10^first_value开始（闭区间）% last_value - 到10^last_value结束（闭区间）% number - 包含number个元素x = logspace(1,3,3); % [10 100 1000] 可以同时采用多种方法创建向量，并使用[]将它们合并 12x = [2:4 4,5,6 linspace(10,20,2)]; % (2 3 4) (4 5 6) (10 20) 向量引用 格式 说明 x(index) 表示向量中的第个元素 x(i:j) 表示向量中的第到第个元素 x(i:delta:j) 表示向量中的第到第个元素，每个取一个值 向量的索引从1开始 可以用另一个向量作为索引，去访问向量，向量只能包含正整数，且不能超过的索引范围 12345x = 1:2:20;n1 = [1,4,9,7];n2 = 2:3:10; % [2,5,8]x(n1) % [1 7 17 13]x(n2) % [3 9 15] 向量运算 四则运算 相当于对向量中的元素分别进行四则运算 12345x = 2:2:10; % [2 4 6 8 10]x+1 % [3 5 7 9 11]x-1 % [1 3 5 7 9]x*2 % [4 8 12 16 20]x/2 % [1 2 3 4 5] 矩阵运算 向量可以看做特殊的矩阵，可以用矩阵运算的规则进行向量运算 1234567x = 2:2:10; % [2 4 6 8 10]y = 1:5; % [1 2 3 4 5]x+y % [3 6 9 12 15]x-y % [1 2 3 4 5]x.*y % [2 8 18 32 50] 按位乘x./y % [2 2 2 2 2] 按位除x*y' % 110 矩阵乘法 点积（数量积、内积） 向量和的点积定义为 其中，向量和向量必须长度相同。 123dot(a,b);sum(a.*b);sum(a*b'); 向量积（外积、叉积、叉乘） 向量和的向量积模长为 其方向与向量和所在平面垂直，且遵循右手定则。 12345cross(a,b); % 返回a和b的叉积，此时a和b必须是3维的向量% 计算其他维度叉积可以通过help cross查看对应方法x = [1,0,0];y = [0,1,0];z = cross(x,y); % z = [0,0,1] ps. 点积的结果是一个数，向量积的结果是一个同维向量 多项式 在Matlab中，用系数向量表示相应的多项式，以便进行多项式计算： 系数中的0不能省略，如 多项式的创建 使用系数向量p，通过函数poly2sym(p)创建多项式，返回sym类型多项式 1s = poly2sym([1,2,1]); % x^2 + 2*x + 1 使用根向量root，通过函数poly(root)创建多项式，返回系数向量 123root = [1 2];p = poly(root); % [1 -3 2]poly2sym(p) % x^2 - 3*x + 2 也可以编写字符串str，再通过eval(str)函数将其转换为sym类型。 sym类型表示“符号表达式”，也可以直接用于计算，后续的章节中包含相关内容。 多项式运算 多项式运算通过系数向量进行。 加减运算直接用+-实现，相加、相减的两个向量必须大小相等。 多项式乘法 相当于执行两个数组的卷积，用函数conv(p1,p2)实现，返回结果多项式的系数向量 123p1 = [1 2 1];p2 = [1 2 1];conv(p1,p2) % [1 4 6 4 1] 多项式除法 相当于执行两个数组的解卷，用函数deconv(p,q)实现，返回结果多项式的系数向量 123456789[k, r] = deconv(p, q);% k - p除以q的商% r - p除以q的余式% p = conv(q, k) + r;p1 = [1 2 1];p2 = [1 2 1];p = conv(p1,p2); % [1 4 6 4 1]deconv(p, p1) % [1 2 1] 多项式求导 通过函数polyder(p)实现，返回结果多项式的系数向量 12p = [1 1 1 1 1];polyder(p) % [4 3 2 1]","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab基础知识","slug":"matlab-basic-1","date":"2022-08-05T14:19:06.000Z","updated":"2022-08-17T03:51:27.330Z","comments":true,"path":"2022/08/05/matlab-basic-1/","link":"","permalink":"https://pyxblog.cn/2022/08/05/matlab-basic-1/","excerpt":"Matlab系列基础教程1-基础知识，包括Matlab中的常量、数据类型、运算符、复数与三角函数的基本用法。","text":"Matlab系列基础教程1-基础知识，包括Matlab中的常量、数据类型、运算符、复数与三角函数的基本用法。 常量 常量名称 对应含义 pi 圆周率 eps 浮点相对精度，常用于防止0出现在分母上 inf(Inf) 无穷大，如 NaN(nan) 不定值，如、、 i(j) 复数中的虚数单位 realmin 最小正浮点数 realmax 最大正浮点数 ps. 常量可以被赋值，使用命令clear+变量名或重启Matlab可以将常量恢复初始值。 数据类型 整型 含义 占用空间 char 字符型 1字节 unsigned char 无符号字符型 1字节 short 短整型 2字节 unsigned short 无符号短整型 2字节 int 有符号整型 4字节 unsigned int 无符号整型 4字节 long 长整型 4字节 unsigned long 无符号长整型 4字节 浮点型： 十进制数形式：由数字和小数点组成 指数形式：一般形式为 aEn，其中a为10进制数，n为10进制整数，表示 可以分为两类：单精度型和双精度型 单精度 float，占4字节，数值范围，最多7位有效数字 双精度 double，占8字节，数值范围，最多16位有效数字 ps. 使用命令format可以控制命令行的输出格式，参考help format 类型转换 12nu = 123;st = num2str(nu); % '123' 遇到不熟悉的类型转换时，可以使用lookfor指令查找相关函数： 123456789101112131415161718192021&gt;&gt; lookfor num2num2cell - Convert numeric array into cell array.num2hex - Convert singles and doubles to IEEE hexadecimal string formatnum2str - Convert numbers to character representationnum2ruler - Convert numeric array to ruler-appropriate array datatypeenum2val - Converts an enumerated string to its numerical equivalent.num2cell - Convert numeric codistributed array into cell arraynum2str - overloaded for gpuArraysnum2mstr - Convert number to string in maximum precision.iptnum2ordinal - Convert positive integer to ordinal string.num2ordinal - Convert positive integer to ordinal character vector.signal_num2str - Convert the number to a string.num2goid - Converts numbers to Gene Ontology IDs.num2str - Convert numbers to character representationdefnum2 - Sets Default channel namesnum2deriv - Numeric two-point network derivative function.num2base - Convert stored integers to stringsnum2sdec - Convert stored integers of array of fi objects to signed decimal representationnum2fixpt - Quantize a value using a Fixed-Point Designer representation.num2alphaheaders - Generate Alpha headers from a number (usually column).&gt;&gt; 运算符 算数运算符 定义 + 算数加 - 算数减 * 算数乘 .* 点乘 ^ 算数乘方 .^ 点乘方 \\ 算数左除 .\\ 点左除 / 算数右除 ./ 点右除 ' 矩阵共轭转置 .' 矩阵转置，不求共轭 其中： 左除a\\b表示，右除a/b表示 A*B表示矩阵乘法，要求矩阵的第二维度与矩阵的第一维度相等，A.*B表示矩阵按位乘法，要求矩阵和矩阵的形状相同，对乘方具有一致要求 A+B要求矩阵和矩阵的形状相同，对算数减有一致要求 A+a表示对矩阵中的每个元素都，对其他算数运算有一致要求 关系运算符 定义 == 等于 ~= 不等于 &gt;(&lt;) 大于/小于 &gt;=(&lt;=) 大于等于/小于等于 逻辑运算符 定义 &amp; 逻辑与 | 逻辑或 ~ 逻辑非 xor 逻辑异或 any 有非零元素则为真 all 所有元素均非零则为真 ps. 有关优先级 算数运算符 &gt; 关系运算符 &gt; 逻辑运算符 逻辑运算符中，~具有最高优先级，&amp;和|优先级相同 复数及三角运算函数 复数运算函数 对应含义 abs(z) 返回绝对值或复数的模 theta=angle(z) 返回复数的相位，范围 z=complex(a,b) 返回复数 conj(z) 返回复数的共轭 a=real(z) 返回复数的实部 b=imag(z) 返回复数的虚部 isreal(x) 判断矩阵是否含有复数 unwrap 平移相位角 cplxpair 将复数排序为复共轭对组 三角运算函数 对应含义 sin() 正弦函数 cos() 余弦函数 tan() 正切函数 cot() 余切函数 sec() 正割函数 csc() 余割函数 ps. 反三角函数=a+三角函数，如反正弦为asin()","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]},{"title":"Matlab命令行","slug":"matlab-basic-0","date":"2022-08-05T13:34:25.000Z","updated":"2022-08-17T03:51:10.630Z","comments":true,"path":"2022/08/05/matlab-basic-0/","link":"","permalink":"https://pyxblog.cn/2022/08/05/matlab-basic-0/","excerpt":"Matlab系列基础教程0-命令行常用指令","text":"Matlab系列基础教程0-命令行常用指令 常用指令 指令含义 指令 help+函数名 精确查询函数 lookfor+函数信息 模糊查询函数 who 内存变量列表 whos 内存变量详细信息 which + 文件名 查找文件位置 exist+变量名 判断变量是否存在 path 查看当前所有路径 addpath+路径 添加路径 clc 清除命令行 clear 清除内存变量 close all 关闭所有窗口 应用示例 使用 help 指令查询函数用法 如同所示，使用 help 指令查询已知函数名的任意函数用法，其中大部分常用函数均有官方的中文版用法详解及相关实例，少部分尚未完成汉化（英文版文档），但也可以通过实例看懂。 使用 lookfor 指令查找相关函数 如同所示，使用 help 指令查询与 plot 相关的函数，会输出函数名/函数描述中带有\"plot\"字段的所有结果以供查看。 一般情况下，在主函数中前三行会写： 123clearclose allclc 作用是在主函数最开始依次执行： 清除内存变量 关闭之前打开的图形窗口 清空命令行（上一次运行代码的输入输出） 大家可以养成习惯哦！","categories":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]}],"categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/"},{"name":"实战","slug":"爬虫/实战","permalink":"https://pyxblog.cn/categories/%E7%88%AC%E8%99%AB/%E5%AE%9E%E6%88%98/"},{"name":"markdown系列教程","slug":"markdown系列教程","permalink":"https://pyxblog.cn/categories/markdown%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/"},{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"实战demo","slug":"深度学习/实战demo","permalink":"https://pyxblog.cn/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%AE%9E%E6%88%98demo/"},{"name":"python","slug":"python","permalink":"https://pyxblog.cn/categories/python/"},{"name":"基础教程","slug":"python/基础教程","permalink":"https://pyxblog.cn/categories/python/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"},{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/categories/Matlab/"},{"name":"基础教程","slug":"Matlab/基础教程","permalink":"https://pyxblog.cn/categories/Matlab/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"python","slug":"python","permalink":"https://pyxblog.cn/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://pyxblog.cn/tags/%E7%88%AC%E8%99%AB/"},{"name":"scrapy","slug":"scrapy","permalink":"https://pyxblog.cn/tags/scrapy/"},{"name":"latex","slug":"latex","permalink":"https://pyxblog.cn/tags/latex/"},{"name":"markdown","slug":"markdown","permalink":"https://pyxblog.cn/tags/markdown/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://pyxblog.cn/tags/PyTorch/"},{"name":"深度学习","slug":"深度学习","permalink":"https://pyxblog.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"Matlab","slug":"Matlab","permalink":"https://pyxblog.cn/tags/Matlab/"}]}